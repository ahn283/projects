{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db connection\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import keyring\n",
    "import platform\n",
    "import numpy as np\n",
    "\n",
    "user = 'root'\n",
    "pw = keyring.get_password('macmini_db', user)\n",
    "host = '192.168.219.106' if platform.system() == 'Windows' else '127.0.0.1'\n",
    "port = 3306\n",
    "db = 'stock'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base data\n",
    "COLUMNS_STOCK_DATA = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "COLUMNS_TRAINING_DATA = ['open', 'high', 'low', 'close', 'volume', 'close_ma5', 'volume_ma5', 'close_ma5_ratio', 'volume_ma5_ratio',\n",
    "       'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio',\n",
    "       'low_close_ratio', 'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "       'close_ma10', 'volume_ma10', 'close_ma10_ratio', 'volume_ma10_ratio',\n",
    "       'close_ma20', 'volume_ma20', 'close_ma20_ratio', 'volume_ma20_ratio',\n",
    "       'close_ma60', 'volume_ma60', 'close_ma60_ratio', 'volume_ma60_ratio',\n",
    "       'close_ma120', 'volume_ma120', 'close_ma120_ratio',\n",
    "       'volume_ma120_ratio', 'close_ma240', 'volume_ma240',\n",
    "       'close_ma240_ratio', 'volume_ma240_ratio', 'upper_bb',\n",
    "       'lower_bb', 'bb_pb', 'bb_width', 'macd',\n",
    "       'macd_signal', 'macd_oscillator', 'rs', 'rsi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stock data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# get us stock price of a specific ticker\n",
    "def get_stock_data(ticker, fro=None, to=None):\n",
    "\n",
    "    # connect DB\n",
    "    engine = create_engine(f'mysql+pymysql://{user}:{pw}@{host}:{port}/{db}')\n",
    "\n",
    "    con = pymysql.connect(\n",
    "        user=user,\n",
    "        passwd=pw,\n",
    "        host=host,\n",
    "        db=db,\n",
    "        charset='utf8'\n",
    "    )\n",
    "            \n",
    "    mycursor = con.cursor()\n",
    "    \n",
    "    if fro is not None:\n",
    "        if to is not None:               \n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date BETWEEN '{fro}' AND '{to}' \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date >= '{fro}'\n",
    "                    \"\"\"\n",
    "    \n",
    "    else:\n",
    "        if to is not None:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date <= '{to}' \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    \"\"\"\n",
    "            \n",
    "    print(query)\n",
    "    prices = pd.read_sql(query, con=engine)\n",
    "    con.close()\n",
    "    engine.dispose()\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2018-01-01' AND '2022-12-31' \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "stock_code = 'AAPL'\n",
    "fro = '2018-01-01'\n",
    "to = '2022-12-31'\n",
    "df = get_stock_data(stock_code, fro=fro, to=to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x = max(min(x, 10), -10)\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \n",
    "    # moving average\n",
    "    windows = [5, 10, 20, 60, 120, 240]\n",
    "    for window in windows:\n",
    "        data[f'close_ma{window}'] = data['close'].rolling(window).mean()\n",
    "        data[f'volume_ma{window}'] = data['volume'].rolling(window).mean()\n",
    "        data[f'close_ma{window}_ratio'] = (data['close'] - data[f'close_ma{window}']) / data[f'close_ma{window}']\n",
    "        data[f'volume_ma{window}_ratio'] = (data['volume'] - data[f'volume_ma{window}']) / data[f'volume_ma{window}']\n",
    "        data['open_close_ratio'] = (data['open'].values - data['close'].values) / data['close'].values\n",
    "        data['open_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'open_prev_close_ratio'] = (data['open'][1:].values - data['close'][:-1].values) / data['close'][:-1].values\n",
    "        data['high_close_ratio'] = (data['high'].values - data['close'].values) / data['close'].values\n",
    "        data['low_close_ratio'] = (data['low'].values - data['close'].values) / data['close'].values\n",
    "        data['close_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'close_prev_close_ratio'] = (data['close'][1:].values - data['close'][:-1].values) / data['close'][:-1].values \n",
    "        data['volume_prev_volume_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'volume_prev_volume_ratio'] = (\n",
    "            # if volume is 0, change it into non zero value exploring previous volume continuously\n",
    "            (data['volume'][1:].values - data['volume'][:-1].values) / data['volume'][:-1].replace(to_replace=0, method='ffill').replace(to_replace=0, method='bfill').values\n",
    "        )\n",
    "    \n",
    "    # Bollinger band\n",
    "    data['middle_bb'] = data['close'].rolling(20).mean()\n",
    "    data['upper_bb'] = data['middle_bb'] + 2 * data['close'].rolling(20).std()\n",
    "    data['lower_bb'] = data['middle_bb'] - 2 * data['close'].rolling(20).std()\n",
    "    data['bb_pb'] = (data['close'] - data['lower_bb']) / (data['upper_bb'] - data['lower_bb'])\n",
    "    data['bb_width'] = (data['upper_bb'] - data['lower_bb']) / data['middle_bb']\n",
    "    \n",
    "    # MACD\n",
    "    macd_short, macd_long, macd_signal = 12, 26, 9\n",
    "    data['ema_short'] = data['close'].ewm(macd_short).mean()\n",
    "    data['ema_long'] = data['close'].ewm(macd_long).mean()\n",
    "    data['macd'] = data['ema_short'] - data['ema_long']\n",
    "    data['macd_signal'] = data['macd'].ewm(macd_signal).mean()\n",
    "    data['macd_oscillator'] = data['macd'] - data['macd_signal']\n",
    "    \n",
    "    # RSI\n",
    "    data['close_change'] = data['close'].diff()\n",
    "    # data['close_up'] = np.where(data['close_change'] >=0, df['close_change'], 0)\n",
    "    data['close_up'] = data['close_change'].apply(lambda x: x if x >= 0 else 0)\n",
    "    # data['close_down'] = np.where(data['close_change'] < 0, df['close_change'].abs(), 0)\n",
    "    data['close_down'] = data['close_change'].apply(lambda x: -x if x < 0 else 0)\n",
    "    data['rs'] = data['close_up'].ewm(alpha=1/14, min_periods=14).mean() / data['close_down'].ewm(alpha=1/14, min_periods=14).mean()\n",
    "    data['rsi'] = 100 - (100 / (1 + data['rs']))\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "load_data() function is a combined function for getting data from databases and preprocessing it into training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock_code, fro, to):\n",
    "    ''' \n",
    "    Arguments\n",
    "    ----------\n",
    "    - stock_code : unique stock code\n",
    "    - fro : start date\n",
    "    - to : end data\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    df_adj : entire prerprocessed data\n",
    "    stock_data : data for plotting chart\n",
    "    training_data : data for training a model\n",
    "    '''\n",
    "    \n",
    "    df = get_stock_data(stock_code, fro, to)\n",
    "    df_adj = preprocess(df).dropna().reset_index(drop=True)\n",
    "    # df_adj.dropna(inplace=True).reset_index(drop=True)\n",
    "    \n",
    "    stock_data = df_adj[COLUMNS_STOCK_DATA]\n",
    "    training_data = df_adj[COLUMNS_TRAINING_DATA]\n",
    "    \n",
    "    return df_adj, stock_data, training_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2018-01-01' AND '2022-12-31' \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "df_adj, df_stock_data, df_training_data = load_data(stock_code, fro, to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get epsilon value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(step, eps_init=1.0, eps_final=0.05, eps_decrease_step=1000):\n",
    "    # eps_init = self.eps_init\n",
    "    # eps_final = self.eps_final\n",
    "    if step >= eps_decrease_step:\n",
    "        eps = eps_final\n",
    "    else:\n",
    "        m = (eps_final - eps_init) / eps_decrease_step\n",
    "        eps = eps_init + m * step\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# environment\n",
    "\n",
    "class Environment:\n",
    "    ''' \n",
    "    Attribute\n",
    "    ---------\n",
    "    - stock_data : stock price data such as 'open', 'close', 'high', 'low', 'volume'\n",
    "    - state : current state\n",
    "    - idx : current postion of stock data\n",
    "    \n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize idx and state\n",
    "    - observe() : move idx into next postion and get a new state\n",
    "    - get_close_price() : get close price of current state\n",
    "    - get_open_price() : get open price of current state\n",
    "    - get_state() : get current state\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, stock_data=None):\n",
    "        self.close_price_idx = 4    # index postion of close price\n",
    "        self.open_price_idx = 1     # index position of open price\n",
    "        self.stock_data = stock_data\n",
    "        self.state = None\n",
    "        self.idx = -1\n",
    "        self.max_idx = len(stock_data)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = None\n",
    "        self.idx = -1\n",
    "        # self.idx = 0\n",
    "        # self.state = self.stock_data.iloc[self.idx]\n",
    "        \n",
    "    def observe(self):\n",
    "        # move to next day and get price data\n",
    "        # if there is no more idx, return None\n",
    "        if len(self.stock_data) > self.idx + 1:\n",
    "            self.idx += 1\n",
    "            self.state = self.stock_data.iloc[self.idx]\n",
    "            return self.state\n",
    "        return None\n",
    "    \n",
    "    def get_close_price(self):\n",
    "        # return close price\n",
    "        if self.state is not None:\n",
    "            return self.state[self.close_price_idx]\n",
    "        return None\n",
    "    \n",
    "    def get_next_close_price(self):\n",
    "        # return tomorrow close price\n",
    "        if self.idx < self.max_idx - 1:\n",
    "            return self.stock_data.iloc[self.idx + 1, self.close_price_idx]\n",
    "        else:\n",
    "            return self.stock_data.iloc[self.idx, self.close_price_idx]\n",
    "    \n",
    "    def get_open_price(self):\n",
    "        # return open price\n",
    "        if self.state is not None:\n",
    "            return self.state[self.open_price_idx]\n",
    "        \n",
    "    def get_next_open_price(self):\n",
    "        # return tomorrow open price\n",
    "        if self.idx < self.max_idx - 1:\n",
    "            return self.stock_data.iloc[self.idx + 1, self.open_price_idx]\n",
    "        else:\n",
    "            return self.stock_data.iloc[self.idx, self.open_price_idx]\n",
    "        \n",
    "    \n",
    "    def get_state(self):\n",
    "        # return current state\n",
    "        if self.state is not None:\n",
    "            return self.state\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(df_stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       2018-12-13\n",
       "open        42.387501\n",
       "high        42.622501\n",
       "low         43.142502\n",
       "close       42.737499\n",
       "volume    127594400.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       2018-12-13\n",
       "open        42.387501\n",
       "high        42.622501\n",
       "low         43.142502\n",
       "close       42.737499\n",
       "volume    127594400.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.369998931884766"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_next_close_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       2018-12-14\n",
       "open            41.32\n",
       "high            42.25\n",
       "low             42.27\n",
       "close       41.369999\n",
       "volume    162814800.0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.369998931884766"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_state()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.369998931884766"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_close_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.682498931884766"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_next_open_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       2018-12-17\n",
       "open        40.682499\n",
       "high        41.362499\n",
       "low         42.087502\n",
       "close       40.985001\n",
       "volume    177151600.0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.682498931884766"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_state()['open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.682498931884766"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_open_price()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - enviroment : instance of environment\n",
    "    - initial_balance : initial capital balance\n",
    "    - min_trading_price : minimum trading price\n",
    "    - max_trading_price : maximum trading price\n",
    "    - balance : cash balance\n",
    "    - num_stocks : obtained stocks\n",
    "    - portfolio_value : value of portfolios (balance + price * num_stocks)\n",
    "    - num_buy : number of buying\n",
    "    - num_sell : number of selling\n",
    "    - num_hold : number of holding\n",
    "    - ratio_hold : ratio of holding stocks\n",
    "    - profitloss : current profit or loss\n",
    "    - avg_buy_price_ratio : the ratio average price of a stock bought to the current price\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize an agent\n",
    "    - set_balance() : initialize balance\n",
    "    - get_states() : get the state of an agent\n",
    "    - decide_action() : exploration or exploitation behavior according to the policy net\n",
    "    - validate_action() : validate actions\n",
    "    - decide_trading_unit() : decide how many stocks are sold or bought\n",
    "    - act() : act the actions\n",
    "    '''\n",
    "    \n",
    "    # action space\n",
    "    ACTION_BUY = 0      # buy\n",
    "    ACTION_SELL = 1     # sell\n",
    "    ACTION_HOLD = 2     # hold\n",
    "    \n",
    "    def __init__(self, env,\n",
    "                 initial_balance=None, min_trading_price=None, max_trading_price=None):      \n",
    "        \n",
    "        # agent state dimensions\n",
    "        # (ratio_hold, profit-loss ratio, current price to avg_buy_price ratio)\n",
    "        self.STATE_DIM = 3\n",
    "        \n",
    "        # trading charge and tax\n",
    "        self.TRADING_CHARGE = 0.00015    # trading charge 0.015%\n",
    "        self.TRADING_TAX = 0.002          # trading tax = 0.2%\n",
    "        \n",
    "        # action space\n",
    "        self.ACTION_BUY = 0      # buy\n",
    "        self.ACTION_SELL = 1     # sell\n",
    "        self.ACTION_HOLD = 2     # hold\n",
    "        \n",
    "        # get probabilities from neural nets\n",
    "        self.ACTIONS = [self.ACTION_BUY, self.ACTION_SELL, self.ACTION_HOLD]\n",
    "        self.NUM_ACTIONS = len(self.ACTIONS)      # output number from nueral nets\n",
    "        \n",
    "        \n",
    "        # get current price from the environment\n",
    "        self.env = env\n",
    "        self.initial_balance = initial_balance\n",
    "        self.done = False\n",
    "        \n",
    "        # minumum and maximum trainding price\n",
    "        self.min_trading_price = min_trading_price\n",
    "        self.max_trading_price = max_trading_price\n",
    "        \n",
    "        # attributes for an agent class\n",
    "        self.balance = initial_balance\n",
    "        self.num_stocks = 0\n",
    "        \n",
    "        # value of portfolio : balance + num_stocks * {current stock price}\n",
    "        self.portfolio_value = self.balance\n",
    "        self.num_buy = 0\n",
    "        self.num_sell = 0\n",
    "        self.num_hold = 0\n",
    "        \n",
    "        # three states of Agent class\n",
    "        self.ratio_hold = 0\n",
    "        self.profitloss = 0\n",
    "        self.avg_buy_price = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.num_stocks = 0\n",
    "        self.portfolio_value = self.balance\n",
    "        self.num_buy = 0\n",
    "        self.num_sell = 0\n",
    "        self.num_hold = 0\n",
    "        self.ratio_hold = 0\n",
    "        self.profitloss = 0\n",
    "        self.avg_buy_price = 0\n",
    "        self.done = False\n",
    "        # self.env.reset()\n",
    "        \n",
    "    def set_initial_balance(self, balance):\n",
    "        self.initial_balance = balance\n",
    "        \n",
    "    def get_states(self):\n",
    "        # return current profitloss based on close price\n",
    "        close_price = self.env.get_close_price()\n",
    "        self.ratio_hold = self.num_stocks * close_price / self.portfolio_value\n",
    "        self.portfolio_value = self.balance + close_price * self.num_stocks\n",
    "        self.profitloss = self.portfolio_value / self.initial_balance - 1\n",
    "        return (\n",
    "            self.ratio_hold,\n",
    "            self.profitloss,        # profitloss = (portfolio_value / initial_balance) - 1\n",
    "            (self.env.get_close_price() / self.avg_buy_price) if self.avg_buy_price > 0 else 0\n",
    "        )\n",
    "        \n",
    "    def decide_action(self, pred_value, eps):\n",
    "        # act randomly with epsilon probability, act according to neural network  with (1 - epsilon) probability\n",
    "        confidence = 0\n",
    "        \n",
    "        # if theres is a pred_policy, follow it, otherwise follow a pred_value\n",
    "        pred = pred_value\n",
    "            \n",
    "        # there is no prediction from both pred_policy and pred_value, explore!\n",
    "        if pred is None:\n",
    "            eps = 1\n",
    "        else:\n",
    "            maxpred = np.max(pred)\n",
    "            # if values for actions are euqal, explore!\n",
    "            if (pred == maxpred).all():\n",
    "                eps = 1\n",
    "                    \n",
    "        # decide whether exploration will be done or not\n",
    "        if np.random.rand() < eps:\n",
    "            exploration = True\n",
    "            action = np.random.randint(self.NUM_ACTIONS) \n",
    "        else: \n",
    "            exploration = False\n",
    "            action = np.argmax(pred)\n",
    "            \n",
    "        confidence = .5\n",
    "        if pred_value is not None:\n",
    "            confidence = sigmoid(pred[action])\n",
    "            \n",
    "        return action, confidence, exploration\n",
    "    \n",
    "    def validate_action(self, action):\n",
    "        # validate if the action is available\n",
    "        if action == self.ACTION_BUY:\n",
    "            # check if al least one stock can be bought.\n",
    "            if self.balance < self.env.get_open_price() * (1 + self.TRADING_CHARGE):\n",
    "                return False\n",
    "        elif action == self.ACTION_SELL:\n",
    "            # check if there is any sotck that can be sold\n",
    "            if self.num_stocks <= 0:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def decide_trading_unit(self, confidence):\n",
    "        # adjust number of stocks for buying and selling according to confidence level\n",
    "        if np.isnan(confidence):\n",
    "            return self.min_trading_price\n",
    "        \n",
    "        # set buying price range between self.min_trading_price + added_trading_price [min_trading_price, max_trading_price]\n",
    "        # in case that confidence > 1 causes the price over max_trading_price, we set min() so that the value cannot have larger value than self.max_trading_price - self.min_trading_price\n",
    "        # in case that confidence < 0, we set max() so that added_trading_price cannot have negative value.\n",
    "        added_trading_price = max(min(\n",
    "            int(confidence * (self.max_trading_price - self.min_trading_price)),\n",
    "            self.max_trading_price - self.min_trading_price\n",
    "        ), 0)\n",
    "        \n",
    "        trading_price = self.min_trading_price + added_trading_price\n",
    "        \n",
    "        return max(int(trading_price / self.env.get_open_price()), 1)\n",
    "    \n",
    "    def step(self, action, confidence):\n",
    "        '''\n",
    "        Arguments\n",
    "        ---------\n",
    "        - action : decided action from decide_action() method based on exploration or exploitation (0 or 1)\n",
    "        - confidence : probability from decide_action() method, the probability from policy network or the softmax probability from value network\n",
    "        '''\n",
    "        \n",
    "        # get the next open price from the environment\n",
    "        \n",
    "        open_price = self.env.get_next_open_price()\n",
    "        \n",
    "        if not self.validate_action(action):\n",
    "            action = self.ACTION_HOLD\n",
    "        \n",
    "        # buy\n",
    "        if action == self.ACTION_BUY:\n",
    "            # decide how many stocks will be bought\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            balance = (\n",
    "                self.balance - open_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            )\n",
    "            \n",
    "            # if lacks of balance, buy maximum units within the amount of money available\n",
    "            if balance < 0:\n",
    "                trading_unit = min(\n",
    "                    int(self.balance / (open_price * (1 + self.TRADING_CHARGE))),\n",
    "                    int(self.max_trading_price / open_price)\n",
    "                )\n",
    "                \n",
    "            # total amount of money with trading charge\n",
    "            invest_amount = open_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            if invest_amount > 0:\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks + open_price * trading_unit) / (self.num_stocks + trading_unit)\n",
    "                self.balance -= invest_amount\n",
    "                self.num_stocks += trading_unit\n",
    "                self.num_buy += 1\n",
    "                \n",
    "        # sell\n",
    "        elif action == self.ACTION_SELL:\n",
    "            # decide how many stocks will be sold\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            \n",
    "            # if lacks of stocks, sell maximum units available\n",
    "            trading_unit = min(trading_unit, self.num_stocks)\n",
    "            \n",
    "            # selling amount\n",
    "            invest_amount = open_price * (\n",
    "                1 - (self.TRADING_TAX + self.TRADING_CHARGE)\n",
    "            ) * trading_unit\n",
    "            \n",
    "            if invest_amount > 0:\n",
    "                # update average buy price\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks - open_price * trading_unit) / (self.num_stocks - trading_unit) if self.num_stocks > trading_unit else 0\n",
    "                self.num_stocks -= trading_unit\n",
    "                self.balance += invest_amount\n",
    "                self.num_sell += 1\n",
    "                \n",
    "        # hold\n",
    "        elif action == self.ACTION_HOLD:\n",
    "            self.num_hold += 1\n",
    "            \n",
    "        # update portfolio value with close price\n",
    "        close_price = self.env.get_next_close_price()\n",
    "        \n",
    "        self.portfolio_value = self.balance + close_price * self.num_stocks\n",
    "        self.profitloss = self.portfolio_value / self.initial_balance - 1\n",
    "        \n",
    "        # info = {\n",
    "        #     'num_stocks': self.num_stocks,\n",
    "        #     'num_hold': self.num_hold,\n",
    "        #     'num_buy': self.num_buy,\n",
    "        #     'num_sell': self.num_sell\n",
    "        # }\n",
    "        \n",
    "        # return next_state, self.profitloss, self.done, info             # (next_states, profitloss, done, info)\n",
    "        return self.profitloss\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "class Visualizer:\n",
    "    ''' \n",
    "    Attributes\n",
    "    ---------\n",
    "    - fig : matplotlib Fugure instance plays like a canvas\n",
    "    - plot() : plot charts except daily price chart stock data chart)\n",
    "    - save() : save Figure as an image file\n",
    "    - clear() : initialize all charts but daily price chart (stock data chart)\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    - Figure title : parameters, epsilon\n",
    "    - Axes 1 : daily price chart (stock data chart)\n",
    "    - Axes 2 : number of stocks and agent action chart\n",
    "    - Axes 3 : value network chart\n",
    "    - Axes 4 : policy network and epsilon chart\n",
    "    - Axes 5 : portfolio value and learning point chart\n",
    "    '''\n",
    "    \n",
    "    COLORS = ['r', 'b', 'g']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.canvas = None\n",
    "        self.fig = None\n",
    "        self.axes = None\n",
    "        self.title = ''\n",
    "        self.x = []\n",
    "        self.xticks = []\n",
    "        self.xlabels = []\n",
    "        \n",
    "    def prepare(self, stock_data, title):\n",
    "        self.title = title\n",
    "        # shred x-axis among all charts\n",
    "        with lock:\n",
    "            # prepare for plotting fice charts\n",
    "            self.fig, self.axes = plt.subplots(   \n",
    "                nrows=5, ncols=1, facecolor='w', sharex=True\n",
    "            )\n",
    "            for ax in self.axes:\n",
    "                # deactivate scientific marks\n",
    "                ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                # move y-axis to the right\n",
    "                ax.yaxis.tick_right()\n",
    "                \n",
    "            # chart 1. daily price data (stock data)\n",
    "            self.axes[0].set_ylabel('Env.')\n",
    "            x = np.arange(len(stock_data))\n",
    "            # make two dimentional array with open, high, low and close order\n",
    "            ohlc = np.hstack((\n",
    "                x.reshape(-1, 1), np.array(stock_data)[:, 1:5]\n",
    "            ))\n",
    "            # red for positive, blue for negative\n",
    "            candlestick_ohlc(self.axes[0], ohlc, colorup='r', colordown='b')\n",
    "            # visualize volume\n",
    "            ax = self.axes[0].twinx()\n",
    "            volume = np.array(stock_data)[:, 5].tolist()\n",
    "            ax.bar(x, volume, color='b', alpha=0.3)\n",
    "            # set x-axis\n",
    "            self.x = np.arange(len(stock_data['date']))\n",
    "            self.xticks = stock_data.index[[0, -1]]\n",
    "            self.xlabels = stock_data.iloc[[0, -1]]['date']\n",
    "            \n",
    "    def plot(self, epoch_str=None, num_epochs=None, eps=None,\n",
    "             action_list=None, actions=None, num_stocks=None,\n",
    "             outvals_value=[], outvals_policy=[], exps=None,\n",
    "             initial_balance=None, pvs=None):\n",
    "        ''' \n",
    "        Attributes\n",
    "        --------\n",
    "        - epoch_str : epoch for Figure title\n",
    "        - num_epochs : number of total epochs\n",
    "        - eps : exploration rate\n",
    "        - action_list : total action list of an agent\n",
    "        - num_stocks : number of stocks\n",
    "        - outvals_value : output array of value network\n",
    "        - outvals_policy : output array of policy network\n",
    "        - exps : array of values if exploration is true or not\n",
    "        - initial_balance\n",
    "        - pvs : array of portfolio values\n",
    "        '''\n",
    "        \n",
    "        with lock:\n",
    "            # action, num_stocks, outvals_value, outvals_policy, pvs has same size\n",
    "            # create an array with same size as actions and use it as an x-axis\n",
    "            actions = np.array(actions)     # action array of an agent\n",
    "            # turn value network output as an array\n",
    "            outvals_value = np.array(outvals_value)\n",
    "            # turn policy network ouput as an array\n",
    "            outvals_policy = np.array(outvals_policy)\n",
    "            # turn initial balance as an array\n",
    "            pvs_base = np.zeros(len(actions)) + initial_balance     # array([initial_balance, initial_balance, initial_balance, ...])\n",
    "            # chart 2. agent states (action, num_stocks)\n",
    "            for action, color in zip(action_list, self.COLORS):\n",
    "                for i in self.x[actions == action]:\n",
    "                    # express actions as background color : red for buying, blue for selling\n",
    "                    self.axes[1].axvline(i, color=color, alpha=0.1)\n",
    "            self.axes[1].plot(self.x, num_stocks, '-k')     # plot number of stocks\n",
    "            \n",
    "            # chart 3. value network (prediction value for action)\n",
    "            if (len(outvals_value)) > 0:\n",
    "                max_actions = np.argmax(outvals_value, axis=1)\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    # plot background\n",
    "                    for idx in self.x:\n",
    "                        if max_actions[idx] == action:\n",
    "                            self.axes[2].axvline(idx, color=color, alpha=0.1)\n",
    "                    # plot value network\n",
    "                    ## red for buying, blue for selling, green for holding\n",
    "                    ## if no predicted action, no plot green chart\n",
    "                    self.axes[2].plot(self.x, outvals_value[:, action], color=color, linestyle='-')\n",
    "                    \n",
    "            # chart 4. policy network\n",
    "            # plot exploration with yellow background\n",
    "            for exp_idx in exps:\n",
    "                self.axes[3].axvline(exp_idx, color='y')\n",
    "            # plot action as background\n",
    "            _outvals = outvals_policy if len(outvals_policy) > 0 else outvals_value\n",
    "            for idx, outval in zip(self.x, _outvals):\n",
    "                color = 'white'\n",
    "                if np.isnan(outval.max()):\n",
    "                    continue\n",
    "                # with no exploration area, red for buying, blue for selling\n",
    "                if outval.argmax() == Agent.ACTION_BUY:\n",
    "                    color = self.COLORS[0]      # red for buying\n",
    "                elif outval.argmax() == Agent.ACTION_SELL:\n",
    "                    color = self.COLORS[1]      # blue for selling\n",
    "                elif outval.argmax() == Agent.ACTION_HOLD:\n",
    "                    color = self.COLORS[2]      # green for holding\n",
    "                self.axes[3].axvline(idx, color=color, alpha=0.1)\n",
    "            \n",
    "            # plot policy network\n",
    "            # red for buying policy network output, blue for selling policy entwork\n",
    "            # when red line is above blue line, buy stocks, otherwise sell stocks\n",
    "            if len(outvals_policy) > 0:\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    self.axes[3].plot(\n",
    "                        self.x, outvals_policy[:, action],\n",
    "                        color=color, linestyle='-'\n",
    "                    )\n",
    "            \n",
    "            # chart 5. portfolio value\n",
    "            # horizontal line for initial balance\n",
    "            self.axes[4].axhline(\n",
    "                initial_balance, linestyle='-', color='gray'\n",
    "            )\n",
    "            self.axes[4].fill_between(\n",
    "                self.x, pvs, pvs_base,\n",
    "                where=pvs > pvs_base, facecolor='r', alpha=0.1\n",
    "            )\n",
    "            self.axes[4].plot(self.x, pvs, '-k')\n",
    "            self.axes[4].xaxis.set_ticks(self.xticks)\n",
    "            self.axes[4].xaxis.set_ticklabels(self.xlabels)\n",
    "            \n",
    "            # epoch and exploration rate\n",
    "            self.fig.suptitle(f'{self.title}\\nEPOCH:{epoch_str}/{num_epochs} EPSILON:{eps:.2f}')\n",
    "            # adjust canvas layout\n",
    "            self.fig.tight_layout()\n",
    "            self.fig.subplots_adjust(top=0.85)\n",
    "            \n",
    "    def clear(self, xlim):\n",
    "        with lock:\n",
    "            _axes = self.axes.tolist()\n",
    "            # initial chart except non changeable value\n",
    "            for ax in _axes[1:]:\n",
    "                ax.cla()        # initialize chart\n",
    "                ax.relim()      # initialize limit\n",
    "                ax.autoscale()  # reset scale\n",
    "                \n",
    "            # reset y-axis label\n",
    "            self.axes[1].set_ylabel('Agent')\n",
    "            self.axes[2].set_ylabel('V')\n",
    "            self.axes[3].set_ylabel('P')\n",
    "            self.axes[4].set_ylabel('PV')\n",
    "            for ax in _axes:\n",
    "                ax.set_xlim(xlim)       # reset limit in x-axis\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                # set equal width horizontally\n",
    "                ax.ticklabel_format(useOffset=False)\n",
    "                \n",
    "    def save(self, path):\n",
    "        with lock:\n",
    "            self.fig.savefig(path)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CNNNetwork:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - input_dim\n",
    "    - output_dim\n",
    "    - lr : learning rate\n",
    "    - activation : activation layer function ('linear', 'sigmoid', 'tanh', 'softmax')\n",
    "    - loss : loss function for networks\n",
    "    - model : final neural network model\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - predict() : calculate value of actions\n",
    "    - train_on_batch() : generate batch data for training\n",
    "    - save_model()\n",
    "    - load_model()\n",
    "    - get_share_network() : generate network head according to the networks\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_dim=0, output_dim=0, num_steps=5, lr=0.01,\n",
    "                 activation='sigmoid', loss='mse'):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.activation = activation\n",
    "        self.loss = loss \n",
    "        \n",
    "        # data shape for CNN network\n",
    "        # CNN has 3 dimensional shape, so we set input shape as (num_steps, input_dim)\n",
    "        inp = (self.num_steps, input_dim)\n",
    "        \n",
    "        self.head = self.get_network_head(inp, self.output_dim)\n",
    "        \n",
    "        # generate network model for head with activation function\n",
    "        self.model = nn.Sequential(self.head)\n",
    "        if self.activation == 'linear':\n",
    "            pass\n",
    "        elif self.activation == 'relu':\n",
    "            self.model.add_module('activation', nn.ReLU())\n",
    "        elif self.activation == 'leaky_relu':\n",
    "            self.model.add_module('activation', nn.LeakyReLU())\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.model.add_module('activation', nn.Sigmoid())\n",
    "        elif self.activation == 'tanh':\n",
    "            self.model.add_module('activation', nn.Tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            self.model.add_module('activation', nn.Softmax(dim=1))\n",
    "        self.model.apply(CNNNetwork.init_weights)\n",
    "        self.model.to(device)\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = None\n",
    "        if loss == 'mse':\n",
    "            self.criterion = nn.MSELoss()\n",
    "        elif loss == 'binary_crossentropy':\n",
    "            self.criterion = nn.BCELoss()\n",
    "            \n",
    "    def predict(self, sample):\n",
    "        # return prediction of buying, selling and holding on given samples\n",
    "        sample = np.array(sample).reshape((1, self.num_steps, self.input_dim))\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(sample).float().to(device)\n",
    "            pred = self.model(x).detach().cpu().numpy()\n",
    "            pred = pred.flatten()\n",
    "        return pred\n",
    "    \n",
    "    def train_on_batch(self, x, y):\n",
    "        x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "        loss = 0\n",
    "        self.model.train()\n",
    "        _x = torch.from_numpy(x).float().to(device)\n",
    "        _y = torch.from_numpy(y).float().to(device)\n",
    "        y_pred = self.model(_x)\n",
    "        _loss = self.criterion(y_pred, _y)\n",
    "        self.optimizer.zero_grad()\n",
    "        _loss.backward()\n",
    "        self.optimizer.step()\n",
    "        loss += _loss.item()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @staticmethod \n",
    "    def get_network_head(inp, output_dim):\n",
    "        kernel_size = 2\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            torch.nn.Conv1d(inp[0], 1, kernel_size),\n",
    "            torch.nn.BatchNorm1d(1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(inp[1] - (kernel_size - 1), 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim)\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        # initialize weights as weighted normal distribution\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv1d):\n",
    "            nn.init.normal_(m.weight, std=0.01)\n",
    "        \n",
    "    def save_model(self, model_path):\n",
    "        if model_path is not None and self.model is not None:\n",
    "            torch.save(self.model, model_path)\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        if model_path is not None:\n",
    "            self.model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method\n",
    "\n",
    "##### Experience buffer\n",
    "\n",
    "- We get transition data $(s,a,r,s^\\prime)$, save into buffer, and train with uniform random sampling data from buffer.\n",
    "\n",
    "- Q-learning is off-poilcy learning.\n",
    "\n",
    "#### Target netwrok\n",
    "\n",
    "- We set separate target network and update it periodically.\n",
    "\n",
    "    - $\\theta_i$ : training parameter for $i$th iteration\n",
    "\n",
    "    - $\\theta^-_i$ : target calculation network for $i$th iteration\n",
    "\n",
    "    - $U(D)$ : replay memory of transitions $\\rightarrow \\pi_0, \\cdots, \\pi_i$ dataset.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "$$L_i(\\theta_i)=E_{s,a,r,s^\\prime}\\left[(r+\\gamma\\max_{a^\\prime}Q(s^\\prime, a^\\prime, Q^-_i)-Q(s,a;\\theta_i))^2\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture\n",
    "\n",
    "- To reudce compuration complexity, neural network get states and return all action-values.\n",
    "\n",
    "<img src='./image/3-s2.0-B9780323857871000117-f06-02-9780323857871.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReplayMemory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, replay_capacity=480, replay_init_ratio=0.3):\n",
    "        self.replay_capacity = replay_capacity\n",
    "        self.replay_init_ratio = replay_init_ratio\n",
    "        self.buffer =deque([], maxlen=self.replay_capacity)\n",
    "        \n",
    "    def getsize(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def append(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "    def sample(self, size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        if buffer_size >= size:\n",
    "            samples = random.sample(self.buffer, size)\n",
    "        else:\n",
    "            assert False, f\"Buffer size ({buffer_size}) is smaller than the sample size ({size})\"\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ReplayMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([], maxlen=480)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN learner class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqn_learner.py\n",
    "from torch import nn\n",
    "import os\n",
    "import logging\n",
    "import collections\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "LOGGER_NAME = 'rltrader'\n",
    "logger = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "class DQNLearner:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - stock_code\n",
    "    - env : environment\n",
    "    - agent : agent\n",
    "    - value_network : value network for a model if needed\n",
    "    Functions\n",
    "    --------\n",
    "    - init_value_network() : function for creatinf value network\n",
    "    - build_sample() : get samples from env instances\n",
    "    - get_batch() : create batch training data\n",
    "    - update_network() : train value network\n",
    "    - fit() : reques train value network\n",
    "    - run() : perform reinforcement learning\n",
    "    - save_models() : save value network\n",
    "    '''\n",
    "    def __init__(self, stock_code=None, fro=None, to=None,\n",
    "                 min_trading_price=100, max_trading_price=10000,\n",
    "                 num_steps=5, lr=0.0005,\n",
    "                 discount_factor=0.9, num_epochs=1000,\n",
    "                 balance=100000, eps_init=1,\n",
    "                 value_network=None, value_network_path=None,\n",
    "                 output_path='', reuse_models=False, gen_output=True):\n",
    "        self.stock_code = stock_code\n",
    "        _, self.stock_data, self.training_data = load_data(stock_code=self.stock_code, fro=fro, to=to)\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.num_epochs = num_epochs\n",
    "        self.eps_init = eps_init\n",
    "        \n",
    "        self.env = Environment(self.stock_data) \n",
    "        self.agent = Agent(self.env, balance, min_trading_price, max_trading_price)\n",
    "        \n",
    "        self.sample = None\n",
    "        self.training_data_idx = -1\n",
    "        \n",
    "        # vector size = training vector size + agent state size\n",
    "        self.num_features = self.agent.STATE_DIM\n",
    "        if self.training_data is not None:\n",
    "            self.num_features += self.training_data.shape[1]\n",
    "            \n",
    "            \n",
    "        # set network\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.value_network = value_network\n",
    "        self.reuse_models = reuse_models\n",
    "\n",
    "        # visualization module\n",
    "        self.visualizer = Visualizer()\n",
    "        \n",
    "        # memeory\n",
    "        self.memory_sample = []     # training data sample\n",
    "        self.memory_action = []     # actions taken\n",
    "        self.memory_reward = []     # reward obtained\n",
    "        self.memory_value = []      # prediction value for action\n",
    "        # self.memory_policy = []     # prediction probability for action\n",
    "        self.memory_pv = []         # portfolio value\n",
    "        self.memory_num_stocks = [] # number of stocks\n",
    "        self.memory_exp_idx = []    # exploration index\n",
    "        \n",
    "        # exploration epoch info\n",
    "        self.loss = 0               # loss during epoch\n",
    "        self.itr_cnt = 0            # number of iterations with profit\n",
    "        self.exploration_cnt = 0    # count of exploration\n",
    "        self.batch_size = 0         # number of training\n",
    "        \n",
    "        # log output\n",
    "        self.output_path = output_path\n",
    "        self.gen_output = gen_output    \n",
    "        \n",
    "        self.value_network_path = value_network_path\n",
    "        # create value network\n",
    "        self.init_value_network()\n",
    "        \n",
    "    def init_value_network(self, activation='linear', loss='mse', kernel_size=2):\n",
    "        self.value_network = CNNNetwork(\n",
    "            input_dim=self.num_features,\n",
    "            output_dim=self.agent.NUM_ACTIONS,\n",
    "            lr=self.lr, num_steps=self.num_steps,\n",
    "            # shared_network=shared_network,\n",
    "            activation=activation, loss=loss\n",
    "        )\n",
    "        \n",
    "        if self.reuse_models and os.path.exists(self.value_network_path):\n",
    "            self.value_network.load_model(model_path=self.value_network_path)\n",
    "            \n",
    "        \n",
    "    def reset(self):\n",
    "        self.sample = None\n",
    "        self.training_data_idx = -1\n",
    "        \n",
    "        # reset environment\n",
    "        self.env.reset()\n",
    "        \n",
    "        # reset agent\n",
    "        self.agent.reset()\n",
    "        \n",
    "        # reset visualizer\n",
    "        self.visualizer.clear([0, len(self.stock_data)])\n",
    "        \n",
    "        # reset memories\n",
    "        self.memory_sample = []\n",
    "        self.memory_action = []\n",
    "        self.memory_reward = []\n",
    "        self.memory_value = []\n",
    "        self.memory_policy = []\n",
    "        self.memory_pv = []\n",
    "        self.memory_num_stocks = []\n",
    "        self.memory_exp_idx = []\n",
    "        \n",
    "        # reset epoch info\n",
    "        self.loss = 0.\n",
    "        self.itr_cnt = 0\n",
    "        self.exploration_cnt = 0\n",
    "        self.batch_size = 0\n",
    "        \n",
    "    def build_sample(self):\n",
    "        # get next index data\n",
    "        self.env.observe()\n",
    "        # 47 samples + 3 agent states = 50 features\n",
    "        if len(self.training_data) > self.training_data_idx + 1:\n",
    "            self.training_data_idx += 1\n",
    "            self.sample = self.training_data[self.training_data_idx].tolist()\n",
    "            self.sample.extend(self.agent.get_states())\n",
    "            return self.sample\n",
    "        print(self.sample)\n",
    "        return None    \n",
    "    \n",
    "    def get_batch(self):\n",
    "        memory = zip(\n",
    "            reversed(self.memory_sample),\n",
    "            reversed(self.memory_action),\n",
    "            reversed(self.memory_value),\n",
    "            reversed(self.memory_reward),\n",
    "        )\n",
    "        \n",
    "        # prepare sample array 'x' and label array 'y_value' with 0 values\n",
    "        x = np.zeros((len(self.memory_sample), self.num_steps, self.num_features))\n",
    "        y_value = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        value_max_next = 0\n",
    "        \n",
    "        # we can handle from the last data bacause of reversed memory\n",
    "        for i, (sample, action, value, reward) in enumerate(memory):\n",
    "            # sample\n",
    "            x[i] = sample\n",
    "            ## reward for training\n",
    "            ## memory_reward[-1] : last profit/loss in the batch data\n",
    "            ## reward : profit/loss at the time of action\n",
    "            r = self.memory_reward[-1] - reward\n",
    "            # value network output\n",
    "            y_value[i] = value\n",
    "            # state-action value\n",
    "            y_value[i, action] = r + self.discount_factor * value_max_next\n",
    "            # save the maximum next state value\n",
    "            value_max_next = value.max()\n",
    "        \n",
    "        # return sample array, value network label\n",
    "        return x, y_value\n",
    "    \n",
    "    \n",
    "    # after generate batch data, call train_on_batch() medho to train value network and policy network\n",
    "    # value network : DQNLearner, ActorCriticLearner, A2CLearner\n",
    "    # policy network : PolicyGradientLearner, ActorCriticLearner, A2CLearner\n",
    "    # loss value after training is saves as instance. in case of training value and policy network return sum of both loss\n",
    "    def fit(self):\n",
    "        # generate batch data\n",
    "        x, y_value = self.get_batch()\n",
    "        # initialize loss\n",
    "        self.loss = None\n",
    "        if len(x) > 0:\n",
    "            loss = 0\n",
    "            if y_value is not None:\n",
    "                # update value network\n",
    "                loss += self.value_network.train_on_batch(x, y_value)\n",
    "            self.loss = loss\n",
    "            \n",
    "    # visualize one complete epoch\n",
    "    # in case of LSTM, CNN agent, the number of agent's actions, num_stocks, output of value network, output of policy network and portfolio value is less than daily price data by (num_steps -1). So we fill (num_steps -1) meaningless data \n",
    "    def visualize(self, epoch_str, num_epochs, eps):\n",
    "        self.memory_action = [self.agent.ACTION_HOLD] * (self.num_steps - 1) + self.memory_action\n",
    "        self.memory_num_stocks = [0] * (self.num_steps - 1) + self.memory_num_stocks\n",
    "        if self.value_network is not None:\n",
    "            self.memory_value = [np.array([np.nan] * len(self.agent.ACTIONS))] * (self.num_steps - 1) + self.memory_value\n",
    "        self.memory_pv = [self.agent.initial_balance] * (self.num_steps - 1) + self.memory_pv\n",
    "        self.visualizer.plot(\n",
    "            epoch_str=epoch_str, num_epochs=num_epochs,\n",
    "            eps=eps, action_list=self.agent.ACTIONS,\n",
    "            actions=self.memory_action,\n",
    "            num_stocks=self.memory_num_stocks,\n",
    "            outvals_value=self.memory_value,\n",
    "            outvals_policy=self.memory_policy,\n",
    "            exps=self.memory_exp_idx,\n",
    "            initial_balance=self.agent.initial_balance,\n",
    "            pvs=self.memory_pv,\n",
    "        )\n",
    "        self.visualizer.save(os.path.join(self.epoch_summary_dir, f'epoch_summary_{epoch_str}.png'))\n",
    "        \n",
    "        \n",
    "    def run(self, learning=True):\n",
    "        '''\n",
    "        Arguments\n",
    "        ---------\n",
    "        - learning : boolean if learning will be done or not\n",
    "            - True : after training, build value and policy network\n",
    "            - False: simulation with pretrined model\n",
    "        '''\n",
    "        info = (\n",
    "            f'[{self.stock_code}] RL:dqn NET:cnn'\n",
    "            f' LR:{self.lr} DF:{self.discount_factor}'\n",
    "        )\n",
    "        \n",
    "        logger.debug(info)\n",
    "        \n",
    "        # start time\n",
    "        time_start = time.time()\n",
    "        \n",
    "        # prepare visualization\n",
    "        self.visualizer.prepare(self.env.stock_data, info)\n",
    "        \n",
    "        # prepare folders foe saving results\n",
    "        if self.gen_output:\n",
    "            self.epoch_summary_dir = os.path.join(self.output_path, f'epoch_summary_{self.stock_code}')\n",
    "            if not os.path.isdir(self.epoch_summary_dir):\n",
    "                os.makedirs(self.epoch_summary_dir)\n",
    "            else:\n",
    "                for f in os.listdir(self.epoch_summary_dir):\n",
    "                    os.remove(os.path.join(self.epoch_summary_dir, f))\n",
    "                    \n",
    "        # reset info about training\n",
    "        # save the most highest portfolio value at max_portfolio_value variable\n",
    "        max_portfolio_value = 0\n",
    "        # save the count of epochs with profit\n",
    "        epoch_win_cnt = 0\n",
    "        \n",
    "        # iterate epochs\n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            # start time of an epoch\n",
    "            time_start_epoch = time.time()\n",
    "            \n",
    "            # queue for making step samples\n",
    "            q_sample = collections.deque(maxlen=self.num_steps)\n",
    "            \n",
    "            # reset environment, networks, visualizer and memories\n",
    "            self.reset()\n",
    "            \n",
    "            # decaying exploration rate\n",
    "            if learning:\n",
    "                eps = self.eps_init * (1 - (epoch / (self.num_epochs - 1)))\n",
    "            else:\n",
    "                eps = self.eps_init\n",
    "                \n",
    "            for i in tqdm(range(len(self.training_data)), leave=False):\n",
    "                # create samples\n",
    "                next_sample = self.build_sample()\n",
    "                if next_sample is None:\n",
    "                    break\n",
    "                \n",
    "                # save samples until its size becomes as num_steps\n",
    "                q_sample.append(next_sample)\n",
    "                if len(q_sample) < self.num_steps:\n",
    "                    continue\n",
    "                \n",
    "                # prediction of value and policyn entwork\n",
    "                pred_value = None\n",
    "                # get predicted value of actions\n",
    "                if self.value_network is not None:\n",
    "                    pred_value = self.value_network.predict(list(q_sample))\n",
    "                    \n",
    "                # make decisions based on predicted value and probabilities\n",
    "                # decide actions based on based on networks or exploration\n",
    "                # decide actions randomly with epsilon probability or according to network output with (1 - epsilon)\n",
    "                # policy network output is the probabilities that selling or buying increase portfolio value. if output for buying is larger than that for selling, then buy the stock. Otherwise, sell it.\n",
    "                # if there is no output of policy network, select the action with the hightes output of value network.\n",
    "                action, confidence, exploration = self.agent.decide_action(pred_value=pred_value, eps=eps)\n",
    "                \n",
    "                # get rewards from action\n",
    "                reward = self.agent.step(action, confidence)\n",
    "                \n",
    "                # save action and the results in the memory\n",
    "                self.memory_sample.append(list(q_sample))\n",
    "                self.memory_action.append(action)\n",
    "                self.memory_reward.append(reward)\n",
    "                if self.value_network is not None:\n",
    "                    self.memory_value.append(pred_value)\n",
    "                self.memory_pv.append(self.agent.portfolio_value)\n",
    "                self.memory_num_stocks.append(self.agent.num_stocks)\n",
    "                if exploration:\n",
    "                    self.memory_exp_idx.append(self.training_data_idx)\n",
    "                    \n",
    "                # update iteration info\n",
    "                self.batch_size += 1\n",
    "                self.itr_cnt += 1\n",
    "                self.exploration_cnt +=1 if exploration else 0\n",
    "                \n",
    "            # training network after completing an epoch\n",
    "            if learning:\n",
    "                self.fit()\n",
    "            \n",
    "            # log about an epoch info\n",
    "            # check the length of epoch number string\n",
    "            num_epochs_digit = len(str(self.num_epochs))\n",
    "            # fill '0' as same size as the length of number of epochs\n",
    "            epoch_str = str(epoch + 1).rjust(num_epochs_digit, '0')\n",
    "            time_end_epoch = time.time()\n",
    "            # save time of an epoch\n",
    "            elapsed_time_epoch = time_end_epoch - time_start_epoch\n",
    "            logger.debug(f'[{self.stock_code}][Epoch {epoch_str}]'\n",
    "                         f'Epsilon:{eps:.4f} #Expl.:{self.exploration_cnt}/{self.itr_cnt} '\n",
    "                         f'#Buy:{self.agent.num_buy} #Sell:{self.agent.num_sell} #Hold:{self.agent.num_hold} '\n",
    "                         f'#Stocks:{self.agent.num_stocks} PV:{self.agent.portfolio_value:,.0f} '\n",
    "                         f'Loss:{self.loss:.6f} ET:{elapsed_time_epoch:.4f}')\n",
    "            \n",
    "            # visualize epoch information\n",
    "            if self.gen_output:\n",
    "                if self.num_epochs == 1 or (epoch + 1) % max(int(self.num_epochs / 100), 1) == 0:\n",
    "                    self.visualize(epoch_str, self.num_epochs, eps)\n",
    "            \n",
    "            # update training info\n",
    "            max_portfolio_value = max(\n",
    "                max_portfolio_value, self.agent.portfolio_value\n",
    "            )\n",
    "            if self.agent.portfolio_value > self.agent.initial_balance:\n",
    "                epoch_win_cnt += 1\n",
    "             \n",
    "        # end time\n",
    "        time_end = time.time()\n",
    "        elapsed_time = time_end - time_start\n",
    "        \n",
    "        # log about training\n",
    "        logger.debug(f'[{self.stock_code} Elapsed Time:{elapsed_time:.4f}]'\n",
    "                    f'Max PV:{max_portfolio_value:,.0f} #Win:{epoch_win_cnt}')\n",
    "        \n",
    "    def save_models(self):\n",
    "        if self.value_network is not None and self.value_network_path is not None:\n",
    "            self.value_network.save_model(self.value_network_path)\n",
    "            \n",
    "    # wihtou training, just predict actions based on samples\n",
    "    def predict(self):\n",
    "        # initiate an agent\n",
    "        self.agent.reset()\n",
    "        \n",
    "        # queue for step samples\n",
    "        q_sample = collections.deque(maxlen=self.num_steps)\n",
    "        \n",
    "        result = []\n",
    "        while True:\n",
    "            # create samples\n",
    "            next_sample = self.build_sample()\n",
    "            if next_sample is None:\n",
    "                break\n",
    "            \n",
    "            # save samples as many as num_steps\n",
    "            q_sample.append(next_sample)\n",
    "            if len(q_sample) < self.num_steps:\n",
    "                continue\n",
    "            \n",
    "            # prediction based on value and policy network\n",
    "            pred_value = None\n",
    "            pred_policy = None\n",
    "            if self.value_network is not None:\n",
    "                pred_value = self.value_network.predict(list(q_sample)).tolist()\n",
    "                \n",
    "            # decide action based on the network\n",
    "            result.append((self.environment.step[0]. pred_value, pred_policy))\n",
    "            \n",
    "        if self.gen_output:\n",
    "            with open(os.path.join(self.output_path, f'pred_{self.stock_code}.json'), 'w') as f:\n",
    "                print(json.dumps(result), file=f)\n",
    "                \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dqn_learner.py\n",
    "\n",
    "# import torch\n",
    "# from torch import nn \n",
    "\n",
    "# class DQNLearner: \n",
    "    \n",
    "#     def __init__(self, \n",
    "#                  env, agent,\n",
    "#                  stock_code=None, fro='2020-01-01', to='2022-12-31',\n",
    "#                  stock_data=None, training_data=None,\n",
    "#                  discount_factor=0.8, num_epochs=1000, batch_size=60, replay_init_ratio=0.3, replacy_capacity=480,\n",
    "#                  num_steps=10, lr=0.005, value_network=None, reuse_models=True, \n",
    "#                  output_path='', gen_output=True):\n",
    "        \n",
    "#         # data, environemnt and agent\n",
    "#         self.stock_code = stock_code\n",
    "#         self.stock_data = stock_data\n",
    "#         self.training_data = training_data\n",
    "#         # _, self.stock_data, self.training_data = load_data(stock_code=self.stock_code, fro=fro, to=to)\n",
    "        \n",
    "#         self.env = env\n",
    "#         self.agent = agent\n",
    "        \n",
    "        \n",
    "#         # reinforcement learning parameters\n",
    "#         self.discount_factor = discount_factor\n",
    "#         self.num_epochs = num_epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.replay_capacity = replacy_capacity\n",
    "#         self.replay_init_ratio = replay_init_ratio \n",
    "        \n",
    "#         #  eps_init=1, eps_final=0.05, eps_decrease_step=1000\n",
    "#         # self.eps_init = eps_init \n",
    "#         # self.eps_final = eps_final \n",
    "#         # self.eps_decrease_step = eps_decrease_step\n",
    "        \n",
    "#         # network\n",
    "#         self.lr = lr\n",
    "#         self.num_steps = num_steps\n",
    "#         self.value_network = value_network\n",
    "#         self.reuse_models = reuse_models \n",
    "#         self.input_dim = int(self.num_steps) * int(self.training_data.shape[1])\n",
    "#         kernel_size = 2\n",
    "#         self.network = nn.Sequential(\n",
    "#             nn.BatchNorm2d(self.input_dim),\n",
    "#             nn.Conv2d(self.input_dim, 1, kernel_size),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(self.input_dim - (kernel_size - 1), 128),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(32, self.agent.NUM_ACTIONS)\n",
    "#         )\n",
    "#         self.target_network = nn.Sequential(\n",
    "#             nn.BatchNorm2d(self.input_dim),\n",
    "#             nn.Conv2d(self.input_dim, 1, kernel_size),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(self.input_dim - (kernel_size - 1), 128),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.Dropout(p=0.1),\n",
    "#             nn.Linear(32, self.agent.NUM_ACTIONS)\n",
    "#         )   \n",
    "        \n",
    "#         # We do not train target_network\n",
    "#         for param in self.target_network.parameters():\n",
    "#             param.requires_grad = False    \n",
    "        \n",
    "#         # memory\n",
    "#         self.replay_memory = ReplayMemory()\n",
    "#         self.memory_sample = []     # training data sample\n",
    "#         self.memory_action = []     # actions taken\n",
    "#         self.memory_reward = []     # reward obtained\n",
    "#         self.memory_value = []      # prediction value for action\n",
    "#         self.memory_pv = []         # portfolio value\n",
    "#         self.memory_num_stocks = [] # number of stocks\n",
    "#         self.memory_exp_idx = []    # exploration index\n",
    "        \n",
    "#         # exploration epoch info\n",
    "#         self.loss = 0               # loss during epoch\n",
    "#         self.itr_cnt = 0            # number of iterations with profit\n",
    "#         self.exploration_cnt = 0    # count of exploration\n",
    "#         self.batch_size = 0         # number of training\n",
    "        \n",
    "#         # log path\n",
    "#         self.output_path = output_path\n",
    "#         self.gen_output = gen_output\n",
    "        \n",
    "#     def update_target_network(self):\n",
    "#         self.target_network.load_state_dict(self.network.state_dict())\n",
    "        \n",
    "#     def set_optimizer(self):\n",
    "#         self.optimizer = torch.optim.NAdam(\n",
    "#             params=self.network.parameters(),\n",
    "#             lr=self.lr,\n",
    "#             weight_decay=1e-3\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         Qs = self.network(x)\n",
    "#         return Qs\n",
    "    \n",
    "#     def forward_target_network(self, x):\n",
    "#         Qs = self.target_network(x)\n",
    "#         return Qs\n",
    "    \n",
    "#     def get_argmax_action(self, x):\n",
    "#         # transform torch tensor with two dimentional matrix\n",
    "#         s = torch.from_numpy(x).reshape(1, -1).float()\n",
    "#         Qs = self.forward(s)\n",
    "#         # get item(integer) in argmax tensor\n",
    "#         argmax_action = Qs.argmax(dim=-1).item()\n",
    "#         return argmax_action\n",
    "    \n",
    "#     def train(self):\n",
    "#         print(self.replay_memory.getsize())\n",
    "#         transitions = self.replay_memory.sample(self.batch_size)\n",
    "#         states, actions, rewards, next_states, dones = zip(*transitions)\n",
    "        \n",
    "#         states_array = np.stack(states, axis=0)                     # (n_batch, states)\n",
    "#         actions_array = np.stack(actions, axis=0, dtype=np.int64)   # (n_batch)\n",
    "#         rewards_array = np.stack(rewards, axis=0)                   # (n_batch)\n",
    "#         next_states_array = np.stack(next_states, axis=0)           # (n_batch, states)\n",
    "#         dones_array = np.stack(dones, axis=0)                       # (n_batch)\n",
    "        \n",
    "#         states_tensor = torch.from_numpy(states_array).float()\n",
    "#         actions_tensor = torch.from_numpy(actions_array)\n",
    "#         rewards_tensor = torch.from_numpy(rewards_array).float()\n",
    "#         next_states_tensor = torch.from_numpy(next_states_array).float()\n",
    "#         dones_tensor = torch.from_numpy(dones_array).float()\n",
    "        \n",
    "#         Qs = self.forward(states_tensor)\n",
    "#         next_Qs = self.forward_target_network(next_states_tensor)\n",
    "        \n",
    "#         chosen_Q = Qs.gather(dim=-1, index=actions_tensor.reshape(-1, 1)).reshape(-1)   # (n_batch, 1) -> (n_batch)\n",
    "#         target_Q = rewards_tensor + (1 - dones_tensor) * self.discount_factor * next_Qs.max(dim=-1).values\n",
    "        \n",
    "#         # loss function\n",
    "#         criterion = nn.SmoothL1Loss()\n",
    "#         loss = criterion(chosen_Q, target_Q)\n",
    "        \n",
    "#         # update by gradient descent\n",
    "#         self.optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         self.optimizer.step()\n",
    "        \n",
    "#         return loss.item()    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2018-01-01' AND '2023-12-31' \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "dqn = DQNLearner(stock_code=stock_code, fro='2018-01-01', to='2023-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42.38750076293945,\n",
       " 42.622501373291016,\n",
       " 43.14250183105469,\n",
       " 42.73749923706055,\n",
       " 127594400.0,\n",
       " 42.3385009765625,\n",
       " 175292480.0,\n",
       " 0.009424005368516047,\n",
       " -0.2721056830275891,\n",
       " -0.008189493544760023,\n",
       " 0.0026611291070369274,\n",
       " -0.002690795339513195,\n",
       " 0.00947651596897686,\n",
       " 0.010940217492328647,\n",
       " -0.10466855845311374,\n",
       " 43.52825088500977,\n",
       " 170264920.0,\n",
       " -0.018166400713830202,\n",
       " -0.25061251607201296,\n",
       " 44.43225040435791,\n",
       " 173363500.0,\n",
       " -0.03814236622890343,\n",
       " -0.26400655270573103,\n",
       " 51.03562507629395,\n",
       " 158317206.66666666,\n",
       " -0.16259477231499375,\n",
       " -0.1940585443207878,\n",
       " 51.0888960202535,\n",
       " 133001283.33333333,\n",
       " -0.16346794379510873,\n",
       " -0.04065286588086803,\n",
       " 47.61911471684774,\n",
       " 133074575.0,\n",
       " -0.10251378062809866,\n",
       " -0.04118123240295902,\n",
       " 48.18011567132509,\n",
       " 40.68438513739073,\n",
       " 0.27390447006800017,\n",
       " 0.16870022260225612,\n",
       " -2.821814528255821,\n",
       " -2.0390696683620253,\n",
       " -0.7827448598937958,\n",
       " 0.5614399715311799,\n",
       " 35.956551757838014,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.build_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "def run_trader(mode='train', \n",
    "               stock_name=None, stock_code=None, fro='2018-01-01', to='2023-12-31',\n",
    "               lr=0.01, discount_factor=0.9,\n",
    "               initial_balance=1000000, min_trading_price=1, max_trading_price=10000,\n",
    "               num_epochs=1000, num_steps=20):\n",
    "    \n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.path.pardir))\n",
    "    # os.environ['RLTRADER_BASE'] = 'C:\\project\\github\\projects\\trader'\n",
    "    \n",
    "    ''' \n",
    "    Arguments\n",
    "    ----------\n",
    "    mode : 'train', 'test', 'update', 'predict\n",
    "    '''\n",
    "    \n",
    "    # learner's parameter\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    output_name = f'{mode}_{stock_name}_dqn_cnn_{now}'\n",
    "    learning = mode in ['train', 'update']\n",
    "    \n",
    "    # use model flag\n",
    "    reuse_models = mode in ['test', 'update', 'predict']\n",
    "    \n",
    "    # value network file\n",
    "    value_network_name = f'{stock_name}_dqn_cnn_value.mdl'\n",
    "    eps_init = 1 if mode in ['train', 'update'] else 0\n",
    "    num_epochs = num_epochs if mode in ['train', 'update'] else 0\n",
    "    \n",
    "    # output path\n",
    "    output_path = os.path.join(BASE_DIR, 'trader', 'output', output_name)\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    # log parameters\n",
    "    params = {\n",
    "        'mode': mode,\n",
    "        'stock_names': stock_name,\n",
    "        'rl_method': 'dqn',\n",
    "        'net': 'cnn',\n",
    "        'start_date': fro,\n",
    "        'end_date': to,\n",
    "        'lr': lr,\n",
    "        'discount_factor': discount_factor,\n",
    "        'initial_balance': initial_balance,\n",
    "        'stock_codes': stock_code,\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_path, 'params.json'), 'w') as f:\n",
    "        f.write(str(params))\n",
    "        \n",
    "    # model_path\n",
    "    value_network_path = os.path.join(BASE_DIR, 'models', value_network_name)\n",
    "    \n",
    "    # setting for logging\n",
    "    # log level DEBUG < INFO < WARNING < CRITICAL. more than DEBUG\n",
    "    log_path = os.path.join(output_path, f'{output_path}.log')\n",
    "    if os.path.exists(log_path):\n",
    "        os.remove(log_path)\n",
    "    logging.basicConfig(format='%(message)s')\n",
    "    logger = logging.getLogger(LOGGER_NAME)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.propagate = False\n",
    "    stream_handler = logging.StreamHandler(sys.stdout)\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    file_handler = logging.FileHandler(filename=log_path, encoding='utf-8')\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "        \n",
    "    # minimum and maximum trading price policy\n",
    "    min_trading_price = min_trading_price\n",
    "    max_trading_price = max_trading_price\n",
    "        \n",
    "        \n",
    "    # start reinforcement learning\n",
    "    learner = DQNLearner(\n",
    "        stock_code=stock_code, fro=fro, to= to,\n",
    "        min_trading_price=min_trading_price, max_trading_price=max_trading_price,\n",
    "        num_steps=num_steps, lr=lr, discount_factor=discount_factor, num_epochs=num_epochs,\n",
    "        balance=initial_balance, eps_init=eps_init, \n",
    "        value_network_path=value_network_path,\n",
    "        output_path=output_path, reuse_models=reuse_models\n",
    "    )\n",
    "        \n",
    "    if mode in ['train', 'test', 'update']:\n",
    "        learner.run(learning=learning)\n",
    "        \n",
    "        if mode in ['train', 'update']:\n",
    "            learner.save_models()\n",
    "    \n",
    "    elif mode == 'predict':\n",
    "        learner.predict()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2018-01-01' AND '2023-12-31' \n",
      "                    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [00:28<19:44,  1.21s/it] C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_19628\\415254748.py:167: UserWarning: The figure layout has changed to tight\n",
      "  self.fig.tight_layout()\n",
      "100%|██████████| 1000/1000 [23:40<00:00,  1.42s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_trader(stock_name='Apple', stock_code='AAPL', num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset replay buffer\n",
    "# init_replay_buffer_size = int(learner.replay_memory.replay_capacity * learner.replay_memory.replay_init_ratio)\n",
    "# s = agent.reset()\n",
    "# step_count = 0\n",
    "\n",
    "# # create initial replay buffer\n",
    "# for _ in range(learner.replay_memory.replay_capacity):\n",
    "#     a = np.random.choice(agent.NUM_ACTIONS)     # uniform random action\n",
    "#     confidence = np.random.random()\n",
    "#     s_next, r, done, info = agent.step(a, confidence=confidence)\n",
    "#     step_count += 1\n",
    "#     s = s_next\n",
    "#     if done:\n",
    "#         env.reset()\n",
    "#         agent.reset()\n",
    "#         step_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train agent\n",
    "# train_env_steps = 20 * 12 * 3\n",
    "# target_update_period = 20 * 3\n",
    "# env.reset()\n",
    "# s = agent.reset()\n",
    "# step_count = 0\n",
    "# for step_train in range(train_env_steps):\n",
    "#     eps = get_eps(step=step_train)\n",
    "#     is_random_action = np.random.choice(2, p=[1 - eps, eps])\n",
    "#     if is_random_action:\n",
    "#         a = np.random.choice(agent.NUM_ACTIONS)     # uniform random action\n",
    "#     else:\n",
    "#         a = learner.get_argmax_action(s)\n",
    "        \n",
    "#     confidence = np.random.random()\n",
    "#     s_next, r, done, info = agent.step(a, confidence)\n",
    "#     step_count += 1\n",
    "    \n",
    "#     transition = (s, a, r, s_next, done)\n",
    "#     learner.replay_memory.append(transition)\n",
    "    \n",
    "#     s = s_next\n",
    "#     if done:\n",
    "#         env.reset()\n",
    "#         s = agent.reset()\n",
    "#         step_count = 0\n",
    "        \n",
    "#     # target update period\n",
    "#     if step_train % target_update_period == 0:\n",
    "#         learner.update_target_network()\n",
    "        \n",
    "#     # train every 5 steps\n",
    "#     if step_train % 5 == 0:\n",
    "#         loss = learner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
