{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db connection\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import keyring\n",
    "import platform\n",
    "import numpy as np\n",
    "\n",
    "user = 'root'\n",
    "pw = keyring.get_password('macmini_db', user)\n",
    "host = '192.168.219.106' if platform.system() == 'Windows' else '127.0.0.1'\n",
    "port = 3306\n",
    "db = 'stock'\n",
    "\n",
    "\n",
    "# # connect DB\n",
    "# engine = create_engine(f'mysql+pymysql://{self.user}:{self.pw}@{self.host}:{self.port}/{self.db}')\n",
    "\n",
    "# con = pymysql.connect(\n",
    "#     user=user,\n",
    "#     passwd=pw,\n",
    "#     host=host,\n",
    "#     db=db,\n",
    "#     charset='utf8'\n",
    "# )\n",
    "        \n",
    "# mycursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base data\n",
    "COLUMNS_STOCK_DATA = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "COLUMNS_MARKET_DATA = [\n",
    "    'kospi', 'kosdaq', 'dow', 'snp',\n",
    "    'nikkei', 'hangseng', 'ftse', 'cac',\n",
    "    'dax', 'enronext', 'vix', \n",
    "    'shanghai',\n",
    "]\n",
    "COLUMNS_BOND_DATA = [\n",
    "    'bond_us_13w', 'bond_us_5y', 'bond_us_10y',\n",
    "    'bond_us_30y', 'bond_kr_3y'\n",
    "]\n",
    "COLUMNS_EXCHANGE_DATA = [\n",
    "    'usd_eur', 'usd_gbr', 'usd_jpy', 'usd_cnh', 'usd_kor',\n",
    "]\n",
    "COLUMNS_VALUE_DATA = [\n",
    "    'per', 'pbr', 'roe', 'dy', 'pcr', 'psr', 'marekt_cap',\n",
    "    'roa',\n",
    "]\n",
    "COLUMNS_FACTOR_DATA = [\n",
    "    'beta', 'value', 'moment', 'qaulity', 'volatility',\n",
    "]\n",
    "COLUMNS_TECH_DATA = [\n",
    "    'upperbb', 'lowerbb', 'bb_pb', 'bb_width', 'macd',\n",
    "    'rsi', 'mfi', 'ii', 'buy_strength', 'sell_strength'\n",
    "]\n",
    "COLUMNS_SECTOR_DATA = [\n",
    "    'xlk', 'xlv', 'xly', 'xlp',\n",
    "    'xle', 'xlf', 'xli', 'xlb',\n",
    "    'xlre', 'xlu',\n",
    "]\n",
    "COLUMNS_COMMODITY_DATA = [\n",
    "    'oil', 'gold',\n",
    "]\n",
    "\n",
    "# moving average data\n",
    "COLUMNS_STOCK_ROLLING_DATA = [\n",
    "    'close_ma5_ratio', 'close_ma10_ratio', 'close_ma20_ratio',\n",
    "    'close_ma60_ratio', 'close_ma120_ratio', 'close_ma240_ratio',\n",
    "    'volume_ma5_ratio', 'volume_ma10_ratio', 'volumne_ma20_ratio',\n",
    "    'volume_ma60_ratio', 'volume_ma120_ratio', 'volume_ma240_ratio',\n",
    "]\n",
    "COLUMNS_MARKET_ROLLING_DATA = [\n",
    "    'market_kospi_ma5_ratio', 'market_kospi_ma10_ratio', 'market_kospi_ma20_ratio',\n",
    "    'market_kospi_ma60_ratio', 'market_kospi_ma120_ratio', 'market_kospi_ma120_ratio',\n",
    "    'market_kosdaq_ma5_ratio', 'market_kosdaq_ma10_ratio', 'market_kosdaq_ma20_ratio',\n",
    "    'market_kosdqp_ma60_ratio', 'market_kosdaq_ma120_ratio', 'market_kosdaq_ma240_ratio',\n",
    "    'market_dow_ma5_ratio', 'market_dow_ma10_ratio', 'market_dow_ma20_ratio',\n",
    "    'market_dow_ma60_ratio', 'market_dow_ma120_ratio', 'market_dow_ma240_ratio',\n",
    "    'market_snp_ma5_ratio', 'market_snp_ma10_ratio', 'market_snp_ma20_ratio',\n",
    "    'market_snp_ma60_ratio', 'market_snp_ma120_ratio', 'market_snp_ma240_ratio',\n",
    "    'market_nikkei_ma5_ratio', 'market_nikkei_ma10_ratio', 'market_nikkei_ma20_ratio',\n",
    "    'market_nikkei_ma60_ratio', 'market_nikkei_ma120_ratio', 'market_ma240_ratio',\n",
    "    'market_hangseng_ma5_ratio', 'market_hangseng_ma10_ratio', 'market_hangseng_ma20_ratio',\n",
    "    'market_hangseng_ma60_ratio', 'market_hangseng_ma120_ratio', 'market_hangseng_ma240_ratio',\n",
    "    'market_ftse_ma5_ratio', 'market_ftse_ma10_ratio', 'market_ftse_ma20_ratio',\n",
    "    'market_ftse_ma60_ratio', 'market_ftse_ma120_ratio', 'market_ftse_ma240_ratio',\n",
    "    'market_cac_ma5_ratio', 'market_cac_ma10_ratio', 'market_cac_ma20_ratio',\n",
    "    'market_cac_ma60_ratio', 'market_cac_ma120_ratio', 'market_cac_ma240_ratio',\n",
    "    'market_dax_ma5_ratio', 'market_dax_ma10_ratio', 'market_dax_ma20_ratio',\n",
    "    'market_dax_ma60_ratio', 'market_dax_ma120_ratio', 'market_dax_ma240_ratio',\n",
    "    'market_euronext_ma5_ratio', 'market_euronext_mas10_ratio', 'market_euronext_ma20_ratio',\n",
    "    'market_euronext_ma60_ratio', 'market_euronext_ma120_ratio', 'marekt_euronext_ma240_ratio',\n",
    "    'market_vix_ma5_ratio', 'market_vix_ma10_ratio', 'market_vix_ma20_ratio',\n",
    "    'market_vix_ma60_ratio', 'market_vix_ma120_ratio', 'market_vix_ma240_raito',\n",
    "    'market_shanghai_ma5_ratio', 'market_shanghai_ma10_ratio', 'market_shanghai_ma20_ratio',\n",
    "    'market_shanghai_ma60_ratio', 'market_shanghai_ma120_ratio', 'market_shanghai_ma240_ratio',\n",
    "]\n",
    "COLUMNS_BOND_ROLLING_DATA = [\n",
    "    'bond_us_13w_ma5_ratio', 'bond_us_13w_ma10_ratio', 'bond_us_13w_ma20_ratio',\n",
    "    'bond_us_13w_ma60_ratio', 'bond_us_13w_ma120_ratio', 'bond_us_12w_ma240_ratio',\n",
    "    'bond_us_5y_ma5_ratio', 'bond_us_5y_ma10_ratio', 'bond_us_5y_ma20_ratio',\n",
    "    'bond_us_5y_ma60_ratio', 'bond_us_5y_ma120_ratio', 'bond_us_5y_ma240_ratio',\n",
    "    'bond_us_10y_ma5_ratio', 'bond_us_10y_ma10_ratio', 'bond_us_10y_ma20_ratio',\n",
    "    'bond_us_10y_ma60_ratio', 'bond_us_10y_ma120_ratio', 'bond_us_10y_ma240_ratio',\n",
    "    'bond_us_30y_ma5_ratio', 'bond_us_30y_ma10_ratio', 'bond_us_30y_ma20_ratio',\n",
    "    'bond_us_30y_ma60_ratio', 'bond_us_30y_ma120_ratio', 'bond_us_30y_ma240_ratio',\n",
    "    'bond_kr_3y_ma5_ratio', 'bond_kr_3y_ma10_ratio', 'bond_kr_3y_ma20_ratio',\n",
    "    'bond_kr_3y_ma60_ratio', 'bond_kr_3y_ma120_ratio', 'bond_kr_3y_ma240_ratio',\n",
    "]\n",
    "COLUMNS_SECTOR_ROLLING_DATA = [\n",
    "    'sector_xlk_ma5_ratio', 'sector_xlk_ma10_ratio', 'sector_xlk_ma20_ratio',\n",
    "    'sector_xlk_ma60_ratio', 'sector_xlk_ma120_ratio', 'sector_xlk_ma240_ratio',\n",
    "    'sector_xlv_ma5_ratio', 'sector_xlv_ma10_ratio', 'sector_xlv_ma20_ratio',\n",
    "    'sector_xlv_ma60_ratio', 'sector_xlv_ma120_ratio', 'sector_xlv_ma240_ratio',\n",
    "    'sector_xly_ma5_ratio', 'sector_xly_ma10_ratio', 'sector_xly_ma20_ratio',\n",
    "    'sector_xly_ma60_ratio', 'sector_xly_ma120_ratio', 'sector_xly_ma240_ratio',\n",
    "    'sector_xlp_ma5_ratio', 'sector_xlp_ma10_ratio', 'sector_xlp_ma20_ratio',\n",
    "    'sector_xlp_ma60_ratio', 'sector_xlp_ma120_ratio', 'sector_xlp_ma240_ratio',\n",
    "    'sector_xle_ma5_ratio', 'sector_xle_ma10_ratio', 'sector_xle_ma20_ratio',\n",
    "    'sector_xle_ma60_ratio', 'sector_xle_ma120_ratio', 'sector_xle_ma240_ratio',\n",
    "    'sector_xlf_ma5_ratio', 'sector_xlf_ma10_ratio', 'sector_xlf_ma20_ratio',\n",
    "    'sector_xlf_ma60_ratio', 'sector_xlf_ma120_ratio', 'sector_xlf_ma240_ratio',\n",
    "    'sector_xli_ma5_ratio', 'sector_xli_ma10_ratio', 'sector_xli_ma20_ratio',\n",
    "    'sector_xli_ma60_ratio', 'sector_xli_ma120_ratio', 'sector_xli_ma240_ratio',\n",
    "    'sector_xlb_ma5_ratio', 'sector_xlb_ma10_ratio', 'sector_xlb_ma20_ratio',\n",
    "    'sector_xlb_ma60_raito', 'sector_xlb_ma120_ratio', 'sector_xlb_ma240_ratio',\n",
    "    'sector_xlre_ma5_ratio', 'sector_xlre_ma10_ratio', 'sector_xlre_ma20_ratio',\n",
    "    'sector_xlre_ma60_ratio', 'sector_xlre_ma120_ratio', 'sector_xlre_ma240_ratio',\n",
    "    'sector_xlu_ma5_ratio', 'sector_xlu_ma10_ratio', 'sector_xlu_ma20_ratio',\n",
    "    'sector_xlu_ma60_ratio', 'sector_xlu_ma120_ratio', 'sector_xlu_ma240_ratio',\n",
    "]\n",
    "\n",
    "COLUMNS_COMMODITY_ROLLING_DATA = [\n",
    "    'commodity_oil_ma5_ratio', 'commodity_oil_ma10_ratio', 'commodiy_oil_ma20_ratio',\n",
    "    'commodity_oil_ma60_ratio', 'commodity_oil_ma120_ratio', 'commodity_oil_ma240_ratio',\n",
    "    'commodity_gold_ma5_ratio', 'commodity_gold_ma10_ratio', 'commodity_gold_ma20_ratio',\n",
    "    'commodity_gold_ma60_ratio', 'commodity_gold_ma120_ratio', 'commodity_gold_ma240_ratio',\n",
    "    \n",
    "]\n",
    "\n",
    "# ratio data\n",
    "COLUMNS_STOCK_RATIO_DATA = [\n",
    "    'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio', 'low_close_ratio',\n",
    "    'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get prices funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# get us stock price of a specific ticker\n",
    "def get_prices_from_ticker(ticker, fro=None, to=None):\n",
    "\n",
    "    # connect DB\n",
    "    engine = create_engine(f'mysql+pymysql://{user}:{pw}@{host}:{port}/{db}')\n",
    "\n",
    "    con = pymysql.connect(\n",
    "        user=user,\n",
    "        passwd=pw,\n",
    "        host=host,\n",
    "        db=db,\n",
    "        charset='utf8'\n",
    "    )\n",
    "            \n",
    "    mycursor = con.cursor()\n",
    "    \n",
    "    if fro is not None:\n",
    "        if to is not None:               \n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = {ticker}\n",
    "                    AND date BETWEEN {fro} AND {to} \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = {ticker}\n",
    "                    AND date >= {fro} \n",
    "                    \"\"\"\n",
    "    \n",
    "    else:\n",
    "        if to is not None:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = {ticker}\n",
    "                    AND date <= {to} \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    \"\"\"\n",
    "            \n",
    "    print(query)\n",
    "    prices = pd.read_sql(query, con=engine)\n",
    "    con.close()\n",
    "    engine.dispose()\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "df = get_prices_from_ticker('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.099192</td>\n",
       "      <td>469033600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>175884800.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.087117</td>\n",
       "      <td>105728000.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.089273</td>\n",
       "      <td>86441600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.091861</td>\n",
       "      <td>73449600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>172.940002</td>\n",
       "      <td>174.380005</td>\n",
       "      <td>172.050003</td>\n",
       "      <td>172.750000</td>\n",
       "      <td>172.750000</td>\n",
       "      <td>60139500.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10901</th>\n",
       "      <td>2024-03-12</td>\n",
       "      <td>173.149994</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>171.009995</td>\n",
       "      <td>173.229996</td>\n",
       "      <td>173.229996</td>\n",
       "      <td>59825400.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>172.770004</td>\n",
       "      <td>173.190002</td>\n",
       "      <td>170.759995</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>52488700.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>172.910004</td>\n",
       "      <td>174.309998</td>\n",
       "      <td>172.050003</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>72913500.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>171.169998</td>\n",
       "      <td>172.619995</td>\n",
       "      <td>170.289993</td>\n",
       "      <td>172.619995</td>\n",
       "      <td>172.619995</td>\n",
       "      <td>121664700.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10905 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        high         low        open       close      volume  \\\n",
       "0      1980-12-12    0.128348    0.128906    0.128348    0.128348    0.099192   \n",
       "1      1980-12-15    0.122210    0.122210    0.121652    0.121652    0.094017   \n",
       "2      1980-12-16    0.113281    0.113281    0.112723    0.112723    0.087117   \n",
       "3      1980-12-17    0.115513    0.116071    0.115513    0.115513    0.089273   \n",
       "4      1980-12-18    0.118862    0.119420    0.118862    0.118862    0.091861   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "10900  2024-03-11  172.940002  174.380005  172.050003  172.750000  172.750000   \n",
       "10901  2024-03-12  173.149994  174.029999  171.009995  173.229996  173.229996   \n",
       "10902  2024-03-13  172.770004  173.190002  170.759995  171.130005  171.130005   \n",
       "10903  2024-03-14  172.910004  174.309998  172.050003  173.000000  173.000000   \n",
       "10904  2024-03-15  171.169998  172.619995  170.289993  172.619995  172.619995   \n",
       "\n",
       "         adj_close ticker  \n",
       "0      469033600.0   AAPL  \n",
       "1      175884800.0   AAPL  \n",
       "2      105728000.0   AAPL  \n",
       "3       86441600.0   AAPL  \n",
       "4       73449600.0   AAPL  \n",
       "...            ...    ...  \n",
       "10900   60139500.0   AAPL  \n",
       "10901   59825400.0   AAPL  \n",
       "10902   52488700.0   AAPL  \n",
       "10903   72913500.0   AAPL  \n",
       "10904  121664700.0   AAPL  \n",
       "\n",
       "[10905 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_STOCK_RATIO_DATA = [\n",
    "    'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio', 'low_close_ratio',\n",
    "    'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "]\n",
    "\n",
    "def preprocess(data):\n",
    "    \n",
    "    # moving average\n",
    "    windows = [5, 10, 20, 60, 120, 240]\n",
    "    for window in windows:\n",
    "        data[f'close_ma{window}'] = data['close'].rolling(window).mean()\n",
    "        data[f'volume_ma{window}'] = data['volume'].rolling(window).mean()\n",
    "        data[f'close_ma{window}_ratio'] = (data['close'] - data[f'close_ma{window}']) / data[f'close_ma{window}']\n",
    "        data[f'volume_ma{window}_ratio'] = (data['volume'] - data[f'volume_ma{window}']) / data[f'volume_ma{window}']\n",
    "        data['open_close_ratio'] = (data['open'].values - data['close'].values) / data['close'].values\n",
    "        data['open_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'open_prev_close_ratio'] = (data['open'][1:].values - data['close'][:-1].values) / data['close'][:-1].values\n",
    "        data['high_close_ratio'] = (data['high'].values - data['close'].values) / data['close'].values\n",
    "        data['low_close_ratio'] = (data['low'].values - data['close'].values) / data['close'].values\n",
    "        data['close_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'close_prev_close_ratio'] = (data['close'][1:].values - data['close'][:-1].values) / data['close'][:-1].values \n",
    "        data['volume_prev_volume_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'volume_prev_volume_ratio'] = (\n",
    "            # if volume is 0, change it into non zero value exploring previous volume continuously\n",
    "            (data['volume'][1:].values - data['volume'][:-1].values) / data['volume'][:-1].replace(to_replace=0, method='ffill').replace(to_replace=0, method='bfill').values\n",
    "        )\n",
    "    \n",
    "    # Bollinger band\n",
    "    data['middle_bb'] = data['close'].rolling(20).mean()\n",
    "    data['upper_bb'] = data['middle_bb'] + 2 * data['close'].rolling(20).std()\n",
    "    data['lower_bb'] = data['middle_bb'] - 2 * data['close'].rolling(20).std()\n",
    "    data['bb_pb'] = (data['close'] - data['lower_bb']) / (data['upper_bb'] - data['lower_bb'])\n",
    "    data['bb_width'] = (data['upper_bb'] - data['lower_bb']) / data['middle_bb']\n",
    "    \n",
    "    # MACD\n",
    "    macd_short, macd_long, macd_signal = 12, 26, 9\n",
    "    data['ema_short'] = data['close'].ewm(macd_short).mean()\n",
    "    data['ema_long'] = data['close'].ewm(macd_long).mean()\n",
    "    data['macd'] = data['ema_short'] - data['ema_long']\n",
    "    data['macd_signal'] = data['macd'].ewm(macd_signal).mean()\n",
    "    data['macd_oscillator'] = data['macd'] - data['macd_signal']\n",
    "    \n",
    "    # RSI\n",
    "    data['close_change'] = data['close'].diff()\n",
    "    data['close_up'] = np.where(data['close_change']>=0, df['close_change'], 0)\n",
    "    # data['close_up'] = data['close_change'].apply(lambda x: x if x >= 0 else 0)\n",
    "    data['close_down'] = np.where(data['close_change'] < 0, df['close_change'].abs(), 0)\n",
    "    # data['close_down] = data['close_change'].apply(lambda x: -x if x < 0 else 0)\n",
    "    data['rs'] = data['close_up'].ewm(alpha=1/14, min_periods=14).mean() / data['close_down'].ewm(alpha=1/14, min_periods=14).mean()\n",
    "    data['rsi'] = 100 - (100 / (1 + data['rs']))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = df_adj[30:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.142857\n",
       "1          0.138393\n",
       "2          0.133371\n",
       "3          0.126116\n",
       "4          0.118862\n",
       "            ...    \n",
       "10870    172.750000\n",
       "10871    173.229996\n",
       "10872    171.130005\n",
       "10873    173.000000\n",
       "10874    172.619995\n",
       "Name: close, Length: 10875, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close_ma5</th>\n",
       "      <th>volume_ma5</th>\n",
       "      <th>...</th>\n",
       "      <th>ema_short</th>\n",
       "      <th>ema_long</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_oscillator</th>\n",
       "      <th>close_change</th>\n",
       "      <th>close_up</th>\n",
       "      <th>close_down</th>\n",
       "      <th>rs</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-27</td>\n",
       "      <td>0.143973</td>\n",
       "      <td>0.143973</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.110405</td>\n",
       "      <td>23699200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.144977</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142455</td>\n",
       "      <td>0.141406</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.099457</td>\n",
       "      <td>52.368628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-28</td>\n",
       "      <td>0.138951</td>\n",
       "      <td>0.138951</td>\n",
       "      <td>0.138393</td>\n",
       "      <td>0.138393</td>\n",
       "      <td>0.106955</td>\n",
       "      <td>28156800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.143638</td>\n",
       "      <td>0.111009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142116</td>\n",
       "      <td>0.141247</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.893069</td>\n",
       "      <td>47.175730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-29</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.103074</td>\n",
       "      <td>43904000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.140960</td>\n",
       "      <td>0.108939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141392</td>\n",
       "      <td>0.140838</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-0.000498</td>\n",
       "      <td>-0.005022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.727594</td>\n",
       "      <td>42.116042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-30</td>\n",
       "      <td>0.127232</td>\n",
       "      <td>0.127232</td>\n",
       "      <td>0.126116</td>\n",
       "      <td>0.126116</td>\n",
       "      <td>0.097467</td>\n",
       "      <td>46188800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.105834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140134</td>\n",
       "      <td>0.140083</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>-0.007255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.564786</td>\n",
       "      <td>36.093507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-02-02</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.091861</td>\n",
       "      <td>23766400.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.131920</td>\n",
       "      <td>0.101953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138392</td>\n",
       "      <td>0.139011</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.001407</td>\n",
       "      <td>-0.007254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.455127</td>\n",
       "      <td>31.277493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>172.940002</td>\n",
       "      <td>174.380005</td>\n",
       "      <td>172.050003</td>\n",
       "      <td>172.750000</td>\n",
       "      <td>172.750000</td>\n",
       "      <td>60139500.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>170.343997</td>\n",
       "      <td>170.343997</td>\n",
       "      <td>...</td>\n",
       "      <td>179.364069</td>\n",
       "      <td>182.966690</td>\n",
       "      <td>-3.602621</td>\n",
       "      <td>-1.591875</td>\n",
       "      <td>-2.010746</td>\n",
       "      <td>2.020004</td>\n",
       "      <td>2.020004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514266</td>\n",
       "      <td>33.961404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>2024-03-12</td>\n",
       "      <td>173.149994</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>171.009995</td>\n",
       "      <td>173.229996</td>\n",
       "      <td>173.229996</td>\n",
       "      <td>59825400.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>170.965997</td>\n",
       "      <td>170.965997</td>\n",
       "      <td>...</td>\n",
       "      <td>178.892217</td>\n",
       "      <td>182.606071</td>\n",
       "      <td>-3.713854</td>\n",
       "      <td>-1.804073</td>\n",
       "      <td>-1.909782</td>\n",
       "      <td>0.479996</td>\n",
       "      <td>0.479996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547323</td>\n",
       "      <td>35.372263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>172.770004</td>\n",
       "      <td>173.190002</td>\n",
       "      <td>170.759995</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>52488700.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>171.367999</td>\n",
       "      <td>171.367999</td>\n",
       "      <td>...</td>\n",
       "      <td>178.295124</td>\n",
       "      <td>182.181032</td>\n",
       "      <td>-3.885908</td>\n",
       "      <td>-2.012256</td>\n",
       "      <td>-1.873652</td>\n",
       "      <td>-2.099991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.099991</td>\n",
       "      <td>0.473565</td>\n",
       "      <td>32.137364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>172.910004</td>\n",
       "      <td>174.309998</td>\n",
       "      <td>172.050003</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>72913500.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>172.167999</td>\n",
       "      <td>172.167999</td>\n",
       "      <td>...</td>\n",
       "      <td>177.887807</td>\n",
       "      <td>181.840994</td>\n",
       "      <td>-3.953187</td>\n",
       "      <td>-2.206349</td>\n",
       "      <td>-1.746838</td>\n",
       "      <td>1.869995</td>\n",
       "      <td>1.869995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602798</td>\n",
       "      <td>37.609120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10874</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>171.169998</td>\n",
       "      <td>172.619995</td>\n",
       "      <td>170.289993</td>\n",
       "      <td>172.619995</td>\n",
       "      <td>172.619995</td>\n",
       "      <td>121664700.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>172.545999</td>\n",
       "      <td>172.545999</td>\n",
       "      <td>...</td>\n",
       "      <td>177.482590</td>\n",
       "      <td>181.499475</td>\n",
       "      <td>-4.016885</td>\n",
       "      <td>-2.387403</td>\n",
       "      <td>-1.629482</td>\n",
       "      <td>-0.380005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380005</td>\n",
       "      <td>0.586219</td>\n",
       "      <td>36.957002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10875 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        high         low        open       close      volume  \\\n",
       "0      1981-01-27    0.143973    0.143973    0.142857    0.142857    0.110405   \n",
       "1      1981-01-28    0.138951    0.138951    0.138393    0.138393    0.106955   \n",
       "2      1981-01-29    0.133929    0.133929    0.133371    0.133371    0.103074   \n",
       "3      1981-01-30    0.127232    0.127232    0.126116    0.126116    0.097467   \n",
       "4      1981-02-02    0.119420    0.119420    0.118862    0.118862    0.091861   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "10870  2024-03-11  172.940002  174.380005  172.050003  172.750000  172.750000   \n",
       "10871  2024-03-12  173.149994  174.029999  171.009995  173.229996  173.229996   \n",
       "10872  2024-03-13  172.770004  173.190002  170.759995  171.130005  171.130005   \n",
       "10873  2024-03-14  172.910004  174.309998  172.050003  173.000000  173.000000   \n",
       "10874  2024-03-15  171.169998  172.619995  170.289993  172.619995  172.619995   \n",
       "\n",
       "         adj_close ticker   close_ma5  volume_ma5  ...   ema_short  \\\n",
       "0       23699200.0   AAPL    0.144977    0.112044  ...    0.142455   \n",
       "1       28156800.0   AAPL    0.143638    0.111009  ...    0.142116   \n",
       "2       43904000.0   AAPL    0.140960    0.108939  ...    0.141392   \n",
       "3       46188800.0   AAPL    0.136942    0.105834  ...    0.140134   \n",
       "4       23766400.0   AAPL    0.131920    0.101953  ...    0.138392   \n",
       "...            ...    ...         ...         ...  ...         ...   \n",
       "10870   60139500.0   AAPL  170.343997  170.343997  ...  179.364069   \n",
       "10871   59825400.0   AAPL  170.965997  170.965997  ...  178.892217   \n",
       "10872   52488700.0   AAPL  171.367999  171.367999  ...  178.295124   \n",
       "10873   72913500.0   AAPL  172.167999  172.167999  ...  177.887807   \n",
       "10874  121664700.0   AAPL  172.545999  172.545999  ...  177.482590   \n",
       "\n",
       "         ema_long      macd  macd_signal  macd_oscillator  close_change  \\\n",
       "0        0.141406  0.001048     0.001137        -0.000089     -0.001116   \n",
       "1        0.141247  0.000869     0.001109        -0.000240     -0.004464   \n",
       "2        0.140838  0.000554     0.001052        -0.000498     -0.005022   \n",
       "3        0.140083  0.000051     0.000949        -0.000898     -0.007255   \n",
       "4        0.139011 -0.000619     0.000788        -0.001407     -0.007254   \n",
       "...           ...       ...          ...              ...           ...   \n",
       "10870  182.966690 -3.602621    -1.591875        -2.010746      2.020004   \n",
       "10871  182.606071 -3.713854    -1.804073        -1.909782      0.479996   \n",
       "10872  182.181032 -3.885908    -2.012256        -1.873652     -2.099991   \n",
       "10873  181.840994 -3.953187    -2.206349        -1.746838      1.869995   \n",
       "10874  181.499475 -4.016885    -2.387403        -1.629482     -0.380005   \n",
       "\n",
       "       close_up  close_down        rs        rsi  \n",
       "0      0.000000    0.001116  1.099457  52.368628  \n",
       "1      0.000000    0.004464  0.893069  47.175730  \n",
       "2      0.000000    0.005022  0.727594  42.116042  \n",
       "3      0.000000    0.007255  0.564786  36.093507  \n",
       "4      0.000000    0.007254  0.455127  31.277493  \n",
       "...         ...         ...       ...        ...  \n",
       "10870  2.020004    0.000000  0.514266  33.961404  \n",
       "10871  0.479996    0.000000  0.547323  35.372263  \n",
       "10872  0.000000    2.099991  0.473565  32.137364  \n",
       "10873  1.869995    0.000000  0.602798  37.609120  \n",
       "10874  0.000000    0.380005  0.586219  36.957002  \n",
       "\n",
       "[10875 rows x 53 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "class Environment:\n",
    "    ''' \n",
    "    Attribute\n",
    "    ---------\n",
    "    - chart_data : stock price chart data\n",
    "    - observation : current observation\n",
    "    - idx : current postion of chart data\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize idx and observation\n",
    "    - observe() : move idx into next postion and get a new observation\n",
    "    - get_price() : get close price of current observation\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, chart_data=None):\n",
    "        self.PRICE_IDX = 4  # index postion of close price\n",
    "        self.chart_data = chart_data\n",
    "        self.observation = None\n",
    "        self.idx = -1\n",
    "        \n",
    "    def reset(self):\n",
    "        self.observation = None\n",
    "        self.idx = -1\n",
    "        \n",
    "    def observe(self):\n",
    "        # if there is no more idx, return None\n",
    "        if len(self.chart_data) > self.idx + 1:\n",
    "            self.idx += 1\n",
    "            self.observation = self.chart_data.iloc[self.idx]\n",
    "            return self.observation\n",
    "        return None\n",
    "    \n",
    "    def get_price(self):\n",
    "        # return close price\n",
    "        if self.observation is not None:\n",
    "            return self.observation[self.PRICE_IDX]\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13839299976825714"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Environment(df_adj)\n",
    "a.reset()\n",
    "a.observe()\n",
    "a.observe()\n",
    "a.get_price()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# str format on date, time\n",
    "FORMAT_DATE = '%Y%m%d'\n",
    "FORMAT_DATETIME = '%Y%m%d%H%M%S'\n",
    "\n",
    "def get_today_str():\n",
    "    today = datetime.datetime.combine(\n",
    "        datetime.date.today(), datetime.datetime.min.time()\n",
    "    )\n",
    "    today_str = today.strftime(FORMAT_DATE)\n",
    "    return today_str\n",
    "\n",
    "def get_time_str():\n",
    "    return datetime.datetime.fromtimestamp(\n",
    "        int(time.time())\n",
    "    ).strftime(FORMAT_DATETIME)\n",
    "    \n",
    "def sigmoid(x):\n",
    "    x = max(min(x, 10), -10)\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240319'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_today_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240319002734'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent\n",
    "import numpy as np\n",
    "\n",
    "class Agent:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - enviroment : instance of environment\n",
    "    - initial_balance : initial capital balance\n",
    "    - min_trading_price : minimum trading price\n",
    "    - max_trading_price : maximum trading price\n",
    "    - balance : cash balance\n",
    "    - num_stocks : obtained stocks\n",
    "    - portfolio_value : value of portfolios (balance + price * num_stocks)\n",
    "    - num_buy : number of buying\n",
    "    - num_sell : number of selling\n",
    "    - num_hold : number of holding\n",
    "    - ratio_hold : ratio of holding stocks\n",
    "    - profitloss : current profit or loss\n",
    "    - avg_buy_price : average price of a stock bought\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize an agent\n",
    "    - set_balance() : initialize initial balance\n",
    "    - get_states() : get the state of an agent\n",
    "    - decide_action() : exploration or exploitation behavior according to the policy net\n",
    "    - validate_action() : validate the behavior\n",
    "    - decide_trading_unit() : decide how many stocks are sold or bought\n",
    "    - act() : act the behavior \n",
    "    '''\n",
    "    \n",
    "    # agent states dimension\n",
    "    ## (ration_hold, profit-loss ratio, current price to avg_buy_price change ratio)\n",
    "    STATE_DIM = 3\n",
    "    \n",
    "    # trading charge and tax\n",
    "    TRADING_CHARGE = 0.00015    # trading charge 0.015%\n",
    "    TRADING_TAX = 0.02          # trading tax = 0.2%\n",
    "    \n",
    "    # action space\n",
    "    ACTION_BUY = 0      # buy\n",
    "    ACTION_SELL = 1     # sell\n",
    "    ACTION_HOLD = 2     # hold\n",
    "    \n",
    "    # get probabilities from neural nets\n",
    "    ACTIONS = [ACTION_BUY, ACTION_SELL, ACTION_HOLD]\n",
    "    NUM_ACTIONS = len(ACTIONS)      # output number from nueral nets\n",
    "    \n",
    "    def __init__(self, environment, initial_balance, min_trading_price, max_trading_price):\n",
    "        # get current price form the enviroment\n",
    "        self.environment = environment\n",
    "        self.initial_balance = initial_balance  # initial balance\n",
    "        \n",
    "        # minimum and maximum buying prices\n",
    "        self.min_trading_price = min_trading_price\n",
    "        self.max_trading_price = max_trading_price\n",
    "        \n",
    "        # attributes for Agent class\n",
    "        self.balance = initial_balance      # current balance\n",
    "        self.num_stocks = 0                 # number of obtained stocks\n",
    "        \n",
    "        # value of portfolio : balance + num_stocks * {current stock price} \n",
    "        self.portfolio_value = 0\n",
    "        self.num_buy = 0        # number of buying\n",
    "        self.num_sell = 0       # number of selling\n",
    "        self.num_hold = 0       # number of holding\n",
    "        \n",
    "        # the state of Agent class\n",
    "        self.ratio_hold = 0     \n",
    "        self.profitloss = 0     # profit-loss ratio\n",
    "        self.avg_buy_price = 0 \n",
    "        \n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.num_stocks = 0\n",
    "        self.portfolio_value = self.initial_balance\n",
    "        self.num_buy = 0\n",
    "        self.num_sell = 0\n",
    "        self.num_hold = 0\n",
    "        self.ratio_hold = 0\n",
    "        self.profitloss = 0\n",
    "        self.avg_buy_price = 0\n",
    "        \n",
    "        \n",
    "    def set_balance(self, balance):\n",
    "        # set initial balance\n",
    "        self.initial_balance = balance\n",
    "        \n",
    "    def get_states(self):\n",
    "        # ratio_hold = num_stocks / (portfolio_value / price)\n",
    "        self.ratio_hold = self.num_stocks * self.environment.get_price() / self.portfolio_value\n",
    "        \n",
    "        return (\n",
    "            self.ratio_hold,\n",
    "            self.profitloss,    # profitloss = (portfolio_value / initial_balance) - 1\n",
    "            (self.environment.get_price() / self.avg_buy_price) - 1 if self.avg_buy_price > 0 else 0 \n",
    "        )\n",
    "        \n",
    "    def decide_action(self, pred_value, pred_policy, epsilon):\n",
    "        # act randomly according with epsilon probability, act according to neural nets otherwise.\n",
    "        confidence = 0\n",
    "        \n",
    "        # if there is a pred_policy, follow it, otherwise, follow pred_value\n",
    "        pred = pred_policy\n",
    "        if pred is None:\n",
    "            pred = pred_value\n",
    "        \n",
    "        if pred is None:\n",
    "            # there are no predictions, explore\n",
    "            epsilon = 1\n",
    "        else:\n",
    "            # values are equal, explore\n",
    "            maxpred = np.max(pred)\n",
    "            if (pred == maxpred).all():\n",
    "                epsilon = 1\n",
    "            \n",
    "            # the difference between buying and selling (e.g., 0.05), explore\n",
    "            if pred_policy is not None:\n",
    "                if np.max(pred_policy) - np.min(pred_policy) < 0.05:\n",
    "                    epsilon = 1\n",
    "                    \n",
    "        # decide exploration\n",
    "        if np.random.rand() < epsilon:\n",
    "            exploration = True\n",
    "            action = np.random.randint(self.NUM_ACTIONS)\n",
    "        else:\n",
    "            exploration = False\n",
    "            action = np.argmax(pred)\n",
    "            \n",
    "        confidence = .5\n",
    "        if pred_policy is not None:\n",
    "            confidence = pred[action]\n",
    "        elif pred_value is not None:\n",
    "            confidence = sigmoid(pred[action])\n",
    "            \n",
    "        return action, confidence, exploration\n",
    "    \n",
    "    def validate_action(self, action):\n",
    "        # validate decided action\n",
    "        if action == Agent.ACTION_BUY:\n",
    "            # check if at least one stock can be bought\n",
    "            if self.balance < self.environment.get_price() * (1 + self.TRADING_CHARGE):\n",
    "                return False\n",
    "        elif action == Agent.ACTION_SELL:\n",
    "            # check if there are obtained stocks\n",
    "            if self.num_stocks <= 0:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def decide_trading_unit(self, confidence):\n",
    "        # adjust number of buying or selling according to confidence level\n",
    "        if np.isnan(confidence):\n",
    "            return self.min_trading_price\n",
    "        \n",
    "        # set buying price range between self.min_trading_price + added_trading_priceRK [min_trading_price, max_trading_price]\n",
    "        # in case that confidence > 1 causes the price over max_trading_price, we set min() so that the value cannot have larger value than self.max_trading_price - self.min_trading_price\n",
    "        # in case that confidence < 0, we set max() so that added_trading_price cannot have negative value.\n",
    "        added_trading_price = max(min(\n",
    "            int(confidence * (self.max_trading_price - self.min_trading_price)),\n",
    "            self.max_trading_price - self.min_trading_price\n",
    "        ), 0)\n",
    "        \n",
    "        trading_price = self.min_trading_price + added_trading_price\n",
    "        \n",
    "        return max(int(trading_price / self.environment.get_price()), 1)\n",
    "    \n",
    "    def act(self, action, confidence):\n",
    "        ''' \n",
    "        Arguments\n",
    "        ---------\n",
    "        - action : decided behavior based on exploratio or exploitation (0 or 1)\n",
    "        - confidence : sofmax probability derived from neural nets\n",
    "        '''\n",
    "        \n",
    "        if not self.validate_action(action):\n",
    "            action = Agent.ACTION_HOLD\n",
    "            \n",
    "        # get the price from the environment\n",
    "        curr_price = self.environment.get_price()\n",
    "        \n",
    "        # buy\n",
    "        if action == Agent.ACTION_BUY:\n",
    "            # how many stocks\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            balance = (\n",
    "                self.balance - curr_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            )\n",
    "            \n",
    "            # if lacks of money, buy maximum units within the amount of money what we have\n",
    "            if balance < 0:\n",
    "                trading_unit = min(\n",
    "                    int(self.balance / (curr_price * (1 + self.TRADING_CHARGE))),\n",
    "                    int(self.max_trading_price / curr_price)\n",
    "                )\n",
    "                \n",
    "            # total amount of money with trading charge\n",
    "            invest_amount = curr_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            if invest_amount > 0:\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks + curr_price * trading_unit) / (self.num_stocks + trading_unit)\n",
    "                self.balance -= invest_amount\n",
    "                self.num_stocks += trading_unit\n",
    "                self.num_buy += 1\n",
    "                \n",
    "        # sell\n",
    "        elif action == Agent.ACTION_SELL:\n",
    "            # how many stocks\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            # if lacks of obtained stocks, sell as many as possible\n",
    "            trading_unit = min(trading_unit, self.num_stocks)\n",
    "            # sell\n",
    "            invest_amount = curr_price * (\n",
    "                1 - (self.TRADING_TAX + self.TRADING_CHARGE)\n",
    "            ) * trading_unit\n",
    "            \n",
    "            if invest_amount > 0:\n",
    "                # update avg_buy_price\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks - curr_price * trading_unit) / (self.num_stocks - trading_unit)\n",
    "                self.num_stocks -= trading_unit\n",
    "                self.balance += invest_amount\n",
    "                self.num_sell += 1\n",
    "                \n",
    "        # hold\n",
    "        elif action == Agent.ACTION_HOLD:\n",
    "            self.num_hold += 1\n",
    "            \n",
    "        # update portfolio value\n",
    "        self.portfolio_value = self.balance + curr_price * self.num_stocks\n",
    "        self.profitloss = self.portfolio_value / self.initial_balance - 1\n",
    "        return self.profitloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer\n",
    "\n",
    "import threading\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "class Visulaizer:\n",
    "    ''' \n",
    "    Attributes\n",
    "    ---------\n",
    "    - fig : Figure class instance playing a canvas role\n",
    "    - axes : Axes class instance for plotting chart\n",
    "    - title : title for plot\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - prepare() : initialize a figure and print daily chart\n",
    "    - plot() : print all chart except daily chart\n",
    "    - save() : save a figure as an image file\n",
    "    - clear() : initial all the chart except daily chart\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    - Figure title : parameters, epochs, and exploration rate\n",
    "    - Axes 1 : daily ohlc chart\n",
    "    - Axes 2 : obtained stocks and agent action\n",
    "    - Axes 3 : neural net output\n",
    "    - Axes 4 : policy net output and exploration chart\n",
    "    - Axes 5 : Portfolio value and learning point chart\n",
    "    '''\n",
    "    \n",
    "    COLORS = ['r', 'b', 'g']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.canvas = None\n",
    "        self.fig = None\n",
    "        self.axes = None\n",
    "        self.title = ''\n",
    "        self.x = []\n",
    "        self.xticks = []\n",
    "        self.xlabels = []\n",
    "        \n",
    "    def prepare(self, chart_data, title):\n",
    "        self.title = title\n",
    "        with lock:\n",
    "            # initialize canva and prepare drawing 5 charts\n",
    "            self.fig, self.axes = plt.subplots(\n",
    "                nrows=5, ncols=1, facecolor='w', sharex=True\n",
    "            )\n",
    "            \n",
    "            for ax in self.axes:\n",
    "                # deactivate the marks unnecessary\n",
    "                ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                # y axis 위치 오른쪽으로 변경\n",
    "                ax.yaxis.tick_right()\n",
    "                \n",
    "            # chart 1. daily ohlc chart\n",
    "            self.axes[0].set_ylabel('Env.')     # y label\n",
    "            x = np.arange(len(chart_data))\n",
    "            # set two dimensional matrix ordering by open, high, low, close \n",
    "            ohlc = np.hstack((\n",
    "                x.reshape(-1, 1), np.array(chart_data)[:, 1:-1]\n",
    "            ))\n",
    "            \n",
    "            # red for positive, blue for negative\n",
    "            candlestick_ohlc(self.axes[0], ohlc, colorup='r', colordown='b')\n",
    "            \n",
    "            # visualize volume\n",
    "            ax = self.axes[0].twinx()\n",
    "            volume = np.array(chart_data)[:, -1].tolist()\n",
    "            ax.bar(x, volume, color='b', alpha=0.3)\n",
    "            \n",
    "            # set x-axis\n",
    "            self.x = np.arange(len(chart_data['date']))\n",
    "            self.xticks = chart_data.index[[0, -1]]\n",
    "            self.xlabels = chart_data.iloc[[0, -1]]['date']\n",
    "            \n",
    "    def plot(self, epoch_str=None, num_epochs=None, epsilon=None,\n",
    "             action_list=None, actions=None, num_stocks=None,\n",
    "             outvals_value=[], outvals_policy=[], exps=None,\n",
    "             initial_balance=None, pvs=None):\n",
    "        ''' \n",
    "        Attributes\n",
    "        ---------\n",
    "        - epoch_str : epoch for Figure title\n",
    "        - num_epochs : total epoch\n",
    "        - epsilon : exploration rate\n",
    "        - action_list : action list that an Agent can take\n",
    "        - actions: : action array that an Agent took\n",
    "        - num_stocks : obtained stock number array\n",
    "        - outvals_value : value network output array\n",
    "        - outvals_policy : policy network output array\n",
    "        - exps : whether it is explored\n",
    "        - initial_balance : initial balance\n",
    "        - pvs : portfolio value array\n",
    "        '''\n",
    "        \n",
    "        # conver numpy array because matplotlib() takes numpy() array\n",
    "        \n",
    "        with lock:\n",
    "            # action, num_stocks, outvals_value, outvals_policy, pvs have same size\n",
    "            # we create array for x-axis as same as action array\n",
    "            actions = np.array(actions)     # action array for an agent aciton\n",
    "            # output array for value network\n",
    "            outvals_value = np.array(outvals_value)\n",
    "            # output array for policy network\n",
    "            outvals_policy = np.array(outvals_policy)\n",
    "            # array for initial balance\n",
    "            pvs_base = np.zeros(len(actions)) + initial_balance\n",
    "            \n",
    "            # chart 2. Agent states (action, num_stocks)\n",
    "            for action, color in zip(action_list, self.COLORS):\n",
    "                for i in self.x[actions == action]:\n",
    "                    # background color : red = buying, blue = selling\n",
    "                    self.axes[1].axvline(i, color=color, alpha=0.1)\n",
    "            self.axes[1].plot(self.x, num_stocks, '-k')     # number of stocks\n",
    "            \n",
    "            # char 3. Value network\n",
    "            if len(outvals_value) > 0:\n",
    "                max_actions = np.argmax(outvals_value, axis=1)\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    # background\n",
    "                    for idx in self.x:\n",
    "                        if max_actions[idx] == action:\n",
    "                            self.axes[2].axvline(idx, color=color, alpha=0.1)\n",
    "                    # plot value network\n",
    "                    ## red for buying, blue for selling, green for holding\n",
    "                    ## if there is no holding in predicting, no green is plotted\n",
    "                    self.axes[2].plot(self.x, outvals_value[:, action], color=color, linestyle='-')\n",
    "                    \n",
    "            # chart 4. policy network\n",
    "            # yellow for exploration\n",
    "            for exp_idx in exps:\n",
    "                self.axes[3].axvline(exp_idx, color='y')\n",
    "            # background for action\n",
    "            _outvals = outvals_policy if len(outvals_policy) > 0 else outvals_value\n",
    "            for idx, outval in zip(self.x, _outvals):\n",
    "                color = 'white'\n",
    "                if np.isnan(outval.max()):\n",
    "                    continue\n",
    "                # in the no exploration point, red for buying, blue for selling\n",
    "                if outval.argmax() == Agent.ACTION_BUY:\n",
    "                    color = self.COLORS[0]\n",
    "                elif outval.argmax() == Agent.ACTION_SELL:\n",
    "                    color = self.COLORS[1]\n",
    "                elif outval.argmax() == Agent.ACTION_HOLD:\n",
    "                    color = self.COLORS[2]\n",
    "                self.axes[3].axvline(idx, color=color, alpha=0.1)\n",
    "                \n",
    "            # plot policy network output\n",
    "            # policy network for buying is red, policy network for selling is blue\n",
    "            # if red line is above the blue line, an agent buys, otherwise sells\n",
    "            if len(outvals_policy) > 0:\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    self.axes[3].plot(\n",
    "                        self.x, outvals_policy[:, action],\n",
    "                        color=color, linstyle='-'\n",
    "                    )\n",
    "                    \n",
    "            # chart 5. Portfolio value\n",
    "            # horizontal straight line for initial balance\n",
    "            self.axes[4].axhline(\n",
    "                initial_balance, linestyle='-', color='gray'\n",
    "            )\n",
    "            # the part above initial balance is plotted as red\n",
    "            self.axes[4].fill_between(\n",
    "                self.x, pvs, pvs_base,\n",
    "                where=pvs > pvs_base, facecolor='r', alpha=0.1\n",
    "            )\n",
    "            # the part below initial balance is plotted as blue\n",
    "            self.axes[4].fill_between(\n",
    "                self.x, pvs, pvs_base,\n",
    "                where=pvs < pvs_base, facecolor='b', alpha=0.1\n",
    "            )\n",
    "            self.axes[4].plot(self.x, pvs, '-k')\n",
    "            self.axes[4].xaxis.set_ticks(self.xticks)\n",
    "            self.axes[4].xaxis.set_ticklabels(self.xlabels)\n",
    "            \n",
    "            # epoch and exploration rate\n",
    "            self.fig.suptitle(f'{self.title}\\nEPOCH:{epoch_str}/{num_epochs} EPSILON:{epsilon:.2f}')\n",
    "            # adjust canvas layout\n",
    "            self.fig.tight_layout()\n",
    "            self.fig.subplots_adjust(top=0.85)\n",
    "            \n",
    "    # initialize visualization\n",
    "    def clear(self, xlim):\n",
    "        with lock:\n",
    "            _axes = self.axes.tolist()\n",
    "            # initialize chart except unchanged values\n",
    "            for ax in _axes[1:]:\n",
    "                ax.cla()        # erase charts\n",
    "                ax.relim()      # initialize limit\n",
    "                ax.autoscale()  # rescale\n",
    "            \n",
    "            # reset y label\n",
    "            self.axes[1].set_ylabel('Agent')\n",
    "            self.axes[2].set_ylabel('V')\n",
    "            self.axes[3].set_ylabel('P')\n",
    "            self.axes[4].set_ylabel('PV')\n",
    "            for ax in _axes:\n",
    "                ax.set_xlim(xlim)       # reset x-axis limit\n",
    "                ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                # set x-axix interval equally\n",
    "                ax.ticklabel_format(useOffset=False)\n",
    "                \n",
    "    # save results\n",
    "    def save(self, path):\n",
    "        with lock:\n",
    "            self.fig.savefig(path)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks\n",
    "import threading\n",
    "import abc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    ''' \n",
    "    Common network class\n",
    "    and DNN, LSTMNetwork, CNN\n",
    "    \n",
    "    Attributes\n",
    "    ---------\n",
    "    - input_dim \n",
    "    - output_dim\n",
    "    - lr : learning rate for network\n",
    "    - shared_network : upper part of network shared with various networks\n",
    "    - activation : action function for output layer e.g) 'linear', 'sigmoid', 'tanh', 'softmax' \n",
    "    - loss : loss function for network\n",
    "    - model : final network model\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - predict() : calculate behavioral value and probabilities \n",
    "    - train_on_batch() : generate dataset for batch learning\n",
    "    - save_model() : save network model as a file\n",
    "    - load_model() : load network model from a file\n",
    "    - get_shared_network() : function for generating shared network\n",
    "    '''\n",
    "    \n",
    "    # thread lock for A3C\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    def __init__(self, input_dim=0, output_dim=0, num_steps=1, lr=0.001,\n",
    "                 share_network=None, activation='sigmoid', loss='mse'):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.shared_network = share_network\n",
    "        self.activation = activation\n",
    "        self.loss = loss\n",
    "        \n",
    "        # data dimension for network\n",
    "        # CNN, LSTMNework has 3 dimension -> inp = (num_steps, input_dim), DNN -> inp = (input_dim, )\n",
    "        inp = None\n",
    "        # if hasattr(self, 'num_steps):\n",
    "        #   inp = (self.num_steps, input_dim)\n",
    "        # else:\n",
    "        #   inp = (self.input_dim, )\n",
    "        if self.num_steps > 1:\n",
    "            inp = (self.num_steps, input_dim)\n",
    "        else:\n",
    "            inp = (self.input_dim, )\n",
    "        \n",
    "        # using shared network\n",
    "        self.head = None\n",
    "        if self.shared_network is None:\n",
    "            self.head = self.get_network_head(inp, self.output_dim)\n",
    "        else:\n",
    "            self.head = self.shared_network\n",
    "            \n",
    "        # not using shared network\n",
    "        # self.head = self.get_network_head(inp, self.output_dim)\n",
    "        \n",
    "        # network model\n",
    "        ## create head network model\n",
    "        self.model = torch.nn.Sequential(self.head)\n",
    "        if self.activation == 'linear':\n",
    "            pass\n",
    "        elif self.activation == 'relu':\n",
    "            self.model.add_module('activation', torch.nn.ReLU())\n",
    "        elif self.activation == 'leaky_relu':\n",
    "            self.model.add_module('activation', torch.nn.LeakyReLU())\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.model.add_module('activation', torch.nn.Sigmoid())\n",
    "        elif self.activation == 'tanh':\n",
    "            self.model.add_module('activation', torch.nn.Tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            self.model.add_module('activation', torch.nn.Tanh())\n",
    "        self.model.apply(Network.init_weights)\n",
    "        self.model.to(device)\n",
    "        \n",
    "        # optimizer\n",
    "        # self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=self.lr)\n",
    "        self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = None\n",
    "        if loss == 'mse':\n",
    "            self.criterion = torch.nn.MSELoss()\n",
    "        elif loss == 'binary_crossentropy':\n",
    "            self.criterion = torch.nn.BCELoss()\n",
    "            \n",
    "    def predict(self, sample):\n",
    "        # return prediction buy, sell and hold on sample data\n",
    "        # value network : behavioral value on sample data, policy network : behavioral probabilities on sample data\n",
    "        with self.lock:\n",
    "            # transform evaluation mode : deactivate layers such as dropout used only in learning process\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(sample).float().to(device)\n",
    "                pred = self.model(x).detatch().cpu().numpy()\n",
    "                pred = pred.flatten()\n",
    "            return pred\n",
    "        \n",
    "    def train_on_batch(self, x, y):\n",
    "        if self.num_steps > 1:\n",
    "            x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "        else:\n",
    "            x = np.array(x).reshape((-1, self.input_dim))\n",
    "        loss = 0.\n",
    "        with self.lock:\n",
    "            # transform learning mode\n",
    "            self.model.train()\n",
    "            _x = torch.from_numpy(x).float().to(device)\n",
    "            _y = torch.from_numpy(y).float().to(device)\n",
    "            y_pred = self.model(_x)\n",
    "            _loss = self.criterion(y_pred, _y)\n",
    "            self.optimizer.zero_grad()\n",
    "            _loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss += _loss.item()\n",
    "        return loss\n",
    "    \n",
    "    def train_on_batch_for_ppo(self, x, y, a, eps, K):\n",
    "        if self.num_steps > 1:\n",
    "            x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "        else:\n",
    "            x = np.array(x).reshape((-1, self.input_dim))\n",
    "        loss = 0.\n",
    "        with self.lock:\n",
    "            self.model.train()\n",
    "            _x = torch.from_numpy(x).float().to(device)\n",
    "            _y = torch.from_numpy(y).float().to(device)\n",
    "            probs = F.softmax(_y, dim=1)\n",
    "            for _ in range(K):\n",
    "                y_pred = self.model(_x)\n",
    "                probs_pred = F.softmax(y_pred, dim=1)\n",
    "                rto = torch.exp(torch.log(probs[:, a]) - torch.log(probs_pred[:, a]))\n",
    "                rto_adv = rto * _y[:, a]\n",
    "                clp_adv = torch.clamp(rto, 1 - eps, 1 + eps) * +y[:, a]\n",
    "                _loss = -torch.min(rto_adv, clp_adv).mean()\n",
    "                self.optimizer.zero_grad()\n",
    "                _loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss += _loss.item()\n",
    "        return loss\n",
    "    \n",
    "    @classmethod\n",
    "    def get_shared_network(cls, net='dnn', num_steps=1, input_dim=0, output_dim=0):\n",
    "        if net == 'dnn':\n",
    "            return DNN.get_network_head((input_dim,), output_dim)\n",
    "        elif net == 'lstm':\n",
    "            return LSTMNetwork.get_network_head((num_steps, input_dim), output_dim)\n",
    "        elif net == 'cnn':\n",
    "            return CNN.get_network_head((num_steps, input_dim), output_dim)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_weight(m):\n",
    "        # initialize weights based on normal distribution\n",
    "        if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv1d):\n",
    "            torch.nn.init.normal_(m.weight, std=0.01)\n",
    "        elif isinstance(m, torch.nn.LSTM):\n",
    "            for weights in m.all_weights:\n",
    "                for weight in weights:\n",
    "                    torch.nn.init.normal_(weight, std=0.01)\n",
    "                    \n",
    "    def save_model(self, model_path):\n",
    "        if model_path is not None and self.model is not None:\n",
    "            torch.save(self.model, model_path)\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        if model_path is not None:\n",
    "            self.model = torch.load(model_path)\n",
    "            \n",
    "class DNN(Network):\n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            torch.nn.Linear(inp[0], 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim),\n",
    "        )\n",
    "        \n",
    "    # def train_on_batch(self, x, y):\n",
    "    #   x = np.array(x).reshape((-1, self.input_dim))\n",
    "    #   return super().train_on_batch(x, y)\n",
    "    \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((1, self.input_dim))\n",
    "        return super().predict(sample)\n",
    "    \n",
    "class LSTMNetwork(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            LSTMModule(inp[1], 128, batch_fist=True, use_last_only=True),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim),\n",
    "        )\n",
    "        \n",
    "    # def train_on_batch(self, x, y):\n",
    "    #     x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "    #     return super().train_on_batch(x, y)\n",
    "    \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((-1, self.num_steps, self.input_dim))\n",
    "        return super().predict(sample)\n",
    "    \n",
    "class LSTMModule(torch.nn.LSTM):\n",
    "    def __init__(self, *args, use_last_only=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.use_last_only = use_last_only\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (h_n, _) = super().forward(x)\n",
    "        if self.use_last_only:\n",
    "            return h_n[-1]\n",
    "        return output\n",
    "    \n",
    "class CNN(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        kernel_size = 2\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            torch.nn.Conv1d(inp[0], 1, kernel_size),\n",
    "            torch.nn.BatchNorm1d(1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(inp[1] - (kernel_size - 1), 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim),\n",
    "        )\n",
    "\n",
    "    # def train_on_batch(self, x, y):\n",
    "    #     x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "    #     return super().train_on_batch(x, y)\n",
    "    \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((1, self.num_steps, self.input_dim))\n",
    "        return super().predict(sample)      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import locale\n",
    "# import platform\n",
    "\n",
    "# logger name\n",
    "LOGGER_NAME = 'rltrader'\n",
    "\n",
    "# # path setting\n",
    "# # parent path\n",
    "# BASE_DIR = os.environ.get('RLTRADER_BASE', os.path.abspath(os.path.join(__file__, os.path.pardir)))\n",
    "\n",
    "# # locale setting\n",
    "# if 'Lines' in platform.system() or 'Darwin' in platform.system():\n",
    "#     locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')\n",
    "# elif 'Windows' in platform.system():\n",
    "#     locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learners\n",
    "\n",
    "import os \n",
    "import logging\n",
    "import abc\n",
    "import collections\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "# DQNLearner\n",
    "class ReinforcementLearner:\n",
    "    ''' \n",
    "    Attributes\n",
    "    ---------\n",
    "    - stock_code \n",
    "    - chart_data\n",
    "    - environment\n",
    "    - agent\n",
    "    - training_data\n",
    "    - value_network\n",
    "    - policy_network\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - init_value_network()\n",
    "    - init_policy_network()\n",
    "    - build_sample() : get sample from environment instance\n",
    "    - update_network() : update value network and policy network\n",
    "    - fit() : request learn value and policy network\n",
    "    - visualize() : visualize epoch info\n",
    "    - fun() : reinforcement learning\n",
    "    - save_models() : save value and policy network\n",
    "    '''\n",
    "    \n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    def __init__(self, rl_method='rl', stock_code=None,\n",
    "                 chart_data=None, training_data=None,\n",
    "                 min_trading_price=10, max_trading_price=10000,\n",
    "                 net='dnn', num_steps=1, lr=0.0005,\n",
    "                 discount_factor=0.9, num_epochs=1000,\n",
    "                 balance=100000, start_epsilon=1, \n",
    "                 value_network=None, policy_network=None,\n",
    "                 output_path='', reuse_models=True, gen_output=True):\n",
    "        ''' \n",
    "        Attributes\n",
    "        --------\n",
    "        - rl_method : reinforcement learning method / 'dqn' : DQNLearner, 'pg' : PolicyGradient, 'ac' : ActorCriticLearner, 'a2c' : A2CLearner, 'a3c' : A3CLearner\n",
    "        - stock_code\n",
    "        - chart_data \n",
    "        - training_data\n",
    "        - min_trading_price, max_trading_price\n",
    "        - net : neural network / 'dnn', 'lstm', 'cnn'\n",
    "        - n_steps : sample step size for LSTM, CNN\n",
    "        - lr : learning rate\n",
    "        - discount_factor : state-action value discount factor\n",
    "        - num_epochs : total training epochs\n",
    "        - balance : initial balance\n",
    "        - start_epsilon : initial exploration rate\n",
    "        - value_network, policy_network\n",
    "        - output_path : save path for model\n",
    "        - reuse_models \n",
    "        '''\n",
    "        \n",
    "        # check arguments\n",
    "        assert min_trading_price > 0\n",
    "        assert max_trading_price > 0\n",
    "        assert max_trading_price >= min_trading_price\n",
    "        assert num_steps > 0\n",
    "        assert lr > 0\n",
    "        \n",
    "        # setting reinforcement learning\n",
    "        self.rl_method = rl_method\n",
    "        self.discount_factor = discount_factor\n",
    "        self.num_epochs = num_epochs\n",
    "        self.start_epsilon = start_epsilon\n",
    "        \n",
    "        # set Environment\n",
    "        self.stock_code = stock_code\n",
    "        self.chart_data = chart_data\n",
    "        self.environment = Environment(chart_data)\n",
    "        \n",
    "        # set Agent\n",
    "        self.agent = Agent(self.environment, balance, min_trading_price, max_trading_price)\n",
    "        \n",
    "        \n",
    "        # training data\n",
    "        self.trainig_data = training_data\n",
    "        self.sample = None\n",
    "        self.trainig_data_idx = -1\n",
    "        \n",
    "        # size of vector = vector for training data size + agent states size\n",
    "        self.num_features = self.agent.STATE_DIM\n",
    "        if self.trainig_data is not None:\n",
    "            self.num_features += self.trainig_data.shape[1]\n",
    "            \n",
    "        # set neural network\n",
    "        self.net = net\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.value_network = value_network\n",
    "        self.policy_network = policy_network\n",
    "        self.reuse_models = reuse_models\n",
    "        \n",
    "        # set Visualizer\n",
    "        self.visualizer = Visulaizer()\n",
    "        \n",
    "        # memory\n",
    "        self.memory_sample = []     # training data sample\n",
    "        self.memory_action = []     # actions that were taken\n",
    "        self.memory_reward = []     # rewards that were got\n",
    "        self.memory_value = []      # prediction values of actions\n",
    "        self.memory_policy = []     # prediction probabilities of actions\n",
    "        self.memory_pv = []         # portfolio value\n",
    "        self.memory_num_stocks = [] # number of stocks obtained\n",
    "        self.memory_exp_idx = []    # exploration position\n",
    "        \n",
    "        # epoch info.\n",
    "        self.loss = 0.          # loss during epoch\n",
    "        self.itr_cnt = 0        # number of profit\n",
    "        self.exploration_cnt = 0    # count of exploration\n",
    "        self.batch_size = 0     # training epoch\n",
    "        \n",
    "        # log\n",
    "        self.output_path = output_path\n",
    "        self.gen_output = gen_output\n",
    "        \n",
    "    def init_value_network(self, shared_network=None, activation='linear', loss='mse'):\n",
    "        if self.net == 'dnn':\n",
    "            self.value_network = DNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, share_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "        elif self.net == 'lstm':\n",
    "            self.value_network = LSTMNetwork(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "        elif self.net == 'cnn':\n",
    "            self.value_network = CNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "        if self.reuse_models and os.path.exists(self.value_network_path):\n",
    "            self.value_network.load_model(model_path=self.value_network_path)\n",
    "    \n",
    "    def init_policy_network(self, shared_network=None, activation='sigmoid', loss='binary_crossentropy'):\n",
    "        \n",
    "        if self.net == 'dnn':\n",
    "            self.policy_network = DNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, share_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'lstm':\n",
    "            self.policy_network = LSTMNetwork(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'cnn':\n",
    "            self.policy_network = CNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        if self.reuse_models and os.path.exists(self.policy_network_path):\n",
    "            self.policy_network.load_model(model_path=self.policy_network_path)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.sample = None\n",
    "        self.trainig_data_idx = -1\n",
    "        \n",
    "        # reset environment\n",
    "        self.environment.reset()\n",
    "        \n",
    "        # reset agent\n",
    "        self.agent.reset()\n",
    "        \n",
    "        # reset visualizer\n",
    "        self.visualizer.clear([0, len(self.chart_data)])\n",
    "        \n",
    "        # intialize memories\n",
    "        self.memory_sample = []\n",
    "        self.memory_action = []\n",
    "        self.memory_reward = []\n",
    "        self.memory_value = []\n",
    "        self.memory_policy = []\n",
    "        self.memory_pv = []\n",
    "        self.memory_num_stocks = []\n",
    "        self.memory_exp_idx = []\n",
    "        \n",
    "        # intialize epoch info\n",
    "        self.loss = 0.\n",
    "        self.itr_cnt = 0\n",
    "        self.exploration_cnt = 0\n",
    "        self.batch_size = 0\n",
    "        \n",
    "    def build_sample(self):\n",
    "        # get data from the next index\n",
    "        self.environment.observe()\n",
    "        # 47 values in the sample + next agent states = 50 values\n",
    "        if len(self.trainig_data) > self.trainig_data_idx + 1:\n",
    "            self.trainig_data_idx += 1\n",
    "            self.sample = self.trainig_data[self.trainig_data_idx].tolist()\n",
    "            self.sample.extend(self.agent.get_states())\n",
    "            return self.sample\n",
    "        return None\n",
    "    \n",
    "    # abstrac method\n",
    "    @abc.abstractmethod\n",
    "    def get_batch(self):\n",
    "        pass\n",
    "    \n",
    "    # after create training batch data, call train_on_batch() method for training value network and policy network\n",
    "    # value network : DQNLearner, ActorCriticLearner, A2CLearner\n",
    "    # policy network : PolicyGrdient, ActorCriticLearner, A2CLearner\n",
    "    # After training, save loss instance and return the sum of value network loss and policy network loss in case tha both network are used\n",
    "    def fit(self):\n",
    "        # create batch fata\n",
    "        x, y_value, y_polcy = self.get_batch()\n",
    "        # init loss\n",
    "        self.loss = None\n",
    "        if len(x) > 0:\n",
    "            loss = 0\n",
    "            if y_value is not None:\n",
    "                # update value network\n",
    "                loss += self.value_network.train_on_batch(x, y_value)\n",
    "            if y_polcy is not None:\n",
    "                # update policy network\n",
    "                loss += self.value_network.train_on_batch(x, y_polcy)\n",
    "            self.loss = loss\n",
    "            \n",
    "    # after end of an epoch, visualize it.\n",
    "    # In case of LSTM, CNN, agent's action, number of stocks, value network output, policy network output, value of portfolio are (num_steps - 1) less than environment observation and fill dummy variables\n",
    "    def visualize(self, epoch_str, num_epochs, epsilon):\n",
    "        self.memory_action = [Agent.ACTION_HOLD] * (self.num_steps - 1) + self.memory_action\n",
    "        self.memory_num_stocks = [0] * (self.num_steps - 1) + self.memory_num_stocks\n",
    "        if self.value_network is not None:\n",
    "            self.memory_value = [np.array([np.nan] * len(Agent.ACTIONS))] * (self.num_steps - 1) + self.memory_value\n",
    "        if self.policy_network is not None:\n",
    "            self.memory_policy = [np.array([np.nan] * len(Agent.ACTIONS))]  * (self.num_steps - 1) + self.memory_policy\n",
    "            \n",
    "        self.memory_pv = [self.agent.initial_balance] * (self.num_steps - 1) + self.memory_pv\n",
    "        \n",
    "        self.visualizer.plot(\n",
    "            epoch_str=epoch_str, num_epochs=num_epochs,\n",
    "            epsilon=epsilon, action_list=Agent.ACTIONS,\n",
    "            actions=self.memory_action,\n",
    "            num_stocks=self.memory_num_stocks,\n",
    "            outvals_value=self.memory_value,\n",
    "            outvals_policy=self.memory_policy,\n",
    "            exps=self.memory_exp_idx,\n",
    "            initial_balance=self.agent.initial_balance,\n",
    "            pvs=self.memory_pv,\n",
    "        )\n",
    "        self.visualizer.save(os.path.join(self.epoch_summary_dir, f'epoch_summary_{epoch_str}.png'))\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "     \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
