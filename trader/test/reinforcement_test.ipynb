{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db connection\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import keyring\n",
    "import platform\n",
    "import numpy as np\n",
    "\n",
    "user = 'root'\n",
    "pw = keyring.get_password('macmini_db', user)\n",
    "host = '192.168.219.106' if platform.system() == 'Windows' else '127.0.0.1'\n",
    "port = 3306\n",
    "db = 'stock'\n",
    "\n",
    "\n",
    "# # connect DB\n",
    "# engine = create_engine(f'mysql+pymysql://{self.user}:{self.pw}@{self.host}:{self.port}/{self.db}')\n",
    "\n",
    "# con = pymysql.connect(\n",
    "#     user=user,\n",
    "#     passwd=pw,\n",
    "#     host=host,\n",
    "#     db=db,\n",
    "#     charset='utf8'\n",
    "# )\n",
    "        \n",
    "# mycursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base data\n",
    "COLUMNS_STOCK_DATA = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "COLUMNS_TRAINING_DATA = COLUMNS_STOCK_DATA + ['close_ma5', 'volume_ma5', 'close_ma5_ratio', 'volume_ma5_ratio',\n",
    "       'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio',\n",
    "       'low_close_ratio', 'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "       'close_ma10', 'volume_ma10', 'close_ma10_ratio', 'volume_ma10_ratio',\n",
    "       'close_ma20', 'volume_ma20', 'close_ma20_ratio', 'volume_ma20_ratio',\n",
    "       'close_ma60', 'volume_ma60', 'close_ma60_ratio', 'volume_ma60_ratio',\n",
    "       'close_ma120', 'volume_ma120', 'close_ma120_ratio',\n",
    "       'volume_ma120_ratio', 'close_ma240', 'volume_ma240',\n",
    "       'close_ma240_ratio', 'volume_ma240_ratio', 'middle_bb', 'upper_bb',\n",
    "       'lower_bb', 'bb_pb', 'bb_width', 'ema_short', 'ema_long', 'macd',\n",
    "       'macd_signal', 'macd_oscillator', 'close_change', 'close_up',\n",
    "       'close_down', 'rs', 'rsi']\n",
    "\n",
    "COLUMNS_MARKET_DATA = [\n",
    "    'kospi', 'kosdaq', 'dow', 'snp',\n",
    "    'nikkei', 'hangseng', 'ftse', 'cac',\n",
    "    'dax', 'enronext', 'vix', \n",
    "    'shanghai',\n",
    "]\n",
    "COLUMNS_BOND_DATA = [\n",
    "    'bond_us_13w', 'bond_us_5y', 'bond_us_10y',\n",
    "    'bond_us_30y', 'bond_kr_3y'\n",
    "]\n",
    "COLUMNS_EXCHANGE_DATA = [\n",
    "    'usd_eur', 'usd_gbr', 'usd_jpy', 'usd_cnh', 'usd_kor',\n",
    "]\n",
    "COLUMNS_VALUE_DATA = [\n",
    "    'per', 'pbr', 'roe', 'dy', 'pcr', 'psr', 'marekt_cap',\n",
    "    'roa',\n",
    "]\n",
    "COLUMNS_FACTOR_DATA = [\n",
    "    'beta', 'value', 'moment', 'qaulity', 'volatility',\n",
    "]\n",
    "COLUMNS_TECH_DATA = [\n",
    "    'upperbb', 'lowerbb', 'bb_pb', 'bb_width', 'macd',\n",
    "    'rsi', 'mfi', 'ii', 'buy_strength', 'sell_strength'\n",
    "]\n",
    "COLUMNS_SECTOR_DATA = [\n",
    "    'xlk', 'xlv', 'xly', 'xlp',\n",
    "    'xle', 'xlf', 'xli', 'xlb',\n",
    "    'xlre', 'xlu',\n",
    "]\n",
    "COLUMNS_COMMODITY_DATA = [\n",
    "    'oil', 'gold',\n",
    "]\n",
    "\n",
    "# moving average data\n",
    "COLUMNS_STOCK_ROLLING_DATA = [\n",
    "    'close_ma5_ratio', 'close_ma10_ratio', 'close_ma20_ratio',\n",
    "    'close_ma60_ratio', 'close_ma120_ratio', 'close_ma240_ratio',\n",
    "    'volume_ma5_ratio', 'volume_ma10_ratio', 'volumne_ma20_ratio',\n",
    "    'volume_ma60_ratio', 'volume_ma120_ratio', 'volume_ma240_ratio',\n",
    "]\n",
    "COLUMNS_MARKET_ROLLING_DATA = [\n",
    "    'market_kospi_ma5_ratio', 'market_kospi_ma10_ratio', 'market_kospi_ma20_ratio',\n",
    "    'market_kospi_ma60_ratio', 'market_kospi_ma120_ratio', 'market_kospi_ma120_ratio',\n",
    "    'market_kosdaq_ma5_ratio', 'market_kosdaq_ma10_ratio', 'market_kosdaq_ma20_ratio',\n",
    "    'market_kosdqp_ma60_ratio', 'market_kosdaq_ma120_ratio', 'market_kosdaq_ma240_ratio',\n",
    "    'market_dow_ma5_ratio', 'market_dow_ma10_ratio', 'market_dow_ma20_ratio',\n",
    "    'market_dow_ma60_ratio', 'market_dow_ma120_ratio', 'market_dow_ma240_ratio',\n",
    "    'market_snp_ma5_ratio', 'market_snp_ma10_ratio', 'market_snp_ma20_ratio',\n",
    "    'market_snp_ma60_ratio', 'market_snp_ma120_ratio', 'market_snp_ma240_ratio',\n",
    "    'market_nikkei_ma5_ratio', 'market_nikkei_ma10_ratio', 'market_nikkei_ma20_ratio',\n",
    "    'market_nikkei_ma60_ratio', 'market_nikkei_ma120_ratio', 'market_ma240_ratio',\n",
    "    'market_hangseng_ma5_ratio', 'market_hangseng_ma10_ratio', 'market_hangseng_ma20_ratio',\n",
    "    'market_hangseng_ma60_ratio', 'market_hangseng_ma120_ratio', 'market_hangseng_ma240_ratio',\n",
    "    'market_ftse_ma5_ratio', 'market_ftse_ma10_ratio', 'market_ftse_ma20_ratio',\n",
    "    'market_ftse_ma60_ratio', 'market_ftse_ma120_ratio', 'market_ftse_ma240_ratio',\n",
    "    'market_cac_ma5_ratio', 'market_cac_ma10_ratio', 'market_cac_ma20_ratio',\n",
    "    'market_cac_ma60_ratio', 'market_cac_ma120_ratio', 'market_cac_ma240_ratio',\n",
    "    'market_dax_ma5_ratio', 'market_dax_ma10_ratio', 'market_dax_ma20_ratio',\n",
    "    'market_dax_ma60_ratio', 'market_dax_ma120_ratio', 'market_dax_ma240_ratio',\n",
    "    'market_euronext_ma5_ratio', 'market_euronext_mas10_ratio', 'market_euronext_ma20_ratio',\n",
    "    'market_euronext_ma60_ratio', 'market_euronext_ma120_ratio', 'marekt_euronext_ma240_ratio',\n",
    "    'market_vix_ma5_ratio', 'market_vix_ma10_ratio', 'market_vix_ma20_ratio',\n",
    "    'market_vix_ma60_ratio', 'market_vix_ma120_ratio', 'market_vix_ma240_raito',\n",
    "    'market_shanghai_ma5_ratio', 'market_shanghai_ma10_ratio', 'market_shanghai_ma20_ratio',\n",
    "    'market_shanghai_ma60_ratio', 'market_shanghai_ma120_ratio', 'market_shanghai_ma240_ratio',\n",
    "]\n",
    "COLUMNS_BOND_ROLLING_DATA = [\n",
    "    'bond_us_13w_ma5_ratio', 'bond_us_13w_ma10_ratio', 'bond_us_13w_ma20_ratio',\n",
    "    'bond_us_13w_ma60_ratio', 'bond_us_13w_ma120_ratio', 'bond_us_12w_ma240_ratio',\n",
    "    'bond_us_5y_ma5_ratio', 'bond_us_5y_ma10_ratio', 'bond_us_5y_ma20_ratio',\n",
    "    'bond_us_5y_ma60_ratio', 'bond_us_5y_ma120_ratio', 'bond_us_5y_ma240_ratio',\n",
    "    'bond_us_10y_ma5_ratio', 'bond_us_10y_ma10_ratio', 'bond_us_10y_ma20_ratio',\n",
    "    'bond_us_10y_ma60_ratio', 'bond_us_10y_ma120_ratio', 'bond_us_10y_ma240_ratio',\n",
    "    'bond_us_30y_ma5_ratio', 'bond_us_30y_ma10_ratio', 'bond_us_30y_ma20_ratio',\n",
    "    'bond_us_30y_ma60_ratio', 'bond_us_30y_ma120_ratio', 'bond_us_30y_ma240_ratio',\n",
    "    'bond_kr_3y_ma5_ratio', 'bond_kr_3y_ma10_ratio', 'bond_kr_3y_ma20_ratio',\n",
    "    'bond_kr_3y_ma60_ratio', 'bond_kr_3y_ma120_ratio', 'bond_kr_3y_ma240_ratio',\n",
    "]\n",
    "COLUMNS_SECTOR_ROLLING_DATA = [\n",
    "    'sector_xlk_ma5_ratio', 'sector_xlk_ma10_ratio', 'sector_xlk_ma20_ratio',\n",
    "    'sector_xlk_ma60_ratio', 'sector_xlk_ma120_ratio', 'sector_xlk_ma240_ratio',\n",
    "    'sector_xlv_ma5_ratio', 'sector_xlv_ma10_ratio', 'sector_xlv_ma20_ratio',\n",
    "    'sector_xlv_ma60_ratio', 'sector_xlv_ma120_ratio', 'sector_xlv_ma240_ratio',\n",
    "    'sector_xly_ma5_ratio', 'sector_xly_ma10_ratio', 'sector_xly_ma20_ratio',\n",
    "    'sector_xly_ma60_ratio', 'sector_xly_ma120_ratio', 'sector_xly_ma240_ratio',\n",
    "    'sector_xlp_ma5_ratio', 'sector_xlp_ma10_ratio', 'sector_xlp_ma20_ratio',\n",
    "    'sector_xlp_ma60_ratio', 'sector_xlp_ma120_ratio', 'sector_xlp_ma240_ratio',\n",
    "    'sector_xle_ma5_ratio', 'sector_xle_ma10_ratio', 'sector_xle_ma20_ratio',\n",
    "    'sector_xle_ma60_ratio', 'sector_xle_ma120_ratio', 'sector_xle_ma240_ratio',\n",
    "    'sector_xlf_ma5_ratio', 'sector_xlf_ma10_ratio', 'sector_xlf_ma20_ratio',\n",
    "    'sector_xlf_ma60_ratio', 'sector_xlf_ma120_ratio', 'sector_xlf_ma240_ratio',\n",
    "    'sector_xli_ma5_ratio', 'sector_xli_ma10_ratio', 'sector_xli_ma20_ratio',\n",
    "    'sector_xli_ma60_ratio', 'sector_xli_ma120_ratio', 'sector_xli_ma240_ratio',\n",
    "    'sector_xlb_ma5_ratio', 'sector_xlb_ma10_ratio', 'sector_xlb_ma20_ratio',\n",
    "    'sector_xlb_ma60_raito', 'sector_xlb_ma120_ratio', 'sector_xlb_ma240_ratio',\n",
    "    'sector_xlre_ma5_ratio', 'sector_xlre_ma10_ratio', 'sector_xlre_ma20_ratio',\n",
    "    'sector_xlre_ma60_ratio', 'sector_xlre_ma120_ratio', 'sector_xlre_ma240_ratio',\n",
    "    'sector_xlu_ma5_ratio', 'sector_xlu_ma10_ratio', 'sector_xlu_ma20_ratio',\n",
    "    'sector_xlu_ma60_ratio', 'sector_xlu_ma120_ratio', 'sector_xlu_ma240_ratio',\n",
    "]\n",
    "\n",
    "COLUMNS_COMMODITY_ROLLING_DATA = [\n",
    "    'commodity_oil_ma5_ratio', 'commodity_oil_ma10_ratio', 'commodiy_oil_ma20_ratio',\n",
    "    'commodity_oil_ma60_ratio', 'commodity_oil_ma120_ratio', 'commodity_oil_ma240_ratio',\n",
    "    'commodity_gold_ma5_ratio', 'commodity_gold_ma10_ratio', 'commodity_gold_ma20_ratio',\n",
    "    'commodity_gold_ma60_ratio', 'commodity_gold_ma120_ratio', 'commodity_gold_ma240_ratio',\n",
    "    \n",
    "]\n",
    "\n",
    "# ratio data\n",
    "COLUMNS_STOCK_RATIO_DATA = [\n",
    "    'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio', 'low_close_ratio',\n",
    "    'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get price function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# get us stock price of a specific ticker\n",
    "def get_prices_from_ticker(ticker, fro=None, to=None):\n",
    "\n",
    "    # connect DB\n",
    "    engine = create_engine(f'mysql+pymysql://{user}:{pw}@{host}:{port}/{db}')\n",
    "\n",
    "    con = pymysql.connect(\n",
    "        user=user,\n",
    "        passwd=pw,\n",
    "        host=host,\n",
    "        db=db,\n",
    "        charset='utf8'\n",
    "    )\n",
    "            \n",
    "    mycursor = con.cursor()\n",
    "    \n",
    "    if fro is not None:\n",
    "        if to is not None:               \n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date BETWEEN '{fro}' AND '{to}' \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date >= '{fro}'\n",
    "                    \"\"\"\n",
    "    \n",
    "    else:\n",
    "        if to is not None:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date <= '{to}' \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    \"\"\"\n",
    "            \n",
    "    print(query)\n",
    "    prices = pd.read_sql(query, con=engine)\n",
    "    con.close()\n",
    "    engine.dispose()\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# str format on date, time\n",
    "FORMAT_DATE = '%Y%m%d'\n",
    "FORMAT_DATETIME = '%Y%m%d%H%M%S'\n",
    "\n",
    "def get_today_str():\n",
    "    today = datetime.datetime.combine(\n",
    "        datetime.date.today(), datetime.datetime.min.time()\n",
    "    )\n",
    "    today_str = today.strftime(FORMAT_DATE)\n",
    "    return today_str\n",
    "\n",
    "def get_time_str():\n",
    "    return datetime.datetime.fromtimestamp(\n",
    "        int(time.time())\n",
    "    ).strftime(FORMAT_DATETIME)\n",
    "    \n",
    "def sigmoid(x):\n",
    "    x = max(min(x, 10), -10)\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2010-01-01' AND '2020-12-31' \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "stock_code = 'AAPL'\n",
    "fro = '2010-01-01'\n",
    "to = '2020-12-31'\n",
    "df = get_prices_from_ticker(stock_code, fro=fro, to=to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>7.643214</td>\n",
       "      <td>6.470741</td>\n",
       "      <td>493729600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>7.664286</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>7.616071</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>6.481927</td>\n",
       "      <td>601904800.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>6.378825</td>\n",
       "      <td>552160000.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466071</td>\n",
       "      <td>7.520714</td>\n",
       "      <td>6.367032</td>\n",
       "      <td>477131200.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>7.510714</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466429</td>\n",
       "      <td>7.570714</td>\n",
       "      <td>6.409362</td>\n",
       "      <td>447610800.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>131.320007</td>\n",
       "      <td>133.460007</td>\n",
       "      <td>131.100006</td>\n",
       "      <td>131.970001</td>\n",
       "      <td>129.514481</td>\n",
       "      <td>54930100.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>137.339996</td>\n",
       "      <td>133.509995</td>\n",
       "      <td>136.690002</td>\n",
       "      <td>134.146637</td>\n",
       "      <td>124486200.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>132.360519</td>\n",
       "      <td>121047300.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>135.580002</td>\n",
       "      <td>135.990005</td>\n",
       "      <td>133.399994</td>\n",
       "      <td>133.720001</td>\n",
       "      <td>131.231888</td>\n",
       "      <td>96452100.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>134.080002</td>\n",
       "      <td>134.740005</td>\n",
       "      <td>131.720001</td>\n",
       "      <td>132.690002</td>\n",
       "      <td>130.221085</td>\n",
       "      <td>99116600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2769 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        high         low        open       close      volume  \\\n",
       "0     2010-01-04    7.622500    7.660714    7.585000    7.643214    6.470741   \n",
       "1     2010-01-05    7.664286    7.699643    7.616071    7.656429    6.481927   \n",
       "2     2010-01-06    7.656429    7.686786    7.526786    7.534643    6.378825   \n",
       "3     2010-01-07    7.562500    7.571429    7.466071    7.520714    6.367032   \n",
       "4     2010-01-08    7.510714    7.571429    7.466429    7.570714    6.409362   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2764  2020-12-24  131.320007  133.460007  131.100006  131.970001  129.514481   \n",
       "2765  2020-12-28  133.990005  137.339996  133.509995  136.690002  134.146637   \n",
       "2766  2020-12-29  138.050003  138.789993  134.339996  134.869995  132.360519   \n",
       "2767  2020-12-30  135.580002  135.990005  133.399994  133.720001  131.231888   \n",
       "2768  2020-12-31  134.080002  134.740005  131.720001  132.690002  130.221085   \n",
       "\n",
       "        adj_close ticker  \n",
       "0     493729600.0   AAPL  \n",
       "1     601904800.0   AAPL  \n",
       "2     552160000.0   AAPL  \n",
       "3     477131200.0   AAPL  \n",
       "4     447610800.0   AAPL  \n",
       "...           ...    ...  \n",
       "2764   54930100.0   AAPL  \n",
       "2765  124486200.0   AAPL  \n",
       "2766  121047300.0   AAPL  \n",
       "2767   96452100.0   AAPL  \n",
       "2768   99116600.0   AAPL  \n",
       "\n",
       "[2769 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_STOCK_RATIO_DATA = [\n",
    "    'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio', 'low_close_ratio',\n",
    "    'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "]\n",
    "\n",
    "def preprocess(data):\n",
    "    \n",
    "    # moving average\n",
    "    windows = [5, 10, 20, 60, 120, 240]\n",
    "    for window in windows:\n",
    "        data[f'close_ma{window}'] = data['close'].rolling(window).mean()\n",
    "        data[f'volume_ma{window}'] = data['volume'].rolling(window).mean()\n",
    "        data[f'close_ma{window}_ratio'] = (data['close'] - data[f'close_ma{window}']) / data[f'close_ma{window}']\n",
    "        data[f'volume_ma{window}_ratio'] = (data['volume'] - data[f'volume_ma{window}']) / data[f'volume_ma{window}']\n",
    "        data['open_close_ratio'] = (data['open'].values - data['close'].values) / data['close'].values\n",
    "        data['open_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'open_prev_close_ratio'] = (data['open'][1:].values - data['close'][:-1].values) / data['close'][:-1].values\n",
    "        data['high_close_ratio'] = (data['high'].values - data['close'].values) / data['close'].values\n",
    "        data['low_close_ratio'] = (data['low'].values - data['close'].values) / data['close'].values\n",
    "        data['close_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'close_prev_close_ratio'] = (data['close'][1:].values - data['close'][:-1].values) / data['close'][:-1].values \n",
    "        data['volume_prev_volume_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'volume_prev_volume_ratio'] = (\n",
    "            # if volume is 0, change it into non zero value exploring previous volume continuously\n",
    "            (data['volume'][1:].values - data['volume'][:-1].values) / data['volume'][:-1].replace(to_replace=0, method='ffill').replace(to_replace=0, method='bfill').values\n",
    "        )\n",
    "    \n",
    "    # Bollinger band\n",
    "    data['middle_bb'] = data['close'].rolling(20).mean()\n",
    "    data['upper_bb'] = data['middle_bb'] + 2 * data['close'].rolling(20).std()\n",
    "    data['lower_bb'] = data['middle_bb'] - 2 * data['close'].rolling(20).std()\n",
    "    data['bb_pb'] = (data['close'] - data['lower_bb']) / (data['upper_bb'] - data['lower_bb'])\n",
    "    data['bb_width'] = (data['upper_bb'] - data['lower_bb']) / data['middle_bb']\n",
    "    \n",
    "    # MACD\n",
    "    macd_short, macd_long, macd_signal = 12, 26, 9\n",
    "    data['ema_short'] = data['close'].ewm(macd_short).mean()\n",
    "    data['ema_long'] = data['close'].ewm(macd_long).mean()\n",
    "    data['macd'] = data['ema_short'] - data['ema_long']\n",
    "    data['macd_signal'] = data['macd'].ewm(macd_signal).mean()\n",
    "    data['macd_oscillator'] = data['macd'] - data['macd_signal']\n",
    "    \n",
    "    # RSI\n",
    "    data['close_change'] = data['close'].diff()\n",
    "    data['close_up'] = np.where(data['close_change']>=0, df['close_change'], 0)\n",
    "    # data['close_up'] = data['close_change'].apply(lambda x: x if x >= 0 else 0)\n",
    "    data['close_down'] = np.where(data['close_change'] < 0, df['close_change'].abs(), 0)\n",
    "    # data['close_down] = data['close_change'].apply(lambda x: -x if x < 0 else 0)\n",
    "    data['rs'] = data['close_up'].ewm(alpha=1/14, min_periods=14).mean() / data['close_down'].ewm(alpha=1/14, min_periods=14).mean()\n",
    "    data['rsi'] = 100 - (100 / (1 + data['rs']))\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_test(stock_code, fro, to):\n",
    "    df = get_prices_from_ticker(stock_code, fro, to)\n",
    "    df_adj = preprocess(df)\n",
    "    df_adj = df_adj[30:].reset_index(drop=True)\n",
    "    \n",
    "    return df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = df_adj[30:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7.233929\n",
       "1         7.247500\n",
       "2         7.202500\n",
       "3         7.157857\n",
       "4         7.037857\n",
       "           ...    \n",
       "2734    131.970001\n",
       "2735    136.690002\n",
       "2736    134.869995\n",
       "2737    133.720001\n",
       "2738    132.690002\n",
       "Name: close, Length: 2739, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close_ma5</th>\n",
       "      <th>volume_ma5</th>\n",
       "      <th>...</th>\n",
       "      <th>ema_short</th>\n",
       "      <th>ema_long</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_oscillator</th>\n",
       "      <th>close_change</th>\n",
       "      <th>close_up</th>\n",
       "      <th>close_down</th>\n",
       "      <th>rs</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>7.292500</td>\n",
       "      <td>7.296786</td>\n",
       "      <td>7.173571</td>\n",
       "      <td>7.233929</td>\n",
       "      <td>6.124241</td>\n",
       "      <td>436396800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.143714</td>\n",
       "      <td>6.047865</td>\n",
       "      <td>...</td>\n",
       "      <td>7.161910</td>\n",
       "      <td>7.212694</td>\n",
       "      <td>-0.050783</td>\n",
       "      <td>-0.048545</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>-0.030357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>1.028466</td>\n",
       "      <td>50.701667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-18</td>\n",
       "      <td>7.201071</td>\n",
       "      <td>7.281786</td>\n",
       "      <td>7.175714</td>\n",
       "      <td>7.247500</td>\n",
       "      <td>6.135730</td>\n",
       "      <td>422825200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.199500</td>\n",
       "      <td>6.095093</td>\n",
       "      <td>...</td>\n",
       "      <td>7.169045</td>\n",
       "      <td>7.214532</td>\n",
       "      <td>-0.045487</td>\n",
       "      <td>-0.048228</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.049367</td>\n",
       "      <td>51.204443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>7.209286</td>\n",
       "      <td>7.257143</td>\n",
       "      <td>7.182500</td>\n",
       "      <td>7.202500</td>\n",
       "      <td>6.097633</td>\n",
       "      <td>415469600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.220929</td>\n",
       "      <td>6.113235</td>\n",
       "      <td>...</td>\n",
       "      <td>7.171816</td>\n",
       "      <td>7.213907</td>\n",
       "      <td>-0.042091</td>\n",
       "      <td>-0.047595</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.976485</td>\n",
       "      <td>49.405125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-22</td>\n",
       "      <td>7.226429</td>\n",
       "      <td>7.232143</td>\n",
       "      <td>7.113929</td>\n",
       "      <td>7.157857</td>\n",
       "      <td>6.059838</td>\n",
       "      <td>390563600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.221214</td>\n",
       "      <td>6.113476</td>\n",
       "      <td>...</td>\n",
       "      <td>7.170666</td>\n",
       "      <td>7.211035</td>\n",
       "      <td>-0.040368</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>-0.044643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.909032</td>\n",
       "      <td>47.617442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-23</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>7.190357</td>\n",
       "      <td>6.989643</td>\n",
       "      <td>7.037857</td>\n",
       "      <td>5.958245</td>\n",
       "      <td>575094800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.175929</td>\n",
       "      <td>6.075137</td>\n",
       "      <td>...</td>\n",
       "      <td>7.159790</td>\n",
       "      <td>7.202286</td>\n",
       "      <td>-0.042496</td>\n",
       "      <td>-0.046405</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.757552</td>\n",
       "      <td>43.102673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>131.320007</td>\n",
       "      <td>133.460007</td>\n",
       "      <td>131.100006</td>\n",
       "      <td>131.970001</td>\n",
       "      <td>129.514481</td>\n",
       "      <td>54930100.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>129.940002</td>\n",
       "      <td>127.522238</td>\n",
       "      <td>...</td>\n",
       "      <td>124.557028</td>\n",
       "      <td>120.767285</td>\n",
       "      <td>3.789743</td>\n",
       "      <td>2.724778</td>\n",
       "      <td>1.064965</td>\n",
       "      <td>1.009995</td>\n",
       "      <td>1.009995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.112006</td>\n",
       "      <td>67.866386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>137.339996</td>\n",
       "      <td>133.509995</td>\n",
       "      <td>136.690002</td>\n",
       "      <td>134.146637</td>\n",
       "      <td>124486200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>131.946002</td>\n",
       "      <td>129.490912</td>\n",
       "      <td>...</td>\n",
       "      <td>125.490334</td>\n",
       "      <td>121.357015</td>\n",
       "      <td>4.133319</td>\n",
       "      <td>2.865632</td>\n",
       "      <td>1.267686</td>\n",
       "      <td>4.720001</td>\n",
       "      <td>4.720001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.787585</td>\n",
       "      <td>73.597952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>132.360519</td>\n",
       "      <td>121047300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>133.274002</td>\n",
       "      <td>130.794208</td>\n",
       "      <td>...</td>\n",
       "      <td>126.211846</td>\n",
       "      <td>121.857496</td>\n",
       "      <td>4.354350</td>\n",
       "      <td>3.014504</td>\n",
       "      <td>1.339846</td>\n",
       "      <td>-1.820007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.820007</td>\n",
       "      <td>2.176886</td>\n",
       "      <td>68.522632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>135.580002</td>\n",
       "      <td>135.990005</td>\n",
       "      <td>133.399994</td>\n",
       "      <td>133.720001</td>\n",
       "      <td>131.231888</td>\n",
       "      <td>96452100.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>133.642001</td>\n",
       "      <td>131.155362</td>\n",
       "      <td>...</td>\n",
       "      <td>126.789396</td>\n",
       "      <td>122.296848</td>\n",
       "      <td>4.492549</td>\n",
       "      <td>3.162309</td>\n",
       "      <td>1.330240</td>\n",
       "      <td>-1.149994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.149994</td>\n",
       "      <td>1.894467</td>\n",
       "      <td>65.451324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>134.080002</td>\n",
       "      <td>134.740005</td>\n",
       "      <td>131.720001</td>\n",
       "      <td>132.690002</td>\n",
       "      <td>130.221085</td>\n",
       "      <td>99116600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>133.988000</td>\n",
       "      <td>131.494922</td>\n",
       "      <td>...</td>\n",
       "      <td>127.243289</td>\n",
       "      <td>122.681779</td>\n",
       "      <td>4.561510</td>\n",
       "      <td>3.302229</td>\n",
       "      <td>1.259281</td>\n",
       "      <td>-1.029999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.029999</td>\n",
       "      <td>1.683766</td>\n",
       "      <td>62.738934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2739 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        high         low        open       close      volume  \\\n",
       "0     2010-02-17    7.292500    7.296786    7.173571    7.233929    6.124241   \n",
       "1     2010-02-18    7.201071    7.281786    7.175714    7.247500    6.135730   \n",
       "2     2010-02-19    7.209286    7.257143    7.182500    7.202500    6.097633   \n",
       "3     2010-02-22    7.226429    7.232143    7.113929    7.157857    6.059838   \n",
       "4     2010-02-23    7.142857    7.190357    6.989643    7.037857    5.958245   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2734  2020-12-24  131.320007  133.460007  131.100006  131.970001  129.514481   \n",
       "2735  2020-12-28  133.990005  137.339996  133.509995  136.690002  134.146637   \n",
       "2736  2020-12-29  138.050003  138.789993  134.339996  134.869995  132.360519   \n",
       "2737  2020-12-30  135.580002  135.990005  133.399994  133.720001  131.231888   \n",
       "2738  2020-12-31  134.080002  134.740005  131.720001  132.690002  130.221085   \n",
       "\n",
       "        adj_close ticker   close_ma5  volume_ma5  ...   ema_short    ema_long  \\\n",
       "0     436396800.0   AAPL    7.143714    6.047865  ...    7.161910    7.212694   \n",
       "1     422825200.0   AAPL    7.199500    6.095093  ...    7.169045    7.214532   \n",
       "2     415469600.0   AAPL    7.220929    6.113235  ...    7.171816    7.213907   \n",
       "3     390563600.0   AAPL    7.221214    6.113476  ...    7.170666    7.211035   \n",
       "4     575094800.0   AAPL    7.175929    6.075137  ...    7.159790    7.202286   \n",
       "...           ...    ...         ...         ...  ...         ...         ...   \n",
       "2734   54930100.0   AAPL  129.940002  127.522238  ...  124.557028  120.767285   \n",
       "2735  124486200.0   AAPL  131.946002  129.490912  ...  125.490334  121.357015   \n",
       "2736  121047300.0   AAPL  133.274002  130.794208  ...  126.211846  121.857496   \n",
       "2737   96452100.0   AAPL  133.642001  131.155362  ...  126.789396  122.296848   \n",
       "2738   99116600.0   AAPL  133.988000  131.494922  ...  127.243289  122.681779   \n",
       "\n",
       "          macd  macd_signal  macd_oscillator  close_change  close_up  \\\n",
       "0    -0.050783    -0.048545        -0.002238     -0.030357  0.000000   \n",
       "1    -0.045487    -0.048228         0.002741      0.013571  0.013571   \n",
       "2    -0.042091    -0.047595         0.005504     -0.045000  0.000000   \n",
       "3    -0.040368    -0.046852         0.006483     -0.044643  0.000000   \n",
       "4    -0.042496    -0.046405         0.003909     -0.120000  0.000000   \n",
       "...        ...          ...              ...           ...       ...   \n",
       "2734  3.789743     2.724778         1.064965      1.009995  1.009995   \n",
       "2735  4.133319     2.865632         1.267686      4.720001  4.720001   \n",
       "2736  4.354350     3.014504         1.339846     -1.820007  0.000000   \n",
       "2737  4.492549     3.162309         1.330240     -1.149994  0.000000   \n",
       "2738  4.561510     3.302229         1.259281     -1.029999  0.000000   \n",
       "\n",
       "      close_down        rs        rsi  \n",
       "0       0.030357  1.028466  50.701667  \n",
       "1       0.000000  1.049367  51.204443  \n",
       "2       0.045000  0.976485  49.405125  \n",
       "3       0.044643  0.909032  47.617442  \n",
       "4       0.120000  0.757552  43.102673  \n",
       "...          ...       ...        ...  \n",
       "2734    0.000000  2.112006  67.866386  \n",
       "2735    0.000000  2.787585  73.597952  \n",
       "2736    1.820007  2.176886  68.522632  \n",
       "2737    1.149994  1.894467  65.451324  \n",
       "2738    1.029999  1.683766  62.738934  \n",
       "\n",
       "[2739 rows x 53 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'high', 'low', 'open', 'close', 'volume', 'adj_close', 'ticker',\n",
       "       'close_ma5', 'volume_ma5', 'close_ma5_ratio', 'volume_ma5_ratio',\n",
       "       'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio',\n",
       "       'low_close_ratio', 'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
       "       'close_ma10', 'volume_ma10', 'close_ma10_ratio', 'volume_ma10_ratio',\n",
       "       'close_ma20', 'volume_ma20', 'close_ma20_ratio', 'volume_ma20_ratio',\n",
       "       'close_ma60', 'volume_ma60', 'close_ma60_ratio', 'volume_ma60_ratio',\n",
       "       'close_ma120', 'volume_ma120', 'close_ma120_ratio',\n",
       "       'volume_ma120_ratio', 'close_ma240', 'volume_ma240',\n",
       "       'close_ma240_ratio', 'volume_ma240_ratio', 'middle_bb', 'upper_bb',\n",
       "       'lower_bb', 'bb_pb', 'bb_width', 'ema_short', 'ema_long', 'macd',\n",
       "       'macd_signal', 'macd_oscillator', 'close_change', 'close_up',\n",
       "       'close_down', 'rs', 'rsi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock_code, fro, to):\n",
    "    df = get_prices_from_ticker(stock_code, fro=fro, to=to)\n",
    "    \n",
    "    # # sort ascending\n",
    "    # df = df[30:].sort_values(by='date').reset_index(drop=True)\n",
    "    # print(df)\n",
    "    \n",
    "    # preprocessing\n",
    "    df_adj = preprocess(df)\n",
    "    df_adj = df_adj[30:].reset_index(drop=True)\n",
    "    # df_adj = df_adj.fillna(method='ffill').reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    chart_data = df_adj[COLUMNS_STOCK_DATA]\n",
    "    training_data = df_adj[COLUMNS_TRAINING_DATA]\n",
    "    \n",
    "    return chart_data, training_data.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2010-01-01' AND '2020-12-23' \n",
      "                    \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2764,) (2769,) () ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_chart, training_chart \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAPL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2010-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2020-12-23\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(stock_code, fro, to)\u001b[0m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m get_prices_from_ticker(stock_code, fro\u001b[38;5;241m=\u001b[39mfro, to\u001b[38;5;241m=\u001b[39mto)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# # sort ascending\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# df = df[30:].sort_values(by='date').reset_index(drop=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# print(df)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# preprocessing\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df_adj \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m df_adj \u001b[38;5;241m=\u001b[39m df_adj[\u001b[38;5;241m30\u001b[39m:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# df_adj = df_adj.fillna(method='ffill').reset_index(drop=True)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# RSI\u001b[39;00m\n\u001b[0;32m     44\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdiff()\n\u001b[1;32m---> 45\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_up\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose_change\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose_change\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# data['close_up'] = data['close_change'].apply(lambda x: x if x >= 0 else 0)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_down\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_change\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mabs(), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2764,) (2769,) () "
     ]
    }
   ],
   "source": [
    "test_chart, training_chart = load_data('AAPL', '2010-01-01', '2020-12-23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# environment\n",
    "\n",
    "class Environment:\n",
    "    ''' \n",
    "    Attribute\n",
    "    ---------\n",
    "    - data : stock price data such as 'open', 'close', 'volume', 'bb', 'rsi', etc.\n",
    "    - state : current state\n",
    "    - idx : current postion of chart data\n",
    "    \n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize idx and state\n",
    "    - step() : move idx into next postion and get a new state\n",
    "    - get_price() : get close price of current state\n",
    "    - get_state() : get current state\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data=None):\n",
    "        self.PRICE_IDX = 4  # index postion of close price\n",
    "        self.data = data\n",
    "        self.state = None\n",
    "        self.idx = -1\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = None\n",
    "        self.idx = -1\n",
    "        \n",
    "    def step(self):\n",
    "        # if there is no more idx, return None\n",
    "        if len(self.data) > self.idx + 1:\n",
    "            self.idx += 1\n",
    "            self.state = self.data.iloc[self.idx]\n",
    "            return self.state\n",
    "        return None\n",
    "    \n",
    "    def get_price(self):\n",
    "        # return close price\n",
    "        if self.state is not None:\n",
    "            return self.state[self.PRICE_IDX]\n",
    "        return None\n",
    "    \n",
    "    def get_state(self):\n",
    "        # return current state\n",
    "        if self.state is not None:\n",
    "            return self.state\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.247499942779541"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Environment(df_adj)\n",
    "a.reset()\n",
    "a.step()\n",
    "a.step()\n",
    "a.get_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                         2010-02-19\n",
       "high                           7.209286\n",
       "low                            7.257143\n",
       "open                             7.1825\n",
       "close                            7.2025\n",
       "volume                         6.097633\n",
       "adj_close                   415469600.0\n",
       "ticker                             AAPL\n",
       "close_ma5                      7.220929\n",
       "volume_ma5                     6.113235\n",
       "close_ma5_ratio               -0.002552\n",
       "volume_ma5_ratio              -0.002552\n",
       "open_close_ratio              -0.002777\n",
       "open_prev_close_ratio         -0.008969\n",
       "high_close_ratio               0.000942\n",
       "low_close_ratio                0.007587\n",
       "close_prev_close_ratio        -0.006209\n",
       "volume_prev_volume_ratio      -0.006209\n",
       "close_ma10                     7.108893\n",
       "volume_ma10                    6.018385\n",
       "close_ma10_ratio               0.013168\n",
       "volume_ma10_ratio              0.013168\n",
       "close_ma20                     7.104196\n",
       "volume_ma20                    6.014409\n",
       "close_ma20_ratio               0.013837\n",
       "volume_ma20_ratio              0.013838\n",
       "close_ma60                          NaN\n",
       "volume_ma60                         NaN\n",
       "close_ma60_ratio                    NaN\n",
       "volume_ma60_ratio                   NaN\n",
       "close_ma120                         NaN\n",
       "volume_ma120                        NaN\n",
       "close_ma120_ratio                   NaN\n",
       "volume_ma120_ratio                  NaN\n",
       "close_ma240                         NaN\n",
       "volume_ma240                        NaN\n",
       "close_ma240_ratio                   NaN\n",
       "volume_ma240_ratio                  NaN\n",
       "middle_bb                      7.104196\n",
       "upper_bb                        7.42596\n",
       "lower_bb                       6.782433\n",
       "bb_pb                          0.652757\n",
       "bb_width                       0.090584\n",
       "ema_short                      7.171816\n",
       "ema_long                       7.213907\n",
       "macd                          -0.042091\n",
       "macd_signal                   -0.047595\n",
       "macd_oscillator                0.005504\n",
       "close_change                     -0.045\n",
       "close_up                            0.0\n",
       "close_down                        0.045\n",
       "rs                             0.976485\n",
       "rsi                           49.405125\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.step()\n",
    "a.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent\n",
    "import numpy as np\n",
    "\n",
    "class Agent:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - enviroment : instance of environment\n",
    "    - initial_balance : initial capital balance\n",
    "    - min_trading_price : minimum trading price\n",
    "    - max_trading_price : maximum trading price\n",
    "    - balance : cash balance\n",
    "    - num_stocks : obtained stocks\n",
    "    - portfolio_value : value of portfolios (balance + price * num_stocks)\n",
    "    - num_buy : number of buying\n",
    "    - num_sell : number of selling\n",
    "    - num_hold : number of holding\n",
    "    - ratio_hold : ratio of holding stocks\n",
    "    - profitloss : current profit or loss\n",
    "    - avg_buy_price_ratio : the ratio average price of a stock bought to the current price\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize an agent\n",
    "    - set_balance() : initialize balance\n",
    "    - get_states() : get the state of an agent\n",
    "    - decide_action() : exploration or exploitation behavior according to the policy net\n",
    "    - validate_action() : validate actions\n",
    "    - decide_trading_unit() : decide how many stocks are sold or bought\n",
    "    - act() : act the actions\n",
    "    '''\n",
    "    \n",
    "    # agent state dimensions\n",
    "    ## (ratio_hold, profit-loss ratio, current price to avg_buy_price ratio)\n",
    "    STATE_DIM = 3\n",
    "    \n",
    "    # trading charge and tax\n",
    "    TRADING_CHARGE = 0.00015    # trading charge 0.015%\n",
    "    TRADING_TAX = 0.02          # trading tax = 0.2%\n",
    "    \n",
    "    # action space\n",
    "    ACTION_BUY = 0      # buy\n",
    "    ACTION_SELL = 1     # sell\n",
    "    ACTION_HOLD = 2     # hold\n",
    "    \n",
    "    # get probabilities from neural nets\n",
    "    ACTIONS = [ACTION_BUY, ACTION_SELL, ACTION_HOLD]\n",
    "    NUM_ACTIONS = len(ACTIONS)      # output number from nueral nets\n",
    "    \n",
    "    def __init__(self, environment, initial_balance, min_trading_price, max_trading_price):\n",
    "        # get current price from the environment\n",
    "        self.environment = environment\n",
    "        self.initial_balance = initial_balance\n",
    "        \n",
    "        # minumum and maximum trainding price\n",
    "        self.min_trading_price = min_trading_price\n",
    "        self.max_trading_price = max_trading_price\n",
    "        \n",
    "        # attributes for an agent class\n",
    "        self.balance = initial_balance\n",
    "        self.num_stocks = 0\n",
    "        \n",
    "        # value of portfolio : balance + num_stocks * {current stock price}\n",
    "        self.portfolio_value = 0\n",
    "        self.num_buy = 0\n",
    "        self.num_sell = 0\n",
    "        self.num_hold = 0\n",
    "        \n",
    "        # the state of Agent class\n",
    "        self.ratio_hold = 0\n",
    "        self.profitloss = 0\n",
    "        self.avg_buy_price = 0\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.num_stocks = 0\n",
    "        self.portfolio_value = self.balance\n",
    "        self.num_buy = 0\n",
    "        self.num_sell = 0\n",
    "        self.num_hold = 0\n",
    "        self.ratio_hold = 0\n",
    "        self.profitloss = 0\n",
    "        self.avg_buy_price = 0\n",
    "        \n",
    "    def set_initial_balance(self, balance):\n",
    "        self.initial_balance = balance\n",
    "        \n",
    "    def get_states(self):\n",
    "        # return ratio hold, profit/loss ratio and \n",
    "        # ratio_hold = num_stokcs / (portfoilo_value / price) = (num_stocks * price) / portfolio_value\n",
    "        self.ratio_hold = self.num_stocks * self.environment.get_price() / self.portfolio_value\n",
    "        \n",
    "        return (\n",
    "            self.ratio_hold,\n",
    "            self.profitloss,        # profitloss = (portfolio_value / initial_balance) - 1\n",
    "            (self.environment.get_price() / self.avg_buy_price) - 1 if self.avg_buy_price > 0 else 0\n",
    "        )\n",
    "        \n",
    "    def decide_action(self, pred_value, pred_policy, epsilon):\n",
    "        # act randomly with epsilon probability, act according to neural network  with (1 - epsilon) probability\n",
    "        confidence = 0\n",
    "        \n",
    "        # if theres is a pred_policy, follow it, otherwise follow a pred_value\n",
    "        pred = pred_policy\n",
    "        if pred is None:\n",
    "            pred = pred_value\n",
    "            \n",
    "        # there is no prediction from both pred_policy and pred_value, explore!\n",
    "        if pred is None:\n",
    "            epsilon = 1\n",
    "        else:\n",
    "            maxpred = np.max(pred)\n",
    "            # if values for actions are euqal, explore!\n",
    "            if (pred == maxpred).all():\n",
    "                epsilon = 1\n",
    "        \n",
    "            # if the diffrence between buying and selling prediction policy value is less than 0.05, explore!\n",
    "            if pred_policy is not None:\n",
    "                if np.max(pred_policy) - np.min(pred_policy) < 0.05:\n",
    "                    epsilon = 1\n",
    "            # if pred is not None:\n",
    "            #     if np.max(pred) - np.min(pred) < 0.05:\n",
    "            #         epsilon = 1     \n",
    "                    \n",
    "        # decide whether exploration will be done or not\n",
    "        if np.random.ran() < epsilon:\n",
    "            exploration = True\n",
    "            action = np.random.randint(self.NUM_ACTIONS) \n",
    "        else: \n",
    "            exploration = False\n",
    "            action = np.argmax(pred)\n",
    "            \n",
    "        confidence = .5\n",
    "        if pred_policy is not None:\n",
    "            confidence = pred[action]  \n",
    "        elif pred_value is not None:\n",
    "            confidence = sigmoid(pred[action])\n",
    "            \n",
    "        return action, confidence, exploration\n",
    "    \n",
    "    def validate_action(self, action):\n",
    "        # validate if the action is available\n",
    "        if action == Agent.ACTION_BUY:\n",
    "            # check if al least one stock can be bought.\n",
    "            if self.balance < self.environment.get_price() * (1 + self.TRADING_CHARGE):\n",
    "                return False\n",
    "        elif action == Agent.ACTION_SELL:\n",
    "            # check if there is any sotck that can be sold\n",
    "            if self.num_stocks <= 0:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def decide_trading_unit(self, confidence):\n",
    "        # adjust number of stocks for buying and selling according to confidence level\n",
    "        if np.isnan(confidence):\n",
    "            return self.min_trading_price\n",
    "        \n",
    "        # set buying price range between self.min_trading_price + added_trading_price [min_trading_price, max_trading_price]\n",
    "        # in case that confidence > 1 causes the price over max_trading_price, we set min() so that the value cannot have larger value than self.max_trading_price - self.min_trading_price\n",
    "        # in case that confidence < 0, we set max() so that added_trading_price cannot have negative value.\n",
    "        added_trading_price = max(min(\n",
    "            int(confidence * (self.max_trading_price - self.min_trading_price)),\n",
    "            self.max_trading_price - self.min_trading_price\n",
    "        ), 0)\n",
    "        \n",
    "        trading_price = self.min_trading_price + added_trading_price\n",
    "        \n",
    "        return max(int(trading_price / self.environment.get_price()), 1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def act(self, action, confidence):\n",
    "        '''\n",
    "        Arguments\n",
    "        ---------\n",
    "        - action : decided action from decide_action() method based on exploration or exploitation (0 or 1)\n",
    "        - confidence : probabilitu from decide_action() method, the probability from policy network or the softmax probability from value network\n",
    "        '''\n",
    "        \n",
    "        if not self.validate_action(action):\n",
    "            action = Agent.ACTION_HOLD\n",
    "        \n",
    "        # get the price from the environment\n",
    "        curr_price = self.environment.get_price()\n",
    "        \n",
    "        # buy\n",
    "        if action == Agent.ACTION_BUY:\n",
    "            # decide how many stocks will be bought\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            balance = (\n",
    "                self.balance - curr_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            )\n",
    "            \n",
    "            # if lacks of balance, buy maximum units within the amount of money available\n",
    "            if balance < 0:\n",
    "                trading_unit = min(\n",
    "                    int(self.balance / (curr_price * (1 + self.TRADING_CHARGE))),\n",
    "                    int(self.max_trading_price / curr_price)\n",
    "                )\n",
    "                \n",
    "            # total amount of money with trading charge\n",
    "            invest_amount = curr_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            if invest_amount > 0:\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks + curr_price * trading_unit) / (self.num_stocks + trading_unit)\n",
    "                self.balance -= invest_amount\n",
    "                self.num_stocks += trading_unit\n",
    "                self.num_buy += 1\n",
    "                \n",
    "        # sell\n",
    "        elif action == Agent.ACTION_SELL:\n",
    "            # decide how many stocks will be sold\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            \n",
    "            # if lacks of stocks, sell maximum units available\n",
    "            trading_unit = min(trading_unit, self.num_stocks)\n",
    "            \n",
    "            # selling amount\n",
    "            invest_amount = curr_price * (\n",
    "                1 - (self.TRADING_TAX + self.TRADING_CHARGE)\n",
    "            ) * trading_unit\n",
    "            \n",
    "            if invest_amount > 0:\n",
    "                # update average buy price\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks - curr_price * trading_unit) / (self.num_stocks - trading_unit) if self.num_stocks > trading_unit else 0\n",
    "                self.num_stocks -= trading_unit\n",
    "                self.balance += invest_amount\n",
    "                self.num_sell += 1\n",
    "                \n",
    "        # hold\n",
    "        elif action == Agent.ACTION_HOLD:\n",
    "            self.num_hold += 1\n",
    "            \n",
    "        # update portfolio value\n",
    "        self.portfolio_value = self.balance + curr_price * self.num_stocks\n",
    "        self.profitloss = self.portfolio_value / self.initial_balance - 1\n",
    "        \n",
    "        return self.profitloss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import abc\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as FORMAT_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    ''' \n",
    "    Common attributes and methods for neural networks\n",
    "    \n",
    "    Attributes\n",
    "    ---------\n",
    "    - input_dim\n",
    "    - output_dim\n",
    "    - lr : learning rate\n",
    "    - shared_network : head of neural network which is shared with various networks (e.g., A2C)\n",
    "    - activation : activation layer function ('linear', 'sigmoid', 'tanh', 'softmax')\n",
    "    - loss : loss function for networks\n",
    "    - model : final neural network model\n",
    "    \n",
    "    Functions\n",
    "    ---------\n",
    "    - predict() : calculate value or probability of actions\n",
    "    - train_on_batch() : generate batch data for training\n",
    "    - save_model()\n",
    "    - load_model()\n",
    "    - get_share_network() : generate network head according to the networks\n",
    "    '''\n",
    "    \n",
    "    # # threa lock for A3C\n",
    "    # lock = threading.Lock()\n",
    "    \n",
    "    def __init__(self, input_dim=0, output_dim=0, num_steps=1, lr=0.001,\n",
    "                 shared_network=None, activation='sigmoid', loss='mse'):\n",
    "        self.input_dim = input_dim\n",
    "        self.outpu_dim = output_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.shared_network = shared_network\n",
    "        self.activation = activation\n",
    "        self.loss = loss\n",
    "        \n",
    "        # data shape for various networks\n",
    "        # CNN, LSTMNetwork has 3 dimensional shape, so we set input shape as (num_stpes, input_dim). In DNN, we set input shape as (input_dim, )\n",
    "        inp = None\n",
    "        if self.num_steps > 1:\n",
    "            inp = (self.num_steps, input_dim)\n",
    "        else:\n",
    "            inp = (self.input_dim,)\n",
    "        \n",
    "        # in case that shared_network is used\n",
    "        self.head = None\n",
    "        if self.shared_network is None:\n",
    "            self.head = self.get_network_head(inp, self.outpu_dim)\n",
    "        else:\n",
    "            self.head = self.shared_network\n",
    "            \n",
    "        # neural network model\n",
    "        ## generate network model for head\n",
    "        self.model = torch.nn.Sequential(self.head)\n",
    "        if self.activation == 'linear':\n",
    "            pass\n",
    "        elif self.activation == 'relu':        \n",
    "            self.model.add_module('activation', torch.nn.ReLU())   \n",
    "        elif self.activation == 'leaky_relu':\n",
    "            self.model.add_module('activation', torch.nn.LeakyReLU()) \n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.model.add_module('activation', torch.nn.Sigmoid())\n",
    "        elif self.activation == 'tanh':\n",
    "            self.model.add_module('activation', torch.nn.Tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            self.model.add_module('activation', torch.nn.Softmax(dim=1))\n",
    "        self.model.apply(Network.init_weights)\n",
    "        self.model.to(device)\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = None\n",
    "        if loss == 'mse':\n",
    "            self.criterion = torch.nn.MSELoss()\n",
    "        elif loss == 'binary_crossentropy':\n",
    "            self.criterion = torch.nn.BCELoss()\n",
    "            \n",
    "    def predict(self, sample):\n",
    "        # return prediction of buy, sell and hold on given sample\n",
    "        # value network returns each actions' values on sample and policy network returns each actions' probabilities on sample\n",
    "        with self.lock:\n",
    "            # transform evaluation mode : deavtivate module used only on traininig such as Drop out\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(sample).float().to(device)\n",
    "                pred = self.model(x).detach().cpu().numpy()\n",
    "                pred = pred.flatten()\n",
    "            return pred\n",
    "        \n",
    "    def train_on_batch(self, x, y):\n",
    "        if self.num_steps > 1:\n",
    "            x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "        else:\n",
    "            x = np.array(x).reshape((-1, self.input_dim))\n",
    "        loss = 0\n",
    "        with self.lock:\n",
    "            # transform training mode\n",
    "            self.model.train()\n",
    "            _x = torch.from_numpy(x).float().to(device)\n",
    "            _y = torch.from_numpy(y).float().to(device)\n",
    "            y_pred = self.model(_x)\n",
    "            _loss = self.criterion(y_pred, _y)\n",
    "            self.optimizer.zero_grad()\n",
    "            _loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss += _loss.item()\n",
    "        return loss\n",
    "    \n",
    "    @classmethod\n",
    "    def get_shared_network(cls, net='dnn', num_steps=1, input_dim=0, output_dim=0):\n",
    "        if net == 'dnn':\n",
    "            return DNN.get_network_head((input_dim, ), output_dim)\n",
    "        elif net == 'lstm':\n",
    "            return LSTMNetwork.get_network_head((num_steps, input_dim), output_dim)\n",
    "        elif net == 'cnn':\n",
    "            return CNN.get_network_head((num_steps, input_dim), output_dim)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_weihgts(m):\n",
    "        # initialize weights as weighted normal distribution\n",
    "        if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv1d):\n",
    "            torch.nn.init.normal_(m.weight, std=0.01)\n",
    "        elif isinstance(m, torch.nn.LSTM):\n",
    "            for weights in m.all_weights:\n",
    "                for weight in weights:\n",
    "                    torch.nn.init.normal_(weight, std=0.01)\n",
    "                    \n",
    "    def save_model(self, model_path):\n",
    "        if model_path is not None and self.model is not None:\n",
    "            torch.save(self.model, model_path)\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        if model_path is not None:\n",
    "            self.model = torch.load(model_path)\n",
    "            \n",
    "class DNN(Network):\n",
    "    @staticmethod\n",
    "    def get_network_head(inp, outpu_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),   # input shape = (input_dim, )\n",
    "            torch.nn.Linear(inp[0], 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, outpu_dim),\n",
    "        )\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((1, self.input_dim))\n",
    "        return super().predict(sample)\n",
    "    \n",
    "class LSTMNetwork(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            LSTMModule(inp[1], 128, batch_fist=True, use_last_only=True),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim),\n",
    "        )\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((-1, self.num_steps, self.input_dim))\n",
    "        return super().predict(sample)\n",
    "    \n",
    "class LSTMModule(torch.nn.LSTM):\n",
    "    def __init__(self, *args, use_last_only=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.use_last_only = use_last_only\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (h_n, _) = super().forward(x)\n",
    "        if self.use_last_only:\n",
    "            return h_n[-1]\n",
    "        return output\n",
    "    \n",
    "class CNN(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        kernel_size = 2\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            torch.nn.Conv1d(inp[0], 1, kernel_size),\n",
    "            torch.nn.BatchNorm1d(1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(inp[1] - (kernel_size - 1), 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim)\n",
    "        )\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((1, self.num_steps, self.input_dim))\n",
    "        return super().predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "class Visualizer:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - fig : matplotlib Figure instance plays like a canvas\n",
    "    - plot() : print charts except daily price chart\n",
    "    - save() : save Figure as an image file\n",
    "    - clear() : initialze all chart but daily price chart\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    - Figure title : parameter, epsilon\n",
    "    - Axes 1 : daily price chart\n",
    "    - Axes 2 : number of stocks and agent action chart\n",
    "    - Axes 3 : value network chart\n",
    "    - Axes 4 : policy network and epsilon chart\n",
    "    - Axes 5 : Portfolio value and learning point chart\n",
    "    '''\n",
    "    \n",
    "    COLORS = ['r', 'b', 'g']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.canvas = None \n",
    "        self.fig = None\n",
    "        self.axes = None\n",
    "        self.title = ''\n",
    "        self.x = []\n",
    "        self.xticks = []\n",
    "        self.xlabels = []\n",
    "        \n",
    "    def prepare(self, data, title):\n",
    "        self.title = title\n",
    "        # shared x-axis among all charts\n",
    "        # self.x = np.arange(data['date'])\n",
    "        # self.x_label = [datetime.strptime(date, '%Y%m%d').date() for date in data['date']]\n",
    "        with lock:\n",
    "            # preare for printing five charts\n",
    "            self.fig, self.axes = plt.subplots(\n",
    "                nrows=5, ncols=1, facecolor='w', sharex=True\n",
    "            )\n",
    "            for ax in self.axes:\n",
    "                # deactivate scientific marks\n",
    "                ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                # change y-axis to the right\n",
    "                ax.yais.tick_right()\n",
    "            \n",
    "            # chart 1. daily price data\n",
    "            self.axes[0].set_ylabel('Env.')\n",
    "            x = np.arange(len(data))\n",
    "            # make two dimensional array with open, high, low and close order\n",
    "            ohlc = np.hstack((\n",
    "                x.reshape(-1, 1), np.array(data[:, 1:5])\n",
    "            ))\n",
    "            # red for positive, blue for negative\n",
    "            candlestick_ohlc(self.axes[0], ohlc, colorup='r', colordown='b')\n",
    "            # visulize volume\n",
    "            ax = self.axes[0].twinx()\n",
    "            volume = np.array(data)[:, 5].tolist()\n",
    "            ax.bar(x, volume, color='b', alpha=0.3)\n",
    "            # set x-axis\n",
    "            self.x = np.arange(len(data['date']))\n",
    "            self.xticks = data.index[[0, -1]]\n",
    "            self.xlabels = data.iloc[[0, -1]]['date']\n",
    "            \n",
    "            \n",
    "    def plot(self, epoch_str=None, num_epochs=None, epsilon=None,\n",
    "             action_list=None, actions=None, num_stocks=None,\n",
    "             outvals_value=[], outvals_policy=[], exps=None,\n",
    "             initial_balance=None, pvs=None):\n",
    "        ''' \n",
    "        Attributes\n",
    "        ---------\n",
    "        - epoch_str : epoch for Figure title\n",
    "        - num_epochs : number of total epochs\n",
    "        - epsilon : exploration rate\n",
    "        - action_list : total action list of an agent\n",
    "        - num_stocks : number of stocks\n",
    "        - outvals_value : output array of value network\n",
    "        - outvals_policy : ouput array of policy network\n",
    "        - exps : array whether exploration is true or not\n",
    "        - initial_balance \n",
    "        - pvs : array of portfolio value\n",
    "        '''\n",
    "        \n",
    "        with lock:\n",
    "            # action, num_stocks, outvals_value, outvals_policy, pvs has same size\n",
    "            # create an array with same size as actions and use as x-axis\n",
    "            actions = np.array(actions)     # action array of an agent\n",
    "            # turn value network output as an array\n",
    "            outvals_value = np.array(outvals_value)\n",
    "            # turn policy network output as an array\n",
    "            outvals_policy = np.array(outvals_policy)\n",
    "            # turn initial balance as an array\n",
    "            pvs_base = np.zeros(len(actions)) + initial_balance     # array([initial_balance, initial_balance, initial_balance, ...])\n",
    "            \n",
    "            # chart 2. agent states (action, num_stocks)\n",
    "            for action, color in zip(action_list, self.COLORS):\n",
    "                for i in self.x[actions == action]:\n",
    "                    # express actions as background color : red for buying, blue for selling\n",
    "                    self.axes[1].axvline(i, color=color, alpha=0.1)\n",
    "            self.axes[1].plot(self.x, num_stocks, '-k')     # plot number of stocks\n",
    "            \n",
    "            # chart 3. value network (prediction value for action)\n",
    "            if (len(outvals_value)) > 0:\n",
    "                max_actions = np.argmax(outvals_value, axis=1)\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    # plot background\n",
    "                    for idx in self.x:\n",
    "                        if max_actions[idx] == action:\n",
    "                            self.axes[2].axvline(idx, color=color, alpha=0.1)\n",
    "                    # plot value network\n",
    "                    ## red for buying, blue for selling, green for holding\n",
    "                    ## if no prediction for action, no plot green chart\n",
    "                    self.axes[2].plot(self.x, outvals_policy[:, action], color=color, linestyle='-')\n",
    "            \n",
    "            # chart 4. policy network\n",
    "            # plot exploration as yellow background\n",
    "            for exp_idx in exps:\n",
    "                self.axes[3].axvline(exp_idx, color='y')\n",
    "            # plot action as background\n",
    "            _outvals = outvals_policy if len(outvals_policy) > 0 else outvals_value\n",
    "            for idx, outval in zip(self.x, _outvals):\n",
    "                color = 'white'\n",
    "                if np.isnan(outval.max()):\n",
    "                    continue\n",
    "                # with no exploration area, red for buying, blue for selling\n",
    "                if outval.argmax() == Agent.ACTION_BUY:\n",
    "                    color = self.COLORS[0]      # red for buying\n",
    "                elif outval.argmax() == Agent.ACTION_SELL:\n",
    "                    color = self.COLORS[1]      # blue for selling\n",
    "                elif outval.argmax() == Agent.ACTION_HOLD:\n",
    "                    color = self.COLORS[2]      # green for holding\n",
    "                self.axes[3].axvline(idx, color=color, alpha=0.1)\n",
    "                \n",
    "            # plot policy network\n",
    "            # red for buying policy network output, blue for selling policy network\n",
    "            # when red line is above blue line, buy stocks, otherwise sell stocks\n",
    "            if len(outvals_policy) > 0:\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    self.axes[3].plot(\n",
    "                        self.x, outvals_policy[:, action],\n",
    "                        color=color, linestyle='-'\n",
    "                    )\n",
    "                    \n",
    "            # chart 5. portfolio value\n",
    "            # horzontal line for initial balance\n",
    "            self.axes[4].axhline(\n",
    "                self.x, pvs, pvs_base,\n",
    "                where=pvs > pvs_base, facecolor='r', alpha=0.1\n",
    "            )\n",
    "            self.axes[4].plot(self.x, pvs, '-k')\n",
    "            self.axes[4].xaxis.set_ticks(self.xticks)\n",
    "            self.axes[4].xaxis.set_ticklabels(self.xlabels)\n",
    "            \n",
    "            # epoch and exploration rate\n",
    "            self.fig.suptitle(f'{self.title}\\nEPOCH:{epoch_str}/{num_epochs} EPSILON:{epsilon:.2f}')\n",
    "            # adjust canvas layout\n",
    "            self.fig.tight_layout()\n",
    "            self.fig.subplots_adjust(top=0.85)\n",
    "            \n",
    "    def clear(self, xlim):\n",
    "        with lock:\n",
    "            _axes = self.axes.tolist()\n",
    "            # intial chart except non changeable value\n",
    "            for ax in _axes[1:]:\n",
    "                ax.cla()        # initialize chart\n",
    "                ax.relim()      # initialize limit\n",
    "                ax.autoscale()  # reset scale\n",
    "            \n",
    "            # reset y-axis label\n",
    "            self.axes[1].set_ylabel('Agent')\n",
    "            self.axes[2].set_ylabel('V')\n",
    "            self.axes[3].set_ylabel('P')\n",
    "            self.axes[4].set_ylabel('PV')\n",
    "            for ax in _axes:\n",
    "                ax.set_xlim(xlim)       # reset limit in x-axis\n",
    "                ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_magor_formatter().get_scientific(False)\n",
    "                # set equal width horizontally\n",
    "                ax.ticklabel_format(useOffset=False)\n",
    "                \n",
    "    def save(self, path):\n",
    "        with lock:\n",
    "            self.fig.savefig(path)\n",
    "            \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 100., 100.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [0, 1, 2]\n",
    "pvs = np.zeros(len(actions)) + 100\n",
    "pvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQNLearner (Reinforce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import abc \n",
    "import collections\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "LOGGER_NAME = 'rltrader'\n",
    "logger = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.path.pardir))\n",
    "\n",
    "class ReinforcementLearner:\n",
    "    ''' \n",
    "    Attributes\n",
    "    ----------\n",
    "    - stock_code\n",
    "    - data : stock data\n",
    "    - environment\n",
    "    - agent\n",
    "    - training_data\n",
    "    - value_network\n",
    "    - policy_network\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - init_value_network() : function for creating value network\n",
    "    - init_policy_network() : function for creating policy network\n",
    "    - build_sample() : get samples from environment instances\n",
    "    - get_batch() : create batch training data\n",
    "    - update_network() : training value network and policy network\n",
    "    - fit() : request train value and policy network\n",
    "    - run() : perform reinforcement learning\n",
    "    - save_models() : save value and policy network\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, rl_method='dqn', stock_code=None,\n",
    "                 data=None, tradinig_data=None, \n",
    "                 min_trading_price=100, max_trading_price=10000,\n",
    "                 net='dnn', num_steps=1, lr=0.0005,\n",
    "                 discount_factor=0.9, num_epochs=1000,\n",
    "                 balance=100000, start_epsilon=1,\n",
    "                 value_network=None, policy_network=None,\n",
    "                 output_path='', resue_models=True, gen_output=True):\n",
    "        ''' \n",
    "        Attributes\n",
    "        ---------\n",
    "        - rl_method : reinforcement learning method 'dqn', 'pg', 'ac', 'a2c', 'a3c', 'ppo', ...\n",
    "        - stock_code\n",
    "        - data\n",
    "        - training_data : preprocessed data\n",
    "        - min_trading_price, max_trading_price\n",
    "        - net : network. 'dnn', 'lstm', 'cnn'\n",
    "        - n_steps : LTSM, CNN sequence length\n",
    "        - lr : learning rate\n",
    "        - discount_rate\n",
    "        - num_epochs : number of training epochs\n",
    "        - balance : initial balance\n",
    "        - start_epsilon\n",
    "        - value_network, policy_network\n",
    "        - output_path \n",
    "        - reuse_models\n",
    "        '''\n",
    "        \n",
    "        # check arguments\n",
    "        assert min_trading_price > 0\n",
    "        assert max_trading_price > 0\n",
    "        assert max_trading_price >= min_trading_price\n",
    "        assert num_epochs > 0\n",
    "        assert lr > 0\n",
    "        \n",
    "        # set reinforcement learning\n",
    "        self.rl_method = rl_method\n",
    "        self.discount_factor = discount_factor\n",
    "        self.num_epochs = num_epochs\n",
    "        self.start_epsilon = start_epsilon\n",
    "        \n",
    "        # set environment\n",
    "        self.stock_code = stock_code\n",
    "        self.data = data\n",
    "        self.environment = Environment(data)\n",
    "        \n",
    "        # set agent\n",
    "        self.agent = Agent(self.environment, balance, min_trading_price, max_trading_price)\n",
    "        \n",
    "        # training data\n",
    "        self.training_data = tradinig_data\n",
    "        self.sample = None\n",
    "        self.training_data_idx = -1\n",
    "        \n",
    "        # vector size = training vector size + agent state size\n",
    "        self.num_features = self.agent.STATE_DIM\n",
    "        if self.training_data is not None:\n",
    "            self.num_features += self.training_data.shape[1]\n",
    "        \n",
    "        # set network\n",
    "        self.net = net\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.value_network = value_network\n",
    "        self.policy_network = policy_network\n",
    "        self.reuse_models = resue_models\n",
    "        \n",
    "        # visualization module\n",
    "        self.visualizer = Visualizer()\n",
    "        \n",
    "        # memeory\n",
    "        self.memory_sample = []     # training data sample\n",
    "        self.memory_action = []     # actions taken\n",
    "        self.memory_reward = []     # reward obtained\n",
    "        self.memory_value = []      # prediction value for action\n",
    "        self.memory_policy = []     # prediction probability for action\n",
    "        self.memory_pv = []         # portfolio value\n",
    "        self.memory_num_stocks = [] # number of stocks\n",
    "        self.memory_exp_idx = []    # exploration index\n",
    "        \n",
    "        # exploration epoch info\n",
    "        self.loss = 0               # loss during epoch\n",
    "        self.itr_cnt = 0            # number of iterations with profit\n",
    "        self.exploration_cnt = 0    # count of exploration\n",
    "        self.batch_size = 0         # number of training\n",
    "        \n",
    "        # log output\n",
    "        self.output_path = output_path\n",
    "        self.gen_output = gen_output\n",
    "        \n",
    "    def init_value_network(self, shared_network=None, activation='linear', loss='mse'):\n",
    "        if self.net == 'dnn':\n",
    "            self.value_network = DNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=actions, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'cnn':\n",
    "            self.value_network = CNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'lstm':\n",
    "            self.value_network = LSTMNetwork(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        if self.reuse_models and os.path.exists(self.value_network_path):\n",
    "            self.value_network.load_model(model_path=self.value_network_path)\n",
    "            \n",
    "    def init_policy_network(self, shared_network=None, activation='sigmoid', loss='binary_crossentropy'):\n",
    "        if self.net == 'dnn':\n",
    "            self.policy_network = DNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "        \n",
    "        elif self.net == 'lstm':\n",
    "            self.policy_network == LSTMNetwork(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'cnn':\n",
    "            self.policy_network == CNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        if self.reuse_models and os.path.exists(self.policy_network_path):\n",
    "            self.policy_network.load_model(model_path=self.policy_network_path)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.sample = None\n",
    "        self.training_data_idx = -1\n",
    "        \n",
    "        # reset environment\n",
    "        self.environment.reset()\n",
    "        \n",
    "        # reset agent\n",
    "        self.agent.reset()\n",
    "        \n",
    "        # reset visualizer\n",
    "        self.visualizer.clear([0, len(self.data)])\n",
    "        \n",
    "        # reset memories\n",
    "        self.memory_sample = []\n",
    "        self.memory_action = []\n",
    "        self.memory_reward = []\n",
    "        self.memory_value = []\n",
    "        self.memory_policy = []\n",
    "        self.memory_pv = []\n",
    "        self.memory_num_stocks = []\n",
    "        self.memory_exp_idx = []\n",
    "        \n",
    "        # reset epoch info\n",
    "        self.loss = 0\n",
    "        self.itr_cnt = 0\n",
    "        self.exploration_cnt = 0\n",
    "        self.batch_size = 0\n",
    "        \n",
    "    def build_sample(self):\n",
    "        # get next index data\n",
    "        self.environment.observe()\n",
    "        # 47 samples + 3 agnet states = 50 features\n",
    "        if len(self.training_data) > self.training_data_idx + 1:\n",
    "            self.training_data_idx += 1\n",
    "            self.sample = self.training_data[self.training_data_idx].tolist()\n",
    "            self.sample.extend(self.agent.get_states())\n",
    "            return self.sample\n",
    "        return None\n",
    "    \n",
    "    # abstract method\n",
    "    @abc.abstractmethod\n",
    "    def get_batch(self):\n",
    "        pass\n",
    "    \n",
    "    # after generate batch data, call train_on_batch() medho to train value network and policy network\n",
    "    # value network : DQNLearner, ActorCriticLearner, A2CLearner\n",
    "    # policy network : PolicyGradientLearner, ActorCriticLearner, A2CLearner\n",
    "    # loss value after training is saves as instance. in case of training value and policy network return sum of both loss\n",
    "    def fit(self):\n",
    "        # generate batch data\n",
    "        x, y_value, y_policy = self.get_batch()\n",
    "        # initialize loss\n",
    "        self.loss = None\n",
    "        if len(x) > 0:\n",
    "            loss = 0\n",
    "            if y_value is not None:\n",
    "                # update value network\n",
    "                loss += self.value_network.train_on_batch(x, y_value)\n",
    "            if y_policy is not None:\n",
    "                # update policy network\n",
    "                loss += self.value_network.train_on_batch(x, y_policy)\n",
    "            self.loss = loss\n",
    "            \n",
    "    # visualize one complete epoch\n",
    "    # in case of LSTM, CNN agent, the number of agent's actions, num_stocks, output of value network, output of policy network and portfolio value is less than daily price data by (num_steps -1). So we fill (num_steps -1) meaningless data \n",
    "    def visualize(self, epoch_str, num_epochs, epsilon):\n",
    "        self.memory_action = [Agent.ACTION_HOLD] * (self.num_steps - 1) + self.memory_action\n",
    "        self.memory_num_stocks = [0] * (self.num_steps - 1) + self.memory_num_stocks\n",
    "        if self.value_network is not None:\n",
    "            self.memory_value = [np.array([np.nan] * len(Agent.ACTIONS))] * (self.num_steps - 1) + self.memory_value\n",
    "        if self.policy_network is not None:\n",
    "            self.memory_policy = [np.array([np.nan] * len(Agent.ACTIONS))] * (self.num_steps - 1) + self.memory_policy\n",
    "        \n",
    "        self.memory_pv = [self.agent.initial_balance] * (self.num_steps - 1) + self.memory_pv\n",
    "        self.visualizer.plot(\n",
    "            epoch_str=epoch_str, num_epochs=num_epochs,\n",
    "            epsilon=epsilon, action_list=Agent.ACTIONS,\n",
    "            actions=self.memory_action,\n",
    "            num_stocks=self.memory_num_stocks,\n",
    "            outvals_value=self.memory_value,\n",
    "            outvals_policy=self.memory_policy,\n",
    "            exps=self.memory_exp_idx,\n",
    "            initial_balance=self.agent.initial_balance,\n",
    "            pvs=self.memory_pv,\n",
    "        )\n",
    "        self.visualizer.save(os.path.join(self.epoch_summary_dir, f'epoch_summary_{epoch_str}.png'))\n",
    "                             \n",
    "    def run(self, learning=True):\n",
    "        '''\n",
    "        Arguments\n",
    "        ---------\n",
    "        - learning : boolean if learning will be done or not\n",
    "            - True : after training, build value and policy network\n",
    "            - False: simulation with pretrined model\n",
    "        '''\n",
    "        info = (\n",
    "            f'[{self.stock_code}] RL:{self.lr_method} NET:{self.net}'\n",
    "            f'LR:{self.kr} DF:{self.discount_factor}'\n",
    "        )\n",
    "        with self.lock:\n",
    "            logger.debug(info)\n",
    "        \n",
    "        # start time\n",
    "        time_start = time.time()\n",
    "        \n",
    "        # prepare visualization\n",
    "        self.visualizer.prepare(self.environment.data, info)\n",
    "        \n",
    "        # prepare folders foe saving results\n",
    "        if self.gen_output:\n",
    "            self.epoch_summary_dir = os.path.join(self.output_path, f'epoch_summary_{self.stock_code}')\n",
    "            if not os.path.isdir(self.epoch_summary_dir):\n",
    "                os.makedirs(self.epoch_summary_dir)\n",
    "            else:\n",
    "                for f in os.listdir(self.epoch_summary_dir):\n",
    "                    os.remove(os.path.join(self.epoch_summary_dir, f))\n",
    "                    \n",
    "        # reset info about training\n",
    "        # save the most highest portfolio value at max_portfolio_value variable\n",
    "        max_portfolio_value = 0\n",
    "        # save the count of epochs with profit\n",
    "        epoch_cnt = 0\n",
    "        \n",
    "        # iterate epochs\n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            # start time of an epoch\n",
    "            time_start_epoch = time.time()\n",
    "            \n",
    "            # queue for making step samples\n",
    "            q_sample = collections.deque(maxlen=self.num_steps)\n",
    "            \n",
    "            # reset environment, networks, visualizer and memories\n",
    "            self.reset()\n",
    "            \n",
    "            # decaying exploration rate\n",
    "            if learning:\n",
    "                epsilon = self.start_epsilon * (1 - (epoch / (self.num_epochs - 1)))\n",
    "            else:\n",
    "                epsilon = self.start_epsilon\n",
    "                \n",
    "            for i in tqdm(range(len(self.training_data)), leave=False):\n",
    "                # create samples\n",
    "                next_sample = self.build_sample()\n",
    "                if next_sample is None:\n",
    "                    break\n",
    "                \n",
    "                # save samples until its size becomes as num_steps\n",
    "                q_sample.append(next_sample)\n",
    "                if len(q_sample) < self.num_steps:\n",
    "                    continue\n",
    "                \n",
    "                # prediction of value and policyn entwork\n",
    "                pred_value = None\n",
    "                pred_policy = None\n",
    "                # get predicted value of actions\n",
    "                if self.value_network is not None:\n",
    "                    pred_value = self.value_network.predict(list(q_sample))\n",
    "                # get predicted probabilities of actions\n",
    "                if self.policy_network is not None:\n",
    "                    pred_policy = self.policy_network.predict(list(q_sample))\n",
    "                    \n",
    "                # make decisions based on predicted value and probabilities\n",
    "                # decide actions based on based on networks or exploration\n",
    "                # decide actions randomly with epsilon probability or according to network output with (1 - epsilon)\n",
    "                # policy network output is the probabilities that selling or buying increase portfolio value. if output for buying is larger than that for selling, then buy the stock. Otherwise, sell it.\n",
    "                # if there is no output of policy network, select the action with the hightes output of value network.\n",
    "                action, confidence, exploration = self.agent.decide_action(pred_value, pred_policy, epsilon)\n",
    "                \n",
    "                # get rewards from action\n",
    "                reward = self.agent.act(action, confidence)\n",
    "                \n",
    "                # save action and the results in the memory\n",
    "                self.memory_sample.append(list(q_sample))\n",
    "                self.memory_action.append(action)\n",
    "                self.memory_reward.append(reward)\n",
    "                if self.value_network is not None:\n",
    "                    self.memory_value.append(pred_value)\n",
    "                if self.policy_network is not None:\n",
    "                    self.memory_policy.append(pred_policy)\n",
    "                self.memory_pv.append(self.agent.portfolio_value)\n",
    "                self.memory_num_stocks.append(self.agent.num_stocks)\n",
    "                if exploration:\n",
    "                    self.memory_exp_idx.append(self.training_data_idx)\n",
    "                    \n",
    "                # update iteration info\n",
    "                self.batch_size += 1\n",
    "                self.itr_cnt += 1\n",
    "                self.exploration_cnt +=1 if exploration else 0\n",
    "                \n",
    "            # traing network after completing an epoch\n",
    "            if learning:\n",
    "                self.fit()\n",
    "            \n",
    "            # log about an epoch info\n",
    "            # check the length of epoch number string\n",
    "            num_epochs_digit = len(str(self.num_epochs))\n",
    "            # fill '0' as same size as the length of number of epochs\n",
    "            epoch_str = str(epoch + 1).rjust(num_epochs_digit, '0')\n",
    "            time_end_epoch = time.time()\n",
    "            # save time of an epoch\n",
    "            elapsed_time_epoch = time_end_epoch - time_end_epoch\n",
    "            logger.debug(f'[{self.stock_code}][Epoch {epoch_str}]'\n",
    "                         f'Epsilon:{epsilon:.4f} #Expl.:{self.exploration_cnt}/{self.itr_cnt} '\n",
    "                         f'#Buy:{self.agent.num_buy} #Sell:{self.agent.num_sell} #Hold:{self.agent.num_hold} '\n",
    "                         f'#Stocks:{self.agent.num_stocks} PV:{self.agent.portfolio_value:,.0f} '\n",
    "                         f'Loss:{self.loss:.6f} ET:{elapsed_time_epoch:.4f}')\n",
    "            \n",
    "            # visualize epoch information\n",
    "            if self.gen_output:\n",
    "                if self.num_epochs == 1 or (epoch + 1) % max(int(self.num_epochs / 100), 1) == 0:\n",
    "                    self.visualize(epoch_str, self.num_epochs, epsilon)\n",
    "            \n",
    "            # update training info\n",
    "            max_portfolio_value = max(\n",
    "                max_portfolio_value, self.agent.portfolio_value\n",
    "            )\n",
    "            if self.agent.portfolio_value > self.agent.initial_balance:\n",
    "                epoch_win_cnt += 1\n",
    "                \n",
    "        # end time\n",
    "        time_end = time.time()\n",
    "        elapsed_time = time_end - time_start\n",
    "        \n",
    "        # log about training\n",
    "        with self.lock:\n",
    "            logger.debug(f'[{self.stock_code} Elapsed Time:{elapsed_time:.4f}]'\n",
    "                         f'Max PV:{max_portfolio_value:,.0f} #Win:{epoch_win_cnt}')\n",
    "        \n",
    "    def save_models(self):\n",
    "        if self.value_network is not None and self.value_network_path is not None:\n",
    "            self.value_network.save_model(self.value_network_path)\n",
    "        if self.policy_network is not None and self.policy_network_path is not None:\n",
    "            self.policy_network.save_model(self.policy_network_path)\n",
    "            \n",
    "    # wihtou training, just predict actions based on samples\n",
    "    def predict(self):\n",
    "        # initiate an agent\n",
    "        self.agent.reset()\n",
    "        \n",
    "        # queue for step samples\n",
    "        q_sample = collections.deque(maxlen=self.num_steps)\n",
    "        \n",
    "        result = []\n",
    "        while True:\n",
    "            # create samples\n",
    "            next_sample = self.build_sample()\n",
    "            if next_sample is None:\n",
    "                break\n",
    "            \n",
    "            # save samples as many as num_steps\n",
    "            q_sample.append(next_sample)\n",
    "            if len(q_sample) < self.num_steps:\n",
    "                continue\n",
    "            \n",
    "            # prediction based on value and policy network\n",
    "            pred_value = None\n",
    "            pred_policy = None\n",
    "            if self.value_network is not None:\n",
    "                pred_value = self.value_network.predict(list(q_sample)).tolist()\n",
    "            if self.policy_network is not None:\n",
    "                pred_policy = self.policy_network.predict(list(q_sample)).tolist()\n",
    "                \n",
    "            # decide action based on the network\n",
    "            result.append((self.environment.observe[0]. pred_value, pred_policy))\n",
    "            \n",
    "        if self.gen_output:\n",
    "            with open(os.path.join(self.output_path, f'pred_{self.stock_code}.json'), 'w') as f:\n",
    "                print(json.dumps(result), file=f)\n",
    "                \n",
    "        return result\n",
    "             \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNLearner(ReinforcementLearner):\n",
    "    def __init__(self, *args, value_network_path=None, **kwargs):\n",
    "        super.__init__(*args, **kwargs)\n",
    "        self.value_network_path = value_network_path\n",
    "        # create value network\n",
    "        self.init_value_network()\n",
    "    \n",
    "    # abstract method\n",
    "    def get_batch(self):\n",
    "        # reverse memory array\n",
    "        memory = zip(\n",
    "            reversed(self.memory_sample),\n",
    "            reversed(self.memory_action),\n",
    "            reversed(self.memory_value),\n",
    "            reversed(self.memory_reward),\n",
    "        )\n",
    "        \n",
    "        # prepare sample array 'x' and label array 'y_value' with 0 value\n",
    "        x = np.zeros((len(self.memory_sample), self.num_steps, self.num_features))\n",
    "        y_value = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        value_max_next = 0\n",
    "        \n",
    "        # we can handle from the last data becase of reversed memory\n",
    "        for i, (sample, action, value, reward) in enumerate(memory):\n",
    "            # sample\n",
    "            x[i] = sample\n",
    "            # # reward for training\n",
    "            ## memory_reward[-1] : last profit/loss in the batch data\n",
    "            ## reward : profit/loss at the time of action\n",
    "            r = self.memory_reward[-1] - reward\n",
    "            # value network output\n",
    "            y_value[i] = value\n",
    "            # state-action value\n",
    "            y_value[i, action] = r + self.discount_factor * value_max_next\n",
    "            # save the maximum next state value\n",
    "            value_max_next = value.max()\n",
    "            \n",
    "        # return sample array, value network label, policy network label\n",
    "        # DQN has no policy network, return None\n",
    "        return x, y_value, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2010-01-01' AND '2020-12-31' \n",
      "                    \n",
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'TSLA'\n",
      "                    AND date BETWEEN '2010-01-01' AND '2020-12-31' \n",
      "                    \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2647,) (2769,) () ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m list_max_trading_price \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock_code \u001b[38;5;129;01min\u001b[39;00m stock_codes:\n\u001b[1;32m---> 65\u001b[0m     chart_data, training_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstock_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chart_data) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_steps\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# minimum and maximum trading price policy\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(stock_code, fro, to)\u001b[0m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# preprocessing\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m chart_data \u001b[38;5;241m=\u001b[39m df[COLUMNS_STOCK_DATA]\n",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# RSI\u001b[39;00m\n\u001b[0;32m     44\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdiff()\n\u001b[1;32m---> 45\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_up\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose_change\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose_change\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# data['close_up'] = data['close_change'].apply(lambda x: x if x >= 0 else 0)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_down\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_change\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mabs(), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2647,) (2769,) () "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "os.environ['RLTRADER_BASe'] = 'C:\\project\\github\\projects\\trader\\test'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mode = 'train'      # 'train', 'test', 'update', 'predict'\n",
    "    name = 'RLTrader'\n",
    "    rl_method = 'dqn'\n",
    "    net = 'cnn'\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2020-12-31'\n",
    "    lr = 0.001\n",
    "    discount_factor = 0.7\n",
    "    initial_balance = 1000000\n",
    "    stock_codes = ['AAPL', 'TSLA', 'MSFT']\n",
    "    \n",
    "    # learner's parameter\n",
    "    output_name = f'{mode}_{name}_{rl_method}_{net}'\n",
    "    # reinforcement learning True or False\n",
    "    learning = mode in ['train', 'update']\n",
    "    # use model flag\n",
    "    resue_models = mode in ['test', 'update', 'predict']\n",
    "    value_network_name = f'{name}_{rl_method}_{net}_value.mdl'\n",
    "    policy_network_name = f'{name}_{rl_method}_{net}_policy.mdl'\n",
    "    start_epsilon = 1 if mode in ['tain', 'update'] else 0\n",
    "    num_epochs = 1000 if mode in ['train', 'update'] else 0\n",
    "    num_steps = 5 if net in ['lstm', 'cnn'] else 1\n",
    "    \n",
    "    # output path\n",
    "    output_path = os.path.join(BASE_DIR, 'output', output_name)\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    # model path\n",
    "    value_network_path = os.path.join(BASE_DIR, 'models', value_network_name)\n",
    "    policy_network_path = os.path.join(BASE_DIR, 'models', policy_network_name)\n",
    "    \n",
    "    # setting for logging\n",
    "    # log level DEBUG < INFO < WARNING < CRITICAL. more than DEBUG\n",
    "    log_path = os.path.join(output_path, f'{output_name}.log')\n",
    "    if os.path.exists(log_path):\n",
    "        os.remove(log_path)\n",
    "    logging.basicConfig(format='%(message)s')\n",
    "    logger = logging.getLogger(LOGGER_NAME)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.propagate = False\n",
    "    stream_handler = logging.StreamHandler(sys.stdout)\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    file_handler = logging.FileHandler(filename=log_path, encoding='utf-8')\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    common_params = {}\n",
    "    list_stock_code = []\n",
    "    list_training_data = []\n",
    "    list_min_trading_price = []\n",
    "    list_max_trading_price = []\n",
    "    \n",
    "    for stock_code in stock_codes:\n",
    "        chart_data, training_data = load_data(\n",
    "            stock_code, start_date, end_date\n",
    "        )\n",
    "        \n",
    "        assert len(chart_data) >= num_steps\n",
    "        \n",
    "        # minimum and maximum trading price policy\n",
    "        min_trading_price = 10\n",
    "        max_trading_price = 10000\n",
    "        \n",
    "        # common parameters\n",
    "        common_params = {\n",
    "            'rl_method': rl_method,\n",
    "            'net': net, 'num_steps': num_steps,  'lr': lr,\n",
    "            'balance': initial_balance, 'num_epochs': num_epochs,\n",
    "            'discount_factor': discount_factor, 'start_epsilon': start_epsilon,\n",
    "            'output_path': output_path, 'reuse_models': resue_models\n",
    "        }\n",
    "        \n",
    "        # start reinforcement learning\n",
    "        learner = None\n",
    "        common_params.update({\n",
    "            'stock_code': stock_code,\n",
    "            'chart_data': chart_data,\n",
    "            'training_data': training_data,\n",
    "            'min_trading_price': min_trading_price,\n",
    "            'max_trading_price': max_trading_price\n",
    "        })\n",
    "        \n",
    "        learner = DQNLearner(**{**common_params, 'value_network_path': value_network_path})\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rl_method': 'dqn',\n",
       " 'net': 'cnn',\n",
       " 'num_steps': 5,\n",
       " 'lr': 0.001,\n",
       " 'balance': 1000000,\n",
       " 'num_epochs': 1000,\n",
       " 'discount_factor': 0.7,\n",
       " 'start_epsilon': 0,\n",
       " 'output_path': 'c:\\\\project\\\\github\\\\projects\\\\trader\\\\output\\\\train_RLTrader_dqn_cnn',\n",
       " 'reuse_models': False}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_params = []\n",
    "common_params = {\n",
    "            'rl_method': rl_method,\n",
    "            'net': net, 'num_steps': num_steps,  'lr': lr,\n",
    "            'balance': initial_balance, 'num_epochs': num_epochs,\n",
    "            'discount_factor': discount_factor, 'start_epsilon': start_epsilon,\n",
    "            'output_path': output_path, 'reuse_models': resue_models\n",
    "        }\n",
    "\n",
    "common_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
