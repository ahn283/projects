{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db connection\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import keyring\n",
    "import platform\n",
    "import numpy as np\n",
    "\n",
    "user = 'root'\n",
    "pw = keyring.get_password('macmini_db', user)\n",
    "host = '192.168.219.106' if platform.system() == 'Windows' else '127.0.0.1'\n",
    "port = 3306\n",
    "db = 'stock'\n",
    "\n",
    "\n",
    "# # connect DB\n",
    "# engine = create_engine(f'mysql+pymysql://{self.user}:{self.pw}@{self.host}:{self.port}/{self.db}')\n",
    "\n",
    "# con = pymysql.connect(\n",
    "#     user=user,\n",
    "#     passwd=pw,\n",
    "#     host=host,\n",
    "#     db=db,\n",
    "#     charset='utf8'\n",
    "# )\n",
    "        \n",
    "# mycursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base data\n",
    "COLUMNS_STOCK_DATA = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "COLUMNS_TRAINING_DATA = ['open', 'high', 'low', 'close', 'volume', 'close_ma5', 'volume_ma5', 'close_ma5_ratio', 'volume_ma5_ratio',\n",
    "       'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio',\n",
    "       'low_close_ratio', 'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "       'close_ma10', 'volume_ma10', 'close_ma10_ratio', 'volume_ma10_ratio',\n",
    "       'close_ma20', 'volume_ma20', 'close_ma20_ratio', 'volume_ma20_ratio',\n",
    "       'close_ma60', 'volume_ma60', 'close_ma60_ratio', 'volume_ma60_ratio',\n",
    "       'close_ma120', 'volume_ma120', 'close_ma120_ratio',\n",
    "       'volume_ma120_ratio', 'close_ma240', 'volume_ma240',\n",
    "       'close_ma240_ratio', 'volume_ma240_ratio', 'upper_bb',\n",
    "       'lower_bb', 'bb_pb', 'bb_width', 'macd',\n",
    "       'macd_signal', 'macd_oscillator', 'rs', 'rsi']\n",
    "# COLUMNS_TRAINING_DATA = ['open', 'high', 'low', 'close', 'volume', 'close_ma5', 'volume_ma5', 'close_ma5_ratio', 'volume_ma5_ratio',\n",
    "#        'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio',\n",
    "#        'low_close_ratio', 'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "#        'close_ma10', 'volume_ma10', 'close_ma10_ratio', 'volume_ma10_ratio',\n",
    "#        'close_ma20', 'volume_ma20', 'close_ma20_ratio', 'volume_ma20_ratio',\n",
    "#        'close_ma60', 'volume_ma60', 'close_ma60_ratio', 'volume_ma60_ratio',\n",
    "#        'close_ma120', 'volume_ma120', 'close_ma120_ratio',\n",
    "#        'volume_ma120_ratio', 'close_ma240', 'volume_ma240',\n",
    "#        'close_ma240_ratio', 'volume_ma240_ratio', 'middle_bb', 'upper_bb',\n",
    "#        'lower_bb', 'bb_pb', 'bb_width', 'ema_short', 'ema_long', 'macd',\n",
    "#        'macd_signal', 'macd_oscillator', 'close_change', 'close_up',\n",
    "#        'close_down', 'rs', 'rsi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# get us stock price of a specific ticker\n",
    "def get_prices_from_ticker(ticker, fro=None, to=None):\n",
    "\n",
    "    # connect DB\n",
    "    engine = create_engine(f'mysql+pymysql://{user}:{pw}@{host}:{port}/{db}')\n",
    "\n",
    "    con = pymysql.connect(\n",
    "        user=user,\n",
    "        passwd=pw,\n",
    "        host=host,\n",
    "        db=db,\n",
    "        charset='utf8'\n",
    "    )\n",
    "            \n",
    "    mycursor = con.cursor()\n",
    "    \n",
    "    if fro is not None:\n",
    "        if to is not None:               \n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date BETWEEN '{fro}' AND '{to}' \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date >= '{fro}'\n",
    "                    \"\"\"\n",
    "    \n",
    "    else:\n",
    "        if to is not None:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    AND date <= '{to}' \n",
    "                    \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\" \n",
    "                    SELECT * FROM price_global\n",
    "                    WHERE ticker = '{ticker}'\n",
    "                    \"\"\"\n",
    "            \n",
    "    print(query)\n",
    "    prices = pd.read_sql(query, con=engine)\n",
    "    con.close()\n",
    "    engine.dispose()\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# str format on date, time\n",
    "FORMAT_DATE = '%Y%m%d'\n",
    "FORMAT_DATETIME = '%Y%m%d%H%M%S'\n",
    "\n",
    "def get_today_str():\n",
    "    today = datetime.datetime.combine(\n",
    "        datetime.date.today(), datetime.datetime.min.time()\n",
    "    )\n",
    "    today_str = today.strftime(FORMAT_DATE)\n",
    "    return today_str\n",
    "\n",
    "def get_time_str():\n",
    "    return datetime.datetime.fromtimestamp(\n",
    "        int(time.time())\n",
    "    ).strftime(FORMAT_DATETIME)\n",
    "    \n",
    "def sigmoid(x):\n",
    "    x = max(min(x, 10), -10)\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2010-01-01' AND '2020-12-31' \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "stock_code = 'AAPL'\n",
    "fro = '2010-01-01'\n",
    "to = '2020-12-31'\n",
    "df = get_prices_from_ticker(stock_code, fro=fro, to=to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_STOCK_RATIO_DATA = [\n",
    "    'open_close_ratio', 'open_prev_close_ratio', 'high_close_ratio', 'low_close_ratio',\n",
    "    'close_prev_close_ratio', 'volume_prev_volume_ratio',\n",
    "]\n",
    "\n",
    "def preprocess(data):\n",
    "    \n",
    "    # moving average\n",
    "    windows = [5, 10, 20, 60, 120, 240]\n",
    "    for window in windows:\n",
    "        data[f'close_ma{window}'] = data['close'].rolling(window).mean()\n",
    "        data[f'volume_ma{window}'] = data['volume'].rolling(window).mean()\n",
    "        data[f'close_ma{window}_ratio'] = (data['close'] - data[f'close_ma{window}']) / data[f'close_ma{window}']\n",
    "        data[f'volume_ma{window}_ratio'] = (data['volume'] - data[f'volume_ma{window}']) / data[f'volume_ma{window}']\n",
    "        data['open_close_ratio'] = (data['open'].values - data['close'].values) / data['close'].values\n",
    "        data['open_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'open_prev_close_ratio'] = (data['open'][1:].values - data['close'][:-1].values) / data['close'][:-1].values\n",
    "        data['high_close_ratio'] = (data['high'].values - data['close'].values) / data['close'].values\n",
    "        data['low_close_ratio'] = (data['low'].values - data['close'].values) / data['close'].values\n",
    "        data['close_prev_close_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'close_prev_close_ratio'] = (data['close'][1:].values - data['close'][:-1].values) / data['close'][:-1].values \n",
    "        data['volume_prev_volume_ratio'] = np.zeros(len(data))\n",
    "        data.loc[1:, 'volume_prev_volume_ratio'] = (\n",
    "            # if volume is 0, change it into non zero value exploring previous volume continuously\n",
    "            (data['volume'][1:].values - data['volume'][:-1].values) / data['volume'][:-1].replace(to_replace=0, method='ffill').replace(to_replace=0, method='bfill').values\n",
    "        )\n",
    "    \n",
    "    # Bollinger band\n",
    "    data['middle_bb'] = data['close'].rolling(20).mean()\n",
    "    data['upper_bb'] = data['middle_bb'] + 2 * data['close'].rolling(20).std()\n",
    "    data['lower_bb'] = data['middle_bb'] - 2 * data['close'].rolling(20).std()\n",
    "    data['bb_pb'] = (data['close'] - data['lower_bb']) / (data['upper_bb'] - data['lower_bb'])\n",
    "    data['bb_width'] = (data['upper_bb'] - data['lower_bb']) / data['middle_bb']\n",
    "    \n",
    "    # MACD\n",
    "    macd_short, macd_long, macd_signal = 12, 26, 9\n",
    "    data['ema_short'] = data['close'].ewm(macd_short).mean()\n",
    "    data['ema_long'] = data['close'].ewm(macd_long).mean()\n",
    "    data['macd'] = data['ema_short'] - data['ema_long']\n",
    "    data['macd_signal'] = data['macd'].ewm(macd_signal).mean()\n",
    "    data['macd_oscillator'] = data['macd'] - data['macd_signal']\n",
    "    \n",
    "    # RSI\n",
    "    data['close_change'] = data['close'].diff()\n",
    "    # data['close_up'] = np.where(data['close_change'] >=0, df['close_change'], 0)\n",
    "    data['close_up'] = data['close_change'].apply(lambda x: x if x >= 0 else 0)\n",
    "    # data['close_down'] = np.where(data['close_change'] < 0, df['close_change'].abs(), 0)\n",
    "    data['close_down'] = data['close_change'].apply(lambda x: -x if x < 0 else 0)\n",
    "    data['rs'] = data['close_up'].ewm(alpha=1/14, min_periods=14).mean() / data['close_down'].ewm(alpha=1/14, min_periods=14).mean()\n",
    "    data['rsi'] = 100 - (100 / (1 + data['rs']))\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock_code, fro, to):\n",
    "    df = get_prices_from_ticker(stock_code, fro, to)\n",
    "    df_adj = preprocess(df).dropna().reset_index(drop=True)\n",
    "    # df_adj.dropna(inplace=True).reset_index(drop=True)\n",
    "    \n",
    "    stock_data = df_adj[COLUMNS_STOCK_DATA]\n",
    "    training_data = df_adj[COLUMNS_TRAINING_DATA]\n",
    "    \n",
    "    return df_adj, stock_data, training_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2010-01-01' AND '2020-12-31' \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "df_adj, stock_data, training_data = load_data(stock_code, fro, to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# environment\n",
    "\n",
    "class Environment:\n",
    "    ''' \n",
    "    Attribute\n",
    "    ---------\n",
    "    - stock_data : stock price data such as 'open', 'close', 'volume', 'bb', 'rsi', etc.\n",
    "    - state : current state\n",
    "    - idx : current postion of stock data\n",
    "    \n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize idx and state\n",
    "    - step() : move idx into next postion and get a new state\n",
    "    - get_price() : get close price of current state\n",
    "    - get_state() : get current state\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, stock_data=None):\n",
    "        self.PRICE_IDX = 4  # index postion of close price\n",
    "        self.stock_data = stock_data\n",
    "        self.state = None\n",
    "        self.idx = -1\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = None\n",
    "        self.idx = -1\n",
    "        \n",
    "    def step(self):\n",
    "        # if there is no more idx, return None\n",
    "        if len(self.stock_data) > self.idx + 1:\n",
    "            self.idx += 1\n",
    "            self.state = self.stock_data.iloc[self.idx]\n",
    "            return self.state\n",
    "        return None\n",
    "    \n",
    "    def get_price(self):\n",
    "        # return close price\n",
    "        if self.state is not None:\n",
    "            return self.state[self.PRICE_IDX]\n",
    "        return None\n",
    "    \n",
    "    def get_state(self):\n",
    "        # return current state\n",
    "        if self.state is not None:\n",
    "            return self.state\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.441429138183594"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Environment(df_adj)\n",
    "a.reset()\n",
    "a.step()\n",
    "a.step()\n",
    "a.get_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                         2010-12-16\n",
       "high                            11.4675\n",
       "low                           11.521786\n",
       "open                          11.432143\n",
       "close                         11.473214\n",
       "volume                         9.713216\n",
       "adj_close                   322030800.0\n",
       "ticker                             AAPL\n",
       "close_ma5                     11.458071\n",
       "volume_ma5                     9.700397\n",
       "close_ma5_ratio                0.001322\n",
       "volume_ma5_ratio               0.001321\n",
       "open_close_ratio               -0.00358\n",
       "open_prev_close_ratio         -0.000812\n",
       "high_close_ratio              -0.000498\n",
       "low_close_ratio                0.004233\n",
       "close_prev_close_ratio         0.002778\n",
       "volume_prev_volume_ratio       0.002778\n",
       "close_ma10                    11.431071\n",
       "volume_ma10                    9.677539\n",
       "close_ma10_ratio               0.003687\n",
       "volume_ma10_ratio              0.003687\n",
       "close_ma20                    11.304143\n",
       "volume_ma20                    9.570082\n",
       "close_ma20_ratio               0.014957\n",
       "volume_ma20_ratio              0.014956\n",
       "close_ma60                    10.969405\n",
       "volume_ma60                    9.286692\n",
       "close_ma60_ratio               0.045929\n",
       "volume_ma60_ratio              0.045928\n",
       "close_ma120                   10.071384\n",
       "volume_ma120                   8.526428\n",
       "close_ma120_ratio              0.139189\n",
       "volume_ma120_ratio             0.139189\n",
       "close_ma240                    9.198582\n",
       "volume_ma240                   7.787514\n",
       "close_ma240_ratio              0.247281\n",
       "volume_ma240_ratio             0.247281\n",
       "middle_bb                     11.304143\n",
       "upper_bb                      11.636183\n",
       "lower_bb                      10.972103\n",
       "bb_pb                          0.754594\n",
       "bb_width                       0.058747\n",
       "ema_short                     11.278047\n",
       "ema_long                      10.968925\n",
       "macd                           0.309122\n",
       "macd_signal                    0.335923\n",
       "macd_oscillator               -0.026801\n",
       "close_change                   0.031785\n",
       "close_up                       0.031785\n",
       "close_down                          0.0\n",
       "rs                             1.487603\n",
       "rsi                           59.800667\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.step()\n",
    "a.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent\n",
    "import numpy as np\n",
    "\n",
    "class Agent:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - enviroment : instance of environment\n",
    "    - initial_balance : initial capital balance\n",
    "    - min_trading_price : minimum trading price\n",
    "    - max_trading_price : maximum trading price\n",
    "    - balance : cash balance\n",
    "    - num_stocks : obtained stocks\n",
    "    - portfolio_value : value of portfolios (balance + price * num_stocks)\n",
    "    - num_buy : number of buying\n",
    "    - num_sell : number of selling\n",
    "    - num_hold : number of holding\n",
    "    - ratio_hold : ratio of holding stocks\n",
    "    - profitloss : current profit or loss\n",
    "    - avg_buy_price_ratio : the ratio average price of a stock bought to the current price\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - reset() : initialize an agent\n",
    "    - set_balance() : initialize balance\n",
    "    - get_states() : get the state of an agent\n",
    "    - decide_action() : exploration or exploitation behavior according to the policy net\n",
    "    - validate_action() : validate actions\n",
    "    - decide_trading_unit() : decide how many stocks are sold or bought\n",
    "    - act() : act the actions\n",
    "    '''\n",
    "    \n",
    "    # agent state dimensions\n",
    "    ## (ratio_hold, profit-loss ratio, current price to avg_buy_price ratio)\n",
    "    STATE_DIM = 3\n",
    "    \n",
    "    # trading charge and tax\n",
    "    TRADING_CHARGE = 0.00015    # trading charge 0.015%\n",
    "    TRADING_TAX = 0.02          # trading tax = 0.2%\n",
    "    \n",
    "    # action space\n",
    "    ACTION_BUY = 0      # buy\n",
    "    ACTION_SELL = 1     # sell\n",
    "    ACTION_HOLD = 2     # hold\n",
    "    \n",
    "    # get probabilities from neural nets\n",
    "    ACTIONS = [ACTION_BUY, ACTION_SELL, ACTION_HOLD]\n",
    "    NUM_ACTIONS = len(ACTIONS)      # output number from nueral nets\n",
    "    \n",
    "    def __init__(self, environment, initial_balance, min_trading_price, max_trading_price):\n",
    "        # get current price from the environment\n",
    "        self.environment = environment\n",
    "        self.initial_balance = initial_balance\n",
    "        \n",
    "        # minumum and maximum trainding price\n",
    "        self.min_trading_price = min_trading_price\n",
    "        self.max_trading_price = max_trading_price\n",
    "        \n",
    "        # attributes for an agent class\n",
    "        self.balance = initial_balance\n",
    "        self.num_stocks = 0\n",
    "        \n",
    "        # value of portfolio : balance + num_stocks * {current stock price}\n",
    "        self.portfolio_value = 0\n",
    "        self.num_buy = 0\n",
    "        self.num_sell = 0\n",
    "        self.num_hold = 0\n",
    "        \n",
    "        # the state of Agent class\n",
    "        self.ratio_hold = 0\n",
    "        self.profitloss = 0\n",
    "        self.avg_buy_price = 0\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.num_stocks = 0\n",
    "        self.portfolio_value = self.balance\n",
    "        self.num_buy = 0\n",
    "        self.num_sell = 0\n",
    "        self.num_hold = 0\n",
    "        self.ratio_hold = 0\n",
    "        self.profitloss = 0\n",
    "        self.avg_buy_price = 0\n",
    "        \n",
    "    def set_initial_balance(self, balance):\n",
    "        self.initial_balance = balance\n",
    "        \n",
    "    def get_states(self):\n",
    "        # return ratio hold, profit/loss ratio and \n",
    "        # ratio_hold = num_stokcs / (portfoilo_value / price) = (num_stocks * price) / portfolio_value\n",
    "        self.ratio_hold = self.num_stocks * self.environment.get_price() / self.portfolio_value\n",
    "        \n",
    "        return (\n",
    "            self.ratio_hold,\n",
    "            self.profitloss,        # profitloss = (portfolio_value / initial_balance) - 1\n",
    "            (self.environment.get_price() / self.avg_buy_price) - 1 if self.avg_buy_price > 0 else 0\n",
    "        )\n",
    "        \n",
    "    def decide_action(self, pred_value, pred_policy, epsilon):\n",
    "        # act randomly with epsilon probability, act according to neural network  with (1 - epsilon) probability\n",
    "        confidence = 0\n",
    "        \n",
    "        # if theres is a pred_policy, follow it, otherwise follow a pred_value\n",
    "        pred = pred_policy\n",
    "        if pred is None:\n",
    "            pred = pred_value\n",
    "            \n",
    "        # there is no prediction from both pred_policy and pred_value, explore!\n",
    "        if pred is None:\n",
    "            epsilon = 1\n",
    "        else:\n",
    "            maxpred = np.max(pred)\n",
    "            # if values for actions are euqal, explore!\n",
    "            if (pred == maxpred).all():\n",
    "                epsilon = 1\n",
    "        \n",
    "            # if the diffrence between buying and selling prediction policy value is less than 0.05, explore!\n",
    "            if pred_policy is not None:\n",
    "                if np.max(pred_policy) - np.min(pred_policy) < 0.05:\n",
    "                    epsilon = 1\n",
    "            # if pred is not None:\n",
    "            #     if np.max(pred) - np.min(pred) < 0.05:\n",
    "            #         epsilon = 1     \n",
    "                    \n",
    "        # decide whether exploration will be done or not\n",
    "        if np.random.rand() < epsilon:\n",
    "            exploration = True\n",
    "            action = np.random.randint(self.NUM_ACTIONS) \n",
    "        else: \n",
    "            exploration = False\n",
    "            action = np.argmax(pred)\n",
    "            \n",
    "        confidence = .5\n",
    "        if pred_policy is not None:\n",
    "            confidence = pred[action]  \n",
    "        elif pred_value is not None:\n",
    "            confidence = sigmoid(pred[action])\n",
    "            \n",
    "        return action, confidence, exploration\n",
    "    \n",
    "    def validate_action(self, action):\n",
    "        # validate if the action is available\n",
    "        if action == Agent.ACTION_BUY:\n",
    "            # check if al least one stock can be bought.\n",
    "            if self.balance < self.environment.get_price() * (1 + self.TRADING_CHARGE):\n",
    "                return False\n",
    "        elif action == Agent.ACTION_SELL:\n",
    "            # check if there is any sotck that can be sold\n",
    "            if self.num_stocks <= 0:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def decide_trading_unit(self, confidence):\n",
    "        # adjust number of stocks for buying and selling according to confidence level\n",
    "        if np.isnan(confidence):\n",
    "            return self.min_trading_price\n",
    "        \n",
    "        # set buying price range between self.min_trading_price + added_trading_price [min_trading_price, max_trading_price]\n",
    "        # in case that confidence > 1 causes the price over max_trading_price, we set min() so that the value cannot have larger value than self.max_trading_price - self.min_trading_price\n",
    "        # in case that confidence < 0, we set max() so that added_trading_price cannot have negative value.\n",
    "        added_trading_price = max(min(\n",
    "            int(confidence * (self.max_trading_price - self.min_trading_price)),\n",
    "            self.max_trading_price - self.min_trading_price\n",
    "        ), 0)\n",
    "        \n",
    "        trading_price = self.min_trading_price + added_trading_price\n",
    "        \n",
    "        return max(int(trading_price / self.environment.get_price()), 1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def act(self, action, confidence):\n",
    "        '''\n",
    "        Arguments\n",
    "        ---------\n",
    "        - action : decided action from decide_action() method based on exploration or exploitation (0 or 1)\n",
    "        - confidence : probabilitu from decide_action() method, the probability from policy network or the softmax probability from value network\n",
    "        '''\n",
    "        \n",
    "        if not self.validate_action(action):\n",
    "            action = Agent.ACTION_HOLD\n",
    "        \n",
    "        # get the price from the environment\n",
    "        curr_price = self.environment.get_price()\n",
    "        \n",
    "        # buy\n",
    "        if action == Agent.ACTION_BUY:\n",
    "            # decide how many stocks will be bought\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            balance = (\n",
    "                self.balance - curr_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            )\n",
    "            \n",
    "            # if lacks of balance, buy maximum units within the amount of money available\n",
    "            if balance < 0:\n",
    "                trading_unit = min(\n",
    "                    int(self.balance / (curr_price * (1 + self.TRADING_CHARGE))),\n",
    "                    int(self.max_trading_price / curr_price)\n",
    "                )\n",
    "                \n",
    "            # total amount of money with trading charge\n",
    "            invest_amount = curr_price * (1 + self.TRADING_CHARGE) * trading_unit\n",
    "            if invest_amount > 0:\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks + curr_price * trading_unit) / (self.num_stocks + trading_unit)\n",
    "                self.balance -= invest_amount\n",
    "                self.num_stocks += trading_unit\n",
    "                self.num_buy += 1\n",
    "                \n",
    "        # sell\n",
    "        elif action == Agent.ACTION_SELL:\n",
    "            # decide how many stocks will be sold\n",
    "            trading_unit = self.decide_trading_unit(confidence)\n",
    "            \n",
    "            # if lacks of stocks, sell maximum units available\n",
    "            trading_unit = min(trading_unit, self.num_stocks)\n",
    "            \n",
    "            # selling amount\n",
    "            invest_amount = curr_price * (\n",
    "                1 - (self.TRADING_TAX + self.TRADING_CHARGE)\n",
    "            ) * trading_unit\n",
    "            \n",
    "            if invest_amount > 0:\n",
    "                # update average buy price\n",
    "                self.avg_buy_price = (self.avg_buy_price * self.num_stocks - curr_price * trading_unit) / (self.num_stocks - trading_unit) if self.num_stocks > trading_unit else 0\n",
    "                self.num_stocks -= trading_unit\n",
    "                self.balance += invest_amount\n",
    "                self.num_sell += 1\n",
    "                \n",
    "        # hold\n",
    "        elif action == Agent.ACTION_HOLD:\n",
    "            self.num_hold += 1\n",
    "            \n",
    "        # update portfolio value\n",
    "        self.portfolio_value = self.balance + curr_price * self.num_stocks\n",
    "        self.profitloss = self.portfolio_value / self.initial_balance - 1\n",
    "        \n",
    "        return self.profitloss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import abc\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    ''' \n",
    "    Common attributes and methods for neural networks\n",
    "    \n",
    "    Attributes\n",
    "    ---------\n",
    "    - input_dim\n",
    "    - output_dim\n",
    "    - lr : learning rate\n",
    "    - shared_network : head of neural network which is shared with various networks (e.g., A2C)\n",
    "    - activation : activation layer function ('linear', 'sigmoid', 'tanh', 'softmax')\n",
    "    - loss : loss function for networks\n",
    "    - model : final neural network model\n",
    "    \n",
    "    Functions\n",
    "    ---------\n",
    "    - predict() : calculate value or probability of actions\n",
    "    - train_on_batch() : generate batch data for training\n",
    "    - save_model()\n",
    "    - load_model()\n",
    "    - get_share_network() : generate network head according to the networks\n",
    "    '''\n",
    "    \n",
    "    # thread lock for A3C\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    def __init__(self, input_dim=0, output_dim=0, num_steps=1, lr=0.001,\n",
    "                 shared_network=None, activation='sigmoid', loss='mse'):\n",
    "        self.input_dim = input_dim\n",
    "        self.outpu_dim = output_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.shared_network = shared_network\n",
    "        self.activation = activation\n",
    "        self.loss = loss\n",
    "        \n",
    "        # data shape for various networks\n",
    "        # CNN, LSTMNetwork has 3 dimensional shape, so we set input shape as (num_stpes, input_dim). In DNN, we set input shape as (input_dim, )\n",
    "        inp = None\n",
    "        if self.num_steps > 1:\n",
    "            inp = (self.num_steps, input_dim)\n",
    "        else:\n",
    "            inp = (self.input_dim,)\n",
    "        \n",
    "        # in case that shared_network is used\n",
    "        self.head = None\n",
    "        if self.shared_network is None:\n",
    "            self.head = self.get_network_head(inp, self.outpu_dim)\n",
    "        else:\n",
    "            self.head = self.shared_network\n",
    "            \n",
    "        # neural network model\n",
    "        ## generate network model for head\n",
    "        self.model = torch.nn.Sequential(self.head)\n",
    "        if self.activation == 'linear':\n",
    "            pass\n",
    "        elif self.activation == 'relu':        \n",
    "            self.model.add_module('activation', torch.nn.ReLU())   \n",
    "        elif self.activation == 'leaky_relu':\n",
    "            self.model.add_module('activation', torch.nn.LeakyReLU()) \n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.model.add_module('activation', torch.nn.Sigmoid())\n",
    "        elif self.activation == 'tanh':\n",
    "            self.model.add_module('activation', torch.nn.Tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            self.model.add_module('activation', torch.nn.Softmax(dim=1))\n",
    "        self.model.apply(Network.init_weights)\n",
    "        self.model.to(device)\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = None\n",
    "        if loss == 'mse':\n",
    "            self.criterion = torch.nn.MSELoss()\n",
    "        elif loss == 'binary_crossentropy':\n",
    "            self.criterion = torch.nn.BCELoss()\n",
    "            \n",
    "    def predict(self, sample):\n",
    "        # return prediction of buy, sell and hold on given sample\n",
    "        # value network returns each actions' values on sample and policy network returns each actions' probabilities on sample\n",
    "        with self.lock:\n",
    "            # transform evaluation mode : deavtivate module used only on traininig such as Drop out\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(sample).float().to(device)\n",
    "                pred = self.model(x).detach().cpu().numpy()\n",
    "                pred = pred.flatten()\n",
    "            return pred\n",
    "        \n",
    "    def train_on_batch(self, x, y):\n",
    "        if self.num_steps > 1:\n",
    "            x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "        else:\n",
    "            x = np.array(x).reshape((-1, self.input_dim))\n",
    "        loss = 0\n",
    "        with self.lock:\n",
    "            # transform training mode\n",
    "            self.model.train()\n",
    "            _x = torch.from_numpy(x).float().to(device)\n",
    "            _y = torch.from_numpy(y).float().to(device)\n",
    "            y_pred = self.model(_x)\n",
    "            _loss = self.criterion(y_pred, _y)\n",
    "            self.optimizer.zero_grad()\n",
    "            _loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss += _loss.item()\n",
    "        return loss\n",
    "    \n",
    "    def train_on_batch_for_ppo(self, x, y, a, eps, K):\n",
    "        if self.num_steps > 1:\n",
    "            x = np.array(x).reshape((-1, self.num_steps, self.input_dim))\n",
    "        else:\n",
    "            x = np.array(x).reshape((-1, self.input_dim))\n",
    "            \n",
    "        loss = 0.\n",
    "        with self.lock:\n",
    "            self.model.train()\n",
    "            _x = torch.from_numpy(x).float().to(device)\n",
    "            _y = torch.from_numpy(y).float().to(device)\n",
    "            probs = F.softmax(_y, dim=1)\n",
    "            for _ in range(K):\n",
    "                y_pred = self.model(_x)\n",
    "                probs_pred = F.softmax(y_pred, dim=1)\n",
    "                rto = torch.exp(torch.log(probs[:, a]) - torch.log(probs_pred[:, a]))\n",
    "                rto_adv = rto * _y[:, a]\n",
    "                clp_adv = torch.clamp(rto, 1 - eps, 1 + eps) * _y[:, a]\n",
    "                _loss = -torch.min(rto_adv, clp_adv).mean()\n",
    "                _loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss += _loss.item()\n",
    "        return loss\n",
    "    \n",
    "    @classmethod\n",
    "    def get_shared_network(cls, net='dnn', num_steps=1, input_dim=0, output_dim=0):\n",
    "        if net == 'dnn':\n",
    "            return DNN.get_network_head((input_dim, ), output_dim)\n",
    "        elif net == 'lstm':\n",
    "            return LSTMNetwork.get_network_head((num_steps, input_dim), output_dim)\n",
    "        elif net == 'cnn':\n",
    "            return CNN.get_network_head((num_steps, input_dim), output_dim)\n",
    "        elif net == 'alex':\n",
    "            print('alex')\n",
    "            return AlexNet.get_network_head((num_steps, input_dim), output_dim)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        # initialize weights as weighted normal distribution\n",
    "        if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv1d):\n",
    "            torch.nn.init.normal_(m.weight, std=0.01)\n",
    "        elif isinstance(m, torch.nn.LSTM):\n",
    "            for weights in m.all_weights:\n",
    "                for weight in weights:\n",
    "                    torch.nn.init.normal_(weight, std=0.01)\n",
    "                    \n",
    "    def save_model(self, model_path):\n",
    "        if model_path is not None and self.model is not None:\n",
    "            torch.save(self.model, model_path)\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        if model_path is not None:\n",
    "            self.model = torch.load(model_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(Network):\n",
    "    # @staticmethod\n",
    "    # def get_network_head(inp, outpu_dim):\n",
    "    #     return torch.nn.Sequential(\n",
    "    #         torch.nn.BatchNorm1d(inp[0]),   # input shape = (input_dim, )\n",
    "    #         torch.nn.Linear(inp[0], 256),\n",
    "    #         torch.nn.BatchNorm1d(256),\n",
    "    #         torch.nn.Dropout(p=0.1),\n",
    "    #         torch.nn.Linear(256, 128),\n",
    "    #         torch.nn.BatchNorm1d(128),\n",
    "    #         torch.nn.Dropout(p=0.1),\n",
    "    #         torch.nn.Linear(128, 64),\n",
    "    #         torch.nn.BatchNorm1d(64),\n",
    "    #         torch.nn.Dropout(p=0.1),\n",
    "    #         torch.nn.Linear(64, 32),\n",
    "    #         torch.nn.BatchNorm1d(32),\n",
    "    #         torch.nn.Dropout(p=0.1),\n",
    "    #         torch.nn.Linear(32, outpu_dim),\n",
    "    #     )\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, outpu_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),   # input shape = (input_dim, )\n",
    "            torch.nn.Linear(inp[0], 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, outpu_dim),\n",
    "        )\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((1, self.input_dim))\n",
    "        return super().predict(sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            LSTMModule(inp[1], 128, batch_first=True, use_last_only=True),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim),\n",
    "        )\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((-1, self.num_steps, self.input_dim))\n",
    "        return super().predict(sample)\n",
    "    \n",
    "class LSTMModule(torch.nn.LSTM):\n",
    "    def __init__(self, *args, use_last_only=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.use_last_only = use_last_only\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (h_n, _) = super().forward(x)\n",
    "        if self.use_last_only:\n",
    "            return h_n[-1]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        kernel_size = 2\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(inp[0]),\n",
    "            torch.nn.Conv1d(inp[0], 1, kernel_size),\n",
    "            torch.nn.BatchNorm1d(1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(inp[1] - (kernel_size - 1), 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(32, output_dim)\n",
    "        )\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((1, self.num_steps, self.input_dim))\n",
    "        return super().predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_network_head(inp, output_dim):\n",
    "        kernel_size = 11,\n",
    "        stride = 4\n",
    "        padding = 1\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(inp[0], 96, kernel_size=kernel_size, stride=stride),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            torch.nn.Conv1d(96, 256, kernel_size=kernel_size, padding=padding),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            torch.nn.Conv1d(256, 384, kernel_size=kernel_size, padding=padding),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(384, 384, kernel_size=kernel_size, padding=padding),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(384, 256, kernel_size=kernel_size, padding=padding),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            \n",
    "            # classifier\n",
    "            torch.nn.Linear(256, 4096),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(4096, output_dim)\n",
    "        )\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((1, self.num_steps, self.input_dim))\n",
    "        return super().predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "class Visualizer:\n",
    "    ''' \n",
    "    Attributes\n",
    "    --------\n",
    "    - fig : matplotlib Figure instance plays like a canvas\n",
    "    - plot() : print charts except daily price chart\n",
    "    - save() : save Figure as an image file\n",
    "    - clear() : initialze all chart but daily price chart\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    - Figure title : parameter, epsilon\n",
    "    - Axes 1 : daily price chart\n",
    "    - Axes 2 : number of stocks and agent action chart\n",
    "    - Axes 3 : value network chart\n",
    "    - Axes 4 : policy network and epsilon chart\n",
    "    - Axes 5 : Portfolio value and learning point chart\n",
    "    '''\n",
    "    \n",
    "    COLORS = ['r', 'b', 'g']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.canvas = None \n",
    "        self.fig = None\n",
    "        self.axes = None\n",
    "        self.title = ''\n",
    "        self.x = []\n",
    "        self.xticks = []\n",
    "        self.xlabels = []\n",
    "        \n",
    "    def prepare(self, stock_data, title):\n",
    "        self.title = title\n",
    "        # shared x-axis among all charts\n",
    "        # self.x = np.arange(stock_data['date'])\n",
    "        # self.x_label = [datetime.strptime(date, '%Y%m%d').date() for date in stock_data['date']]\n",
    "        with lock:\n",
    "            # preare for printing five charts\n",
    "            self.fig, self.axes = plt.subplots(\n",
    "                nrows=5, ncols=1, facecolor='w', sharex=True\n",
    "            )\n",
    "            for ax in self.axes:\n",
    "                # deactivate scientific marks\n",
    "                ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                # change y-axis to the right\n",
    "                ax.yaxis.tick_right()\n",
    "            \n",
    "            # chart 1. daily price data\n",
    "            self.axes[0].set_ylabel('Env.')\n",
    "            x = np.arange(len(stock_data))\n",
    "            # make two dimensional array with open, high, low and close order\n",
    "            ohlc = np.hstack((\n",
    "                x.reshape(-1, 1), np.array(stock_data)[:, 1:5]\n",
    "            ))\n",
    "            # red for positive, blue for negative\n",
    "            candlestick_ohlc(self.axes[0], ohlc, colorup='r', colordown='b')\n",
    "            # visualize volume\n",
    "            ax = self.axes[0].twinx()\n",
    "            volume = np.array(stock_data)[:, 5].tolist()\n",
    "            ax.bar(x, volume, color='b', alpha=0.3)\n",
    "            # set x-axis\n",
    "            self.x = np.arange(len(stock_data['date']))\n",
    "            self.xticks = stock_data.index[[0, -1]]\n",
    "            self.xlabels = stock_data.iloc[[0, -1]]['date']\n",
    "            \n",
    "            \n",
    "    def plot(self, epoch_str=None, num_epochs=None, epsilon=None,\n",
    "             action_list=None, actions=None, num_stocks=None,\n",
    "             outvals_value=[], outvals_policy=[], exps=None,\n",
    "             initial_balance=None, pvs=None):\n",
    "        ''' \n",
    "        Attributes\n",
    "        ---------\n",
    "        - epoch_str : epoch for Figure title\n",
    "        - num_epochs : number of total epochs\n",
    "        - epsilon : exploration rate\n",
    "        - action_list : total action list of an agent\n",
    "        - num_stocks : number of stocks\n",
    "        - outvals_value : output array of value network\n",
    "        - outvals_policy : ouput array of policy network\n",
    "        - exps : array whether exploration is true or not\n",
    "        - initial_balance \n",
    "        - pvs : array of portfolio value\n",
    "        '''\n",
    "        \n",
    "        with lock:\n",
    "            # action, num_stocks, outvals_value, outvals_policy, pvs has same size\n",
    "            # create an array with same size as actions and use as x-axis\n",
    "            actions = np.array(actions)     # action array of an agent\n",
    "            # turn value network output as an array\n",
    "            outvals_value = np.array(outvals_value)\n",
    "            # turn policy network output as an array\n",
    "            outvals_policy = np.array(outvals_policy)\n",
    "            # turn initial balance as an array\n",
    "            pvs_base = np.zeros(len(actions)) + initial_balance     # array([initial_balance, initial_balance, initial_balance, ...])\n",
    "            \n",
    "            # chart 2. agent states (action, num_stocks)\n",
    "            for action, color in zip(action_list, self.COLORS):\n",
    "                for i in self.x[actions == action]:\n",
    "                    # express actions as background color : red for buying, blue for selling\n",
    "                    self.axes[1].axvline(i, color=color, alpha=0.1)\n",
    "            self.axes[1].plot(self.x, num_stocks, '-k')     # plot number of stocks\n",
    "            \n",
    "            # chart 3. value network (prediction value for action)\n",
    "            if (len(outvals_value)) > 0:\n",
    "                max_actions = np.argmax(outvals_value, axis=1)\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    # plot background\n",
    "                    for idx in self.x:\n",
    "                        if max_actions[idx] == action:\n",
    "                            self.axes[2].axvline(idx, color=color, alpha=0.1)\n",
    "                    # plot value network\n",
    "                    ## red for buying, blue for selling, green for holding\n",
    "                    ## if no prediction for action, no plot green chart\n",
    "                    self.axes[2].plot(self.x, outvals_value[:, action], color=color, linestyle='-')\n",
    "            \n",
    "            # chart 4. policy network\n",
    "            # plot exploration as yellow background\n",
    "            for exp_idx in exps:\n",
    "                self.axes[3].axvline(exp_idx, color='y')\n",
    "            # plot action as background\n",
    "            _outvals = outvals_policy if len(outvals_policy) > 0 else outvals_value\n",
    "            for idx, outval in zip(self.x, _outvals):\n",
    "                color = 'white'\n",
    "                if np.isnan(outval.max()):\n",
    "                    continue\n",
    "                # with no exploration area, red for buying, blue for selling\n",
    "                if outval.argmax() == Agent.ACTION_BUY:\n",
    "                    color = self.COLORS[0]      # red for buying\n",
    "                elif outval.argmax() == Agent.ACTION_SELL:\n",
    "                    color = self.COLORS[1]      # blue for selling\n",
    "                elif outval.argmax() == Agent.ACTION_HOLD:\n",
    "                    color = self.COLORS[2]      # green for holding\n",
    "                self.axes[3].axvline(idx, color=color, alpha=0.1)\n",
    "                \n",
    "            # plot policy network\n",
    "            # red for buying policy network output, blue for selling policy network\n",
    "            # when red line is above blue line, buy stocks, otherwise sell stocks\n",
    "            if len(outvals_policy) > 0:\n",
    "                for action, color in zip(action_list, self.COLORS):\n",
    "                    self.axes[3].plot(\n",
    "                        self.x, outvals_policy[:, action],\n",
    "                        color=color, linestyle='-'\n",
    "                    )\n",
    "                    \n",
    "            # chart 5. portfolio value\n",
    "            # horzontal line for initial balance\n",
    "            self.axes[4].axhline(\n",
    "                initial_balance, linestyle='-', color='gray'\n",
    "            )\n",
    "            \n",
    "            self.axes[4].fill_between(\n",
    "                self.x, pvs, pvs_base,\n",
    "                where=pvs > pvs_base, facecolor='r', alpha=0.1\n",
    "            )\n",
    "            self.axes[4].plot(self.x, pvs, '-k')\n",
    "            self.axes[4].xaxis.set_ticks(self.xticks)\n",
    "            self.axes[4].xaxis.set_ticklabels(self.xlabels)\n",
    "            \n",
    "            # epoch and exploration rate\n",
    "            self.fig.suptitle(f'{self.title}\\nEPOCH:{epoch_str}/{num_epochs} EPSILON:{epsilon:.2f}')\n",
    "            # adjust canvas layout\n",
    "            self.fig.tight_layout()\n",
    "            self.fig.subplots_adjust(top=0.85)\n",
    "            \n",
    "    def clear(self, xlim):\n",
    "        with lock:\n",
    "            _axes = self.axes.tolist()\n",
    "            # intial chart except non changeable value\n",
    "            for ax in _axes[1:]:\n",
    "                ax.cla()        # initialize chart\n",
    "                ax.relim()      # initialize limit\n",
    "                ax.autoscale()  # reset scale\n",
    "            \n",
    "            # reset y-axis label\n",
    "            self.axes[1].set_ylabel('Agent')\n",
    "            self.axes[2].set_ylabel('V')\n",
    "            self.axes[3].set_ylabel('P')\n",
    "            self.axes[4].set_ylabel('PV')\n",
    "            for ax in _axes:\n",
    "                ax.set_xlim(xlim)       # reset limit in x-axis\n",
    "                ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "                ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "                # set equal width horizontally\n",
    "                ax.ticklabel_format(useOffset=False)\n",
    "                \n",
    "    def save(self, path):\n",
    "        with lock:\n",
    "            self.fig.savefig(path)\n",
    "            \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "Policy $\\pi$ is a function that connectes states to action probabilities. Action probabilities are for getting $a\\sim\\pi(s)$. In the REINFORCE algorithm, agent trains policies and acts as trained policies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function\n",
    "\n",
    "- Reward $R_t(\\tau)$\n",
    "$$R_t(\\tau)=\\sum_{t^{\\\\prime}=t}^T\\gamma^{t^{\\prime}-t}r_{t^\\prime}$$\n",
    "\n",
    "- If $t=0$, the equation above is the reward of a full episode, and an object can be defined as an expectated reward of total episodes.\n",
    "\n",
    "$$J(\\pi_{\\theta})=\\mathbb{E}_{\\tau\\sim\\pi_{\\theta}}\\left[\\sum_{t=0}^T \\gamma^t r_t\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy gradient\n",
    "\n",
    "- Policy gradient algorithm solves the problem below.\n",
    "$$\\max_{\\theta}J(\\pi_{\\theta})=\\mathbb{E}_{\\tau\\sim\\pi_\\theta}[R(\\tau)]$$\n",
    "\n",
    "- We perform policy gradient for maximizing the object.\n",
    "\n",
    "$$\\theta \\leftarrow \\theta + \\alpha\\triangledown_\\theta j(\\pi_\\theta)$$\n",
    "\n",
    "- And policy gradient can be defined as follows.\n",
    "$$\\triangledown_{\\theta}J(\\pi_\\theta)=\\mathbb{E}_{\\tau\\sim\\pi_\\theta}\\left[\\sum_{t=0}^T R_r(\\tau)\\triangledown_\\theta\\log\\pi_\\theta(a_t|s_t)\\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REINFORCE Algorithm\n",
    "\n",
    "#### pseudo code\n",
    "\n",
    "- Initialize learning rate $\\alpha$\n",
    "\n",
    "- Initialize the weights $\\theta$ of policy network $\\pi_\\theta$\n",
    "\n",
    "- For episode = 0, ..., MAX_EPSIODE do:\n",
    "\n",
    "    - Get samples $\\tau=(s_0,a_0,r_0), ..., (s_T, a_T, r_T)$\n",
    "\n",
    "    - Set $\\triangledown_\\theta J(\\pi_\\theta)=0$\n",
    "\n",
    "    - For $t=0, ..., T$ do:\n",
    "\n",
    "        - $R_t(\\tau)=\\sum_{t^\\prime=t}^T\\gamma^{t^\\prime-t}r^\\prime_t$\n",
    "\n",
    "        - $\\triangledown_\\theta J(\\pi_\\theta)=\\triangle_\\theta J(\\pi_\\theta)+R_t(\\tau)\\triangledown_\\theta\\log\\pi_\\theta(a_t|s_t)$\n",
    "    \n",
    "    - End for\n",
    "\n",
    "    - $\\theta=\\theta+\\alpha\\triangledown_\\theta J(\\pi_\\theta)$\n",
    "\n",
    "- End for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import abc \n",
    "import collections\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "LOGGER_NAME = 'rltrader'\n",
    "logger = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.path.pardir))\n",
    "\n",
    "class ReinforcementLearner:\n",
    "    ''' \n",
    "    Attributes\n",
    "    ----------\n",
    "    - stock_code\n",
    "    - stock_data : stock data\n",
    "    - environment\n",
    "    - agent\n",
    "    - training_data\n",
    "    - value_network\n",
    "    - policy_network\n",
    "    \n",
    "    Functions\n",
    "    --------\n",
    "    - init_value_network() : function for creating value network\n",
    "    - init_policy_network() : function for creating policy network\n",
    "    - build_sample() : get samples from environment instances\n",
    "    - get_batch() : create batch training data\n",
    "    - update_network() : training value network and policy network\n",
    "    - fit() : request train value and policy network\n",
    "    - run() : perform reinforcement learning\n",
    "    - save_models() : save value and policy network\n",
    "    '''\n",
    "    \n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    def __init__(self, rl_method='dqn', stock_code=None,\n",
    "                 stock_data=None, training_data=None, \n",
    "                 min_trading_price=100, max_trading_price=10000,\n",
    "                 net='cnn', num_steps=1, lr=0.0005,\n",
    "                 discount_factor=0.9, num_epochs=1000,\n",
    "                 balance=100000, start_epsilon=1,\n",
    "                 value_network=None, policy_network=None,\n",
    "                 output_path='', reuse_models=True, gen_output=True):\n",
    "        ''' \n",
    "        Attributes\n",
    "        ---------\n",
    "        - rl_method : reinforcement learning method 'dqn', 'pg', 'ac', 'a2c', 'a3c', 'ppo', ...\n",
    "        - stock_code\n",
    "        - stock_data\n",
    "        - training_data : preprocessed data\n",
    "        - min_trading_price, max_trading_price\n",
    "        - net : network. 'dnn', 'lstm', 'cnn'\n",
    "        - n_steps : LTSM, CNN sequence length\n",
    "        - lr : learning rate\n",
    "        - discount_rate\n",
    "        - num_epochs : number of training epochs\n",
    "        - balance : initial balance\n",
    "        - start_epsilon\n",
    "        - value_network, policy_network\n",
    "        - output_path \n",
    "        - reuse_models\n",
    "        '''\n",
    "        \n",
    "        # check arguments\n",
    "        assert min_trading_price > 0\n",
    "        assert max_trading_price > 0\n",
    "        assert max_trading_price >= min_trading_price\n",
    "        assert num_epochs > 0\n",
    "        assert lr > 0\n",
    "        \n",
    "        # set reinforcement learning\n",
    "        self.rl_method = rl_method\n",
    "        self.discount_factor = discount_factor\n",
    "        self.num_epochs = num_epochs\n",
    "        self.start_epsilon = start_epsilon\n",
    "        \n",
    "        # set environment\n",
    "        self.stock_code = stock_code\n",
    "        self.stock_data = stock_data\n",
    "        self.environment = Environment(stock_data)\n",
    "        \n",
    "        # set agent\n",
    "        self.agent = Agent(self.environment, balance, min_trading_price, max_trading_price)\n",
    "        \n",
    "        # training data\n",
    "        self.training_data = training_data\n",
    "        self.sample = None\n",
    "        self.training_data_idx = -1\n",
    "        \n",
    "        # vector size = training vector size + agent state size\n",
    "        self.num_features = self.agent.STATE_DIM\n",
    "        if self.training_data is not None:\n",
    "            self.num_features += self.training_data.shape[1]\n",
    "        \n",
    "        # set network\n",
    "        self.net = net\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.value_network = value_network\n",
    "        self.policy_network = policy_network\n",
    "        self.reuse_models = reuse_models\n",
    "        \n",
    "        # visualization module\n",
    "        self.visualizer = Visualizer()\n",
    "        \n",
    "        # memeory\n",
    "        self.memory_sample = []     # training data sample\n",
    "        self.memory_action = []     # actions taken\n",
    "        self.memory_reward = []     # reward obtained\n",
    "        self.memory_value = []      # prediction value for action\n",
    "        self.memory_policy = []     # prediction probability for action\n",
    "        self.memory_pv = []         # portfolio value\n",
    "        self.memory_num_stocks = [] # number of stocks\n",
    "        self.memory_exp_idx = []    # exploration index\n",
    "        \n",
    "        # exploration epoch info\n",
    "        self.loss = 0               # loss during epoch\n",
    "        self.itr_cnt = 0            # number of iterations with profit\n",
    "        self.exploration_cnt = 0    # count of exploration\n",
    "        self.batch_size = 0         # number of training\n",
    "        \n",
    "        # log output\n",
    "        self.output_path = output_path\n",
    "        self.gen_output = gen_output\n",
    "        \n",
    "    def init_value_network(self, shared_network=None, activation='linear', loss='mse'):\n",
    "        if self.net == 'dnn':\n",
    "            self.value_network = DNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, \n",
    "                # num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'cnn':\n",
    "            self.value_network = CNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'lstm':\n",
    "            self.value_network = LSTMNetwork(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        if self.reuse_models and os.path.exists(self.value_network_path):\n",
    "            self.value_network.load_model(model_path=self.value_network_path)\n",
    "            \n",
    "    def init_policy_network(self, shared_network=None, activation='sigmoid', loss='binary_crossentropy'):\n",
    "        if self.net == 'dnn':\n",
    "            self.policy_network = DNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, \n",
    "                # num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "        \n",
    "        elif self.net == 'lstm':\n",
    "            self.policy_network = LSTMNetwork(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        elif self.net == 'cnn':\n",
    "            self.policy_network = CNN(\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS,\n",
    "                lr=self.lr, num_steps=self.num_steps,\n",
    "                shared_network=shared_network,\n",
    "                activation=activation, loss=loss\n",
    "            )\n",
    "            \n",
    "        if self.reuse_models and os.path.exists(self.policy_network_path):\n",
    "            self.policy_network.load_model(model_path=self.policy_network_path)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.sample = None\n",
    "        self.training_data_idx = -1\n",
    "        \n",
    "        # reset environment\n",
    "        self.environment.reset()\n",
    "        \n",
    "        # reset agent\n",
    "        self.agent.reset()\n",
    "        \n",
    "        # reset visualizer\n",
    "        self.visualizer.clear([0, len(self.stock_data)])\n",
    "        \n",
    "        # reset memories\n",
    "        self.memory_sample = []\n",
    "        self.memory_action = []\n",
    "        self.memory_reward = []\n",
    "        self.memory_value = []\n",
    "        self.memory_policy = []\n",
    "        self.memory_pv = []\n",
    "        self.memory_num_stocks = []\n",
    "        self.memory_exp_idx = []\n",
    "        \n",
    "        # reset epoch info\n",
    "        self.loss = 0.\n",
    "        self.itr_cnt = 0\n",
    "        self.exploration_cnt = 0\n",
    "        self.batch_size = 0\n",
    "        \n",
    "    def build_sample(self):\n",
    "        # get next index data\n",
    "        self.environment.step()\n",
    "        # 47 samples + 3 agnet states = 50 features\n",
    "        if len(self.training_data) > self.training_data_idx + 1:\n",
    "            self.training_data_idx += 1\n",
    "            self.sample = self.training_data[self.training_data_idx].tolist()\n",
    "            self.sample.extend(self.agent.get_states())\n",
    "            return self.sample\n",
    "        return None\n",
    "    \n",
    "    # abstract method\n",
    "    @abc.abstractmethod\n",
    "    def get_batch(self):\n",
    "        pass\n",
    "    \n",
    "    # after generate batch data, call train_on_batch() medho to train value network and policy network\n",
    "    # value network : DQNLearner, ActorCriticLearner, A2CLearner\n",
    "    # policy network : PolicyGradientLearner, ActorCriticLearner, A2CLearner\n",
    "    # loss value after training is saves as instance. in case of training value and policy network return sum of both loss\n",
    "    def fit(self):\n",
    "        # generate batch data\n",
    "        x, y_value, y_policy = self.get_batch()\n",
    "        # initialize loss\n",
    "        self.loss = None\n",
    "        if len(x) > 0:\n",
    "            loss = 0\n",
    "            if y_value is not None:\n",
    "                # update value network\n",
    "                loss += self.value_network.train_on_batch(x, y_value)\n",
    "            if y_policy is not None:\n",
    "                # update policy network\n",
    "                loss += self.policy_network.train_on_batch(x, y_policy)\n",
    "            self.loss = loss\n",
    "            \n",
    "    # visualize one complete epoch\n",
    "    # in case of LSTM, CNN agent, the number of agent's actions, num_stocks, output of value network, output of policy network and portfolio value is less than daily price data by (num_steps -1). So we fill (num_steps -1) meaningless data \n",
    "    def visualize(self, epoch_str, num_epochs, epsilon):\n",
    "        self.memory_action = [Agent.ACTION_HOLD] * (self.num_steps - 1) + self.memory_action\n",
    "        self.memory_num_stocks = [0] * (self.num_steps - 1) + self.memory_num_stocks\n",
    "        if self.value_network is not None:\n",
    "            self.memory_value = [np.array([np.nan] * len(Agent.ACTIONS))] * (self.num_steps - 1) + self.memory_value\n",
    "        if self.policy_network is not None:\n",
    "            self.memory_policy = [np.array([np.nan] * len(Agent.ACTIONS))] * (self.num_steps - 1) + self.memory_policy\n",
    "        \n",
    "        self.memory_pv = [self.agent.initial_balance] * (self.num_steps - 1) + self.memory_pv\n",
    "        self.visualizer.plot(\n",
    "            epoch_str=epoch_str, num_epochs=num_epochs,\n",
    "            epsilon=epsilon, action_list=Agent.ACTIONS,\n",
    "            actions=self.memory_action,\n",
    "            num_stocks=self.memory_num_stocks,\n",
    "            outvals_value=self.memory_value,\n",
    "            outvals_policy=self.memory_policy,\n",
    "            exps=self.memory_exp_idx,\n",
    "            initial_balance=self.agent.initial_balance,\n",
    "            pvs=self.memory_pv,\n",
    "        )\n",
    "        self.visualizer.save(os.path.join(self.epoch_summary_dir, f'epoch_summary_{epoch_str}.png'))\n",
    "                             \n",
    "    def run(self, learning=True):\n",
    "        '''\n",
    "        Arguments\n",
    "        ---------\n",
    "        - learning : boolean if learning will be done or not\n",
    "            - True : after training, build value and policy network\n",
    "            - False: simulation with pretrined model\n",
    "        '''\n",
    "        info = (\n",
    "            f'[{self.stock_code}] RL:{self.rl_method} NET:{self.net}'\n",
    "            f' LR:{self.lr} DF:{self.discount_factor}'\n",
    "        )\n",
    "        with self.lock:\n",
    "            logger.debug(info)\n",
    "        \n",
    "        # start time\n",
    "        time_start = time.time()\n",
    "        \n",
    "        # prepare visualization\n",
    "        self.visualizer.prepare(self.environment.stock_data, info)\n",
    "        \n",
    "        # prepare folders foe saving results\n",
    "        if self.gen_output:\n",
    "            self.epoch_summary_dir = os.path.join(self.output_path, f'epoch_summary_{self.stock_code}')\n",
    "            if not os.path.isdir(self.epoch_summary_dir):\n",
    "                os.makedirs(self.epoch_summary_dir)\n",
    "            else:\n",
    "                for f in os.listdir(self.epoch_summary_dir):\n",
    "                    os.remove(os.path.join(self.epoch_summary_dir, f))\n",
    "                    \n",
    "        # reset info about training\n",
    "        # save the most highest portfolio value at max_portfolio_value variable\n",
    "        max_portfolio_value = 0\n",
    "        # save the count of epochs with profit\n",
    "        epoch_win_cnt = 0\n",
    "        \n",
    "        # iterate epochs\n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            # start time of an epoch\n",
    "            time_start_epoch = time.time()\n",
    "            \n",
    "            # queue for making step samples\n",
    "            q_sample = collections.deque(maxlen=self.num_steps)\n",
    "            \n",
    "            # reset environment, networks, visualizer and memories\n",
    "            self.reset()\n",
    "            \n",
    "            # decaying exploration rate\n",
    "            if learning:\n",
    "                epsilon = self.start_epsilon * (1 - (epoch / (self.num_epochs - 1)))\n",
    "            else:\n",
    "                epsilon = self.start_epsilon\n",
    "                \n",
    "            for i in tqdm(range(len(self.training_data)), leave=False):\n",
    "                # create samples\n",
    "                next_sample = self.build_sample()\n",
    "                if next_sample is None:\n",
    "                    break\n",
    "                \n",
    "                # save samples until its size becomes as num_steps\n",
    "                q_sample.append(next_sample)\n",
    "                if len(q_sample) < self.num_steps:\n",
    "                    continue\n",
    "                \n",
    "                # prediction of value and policyn entwork\n",
    "                pred_value = None\n",
    "                pred_policy = None\n",
    "                # get predicted value of actions\n",
    "                if self.value_network is not None:\n",
    "                    pred_value = self.value_network.predict(list(q_sample))\n",
    "                # get predicted probabilities of actions\n",
    "                if self.policy_network is not None:\n",
    "                    pred_policy = self.policy_network.predict(list(q_sample))\n",
    "                    \n",
    "                # make decisions based on predicted value and probabilities\n",
    "                # decide actions based on based on networks or exploration\n",
    "                # decide actions randomly with epsilon probability or according to network output with (1 - epsilon)\n",
    "                # policy network output is the probabilities that selling or buying increase portfolio value. if output for buying is larger than that for selling, then buy the stock. Otherwise, sell it.\n",
    "                # if there is no output of policy network, select the action with the hightes output of value network.\n",
    "                action, confidence, exploration = self.agent.decide_action(pred_value, pred_policy, epsilon)\n",
    "                \n",
    "                # get rewards from action\n",
    "                reward = self.agent.act(action, confidence)\n",
    "                \n",
    "                # save action and the results in the memory\n",
    "                self.memory_sample.append(list(q_sample))\n",
    "                self.memory_action.append(action)\n",
    "                self.memory_reward.append(reward)\n",
    "                if self.value_network is not None:\n",
    "                    self.memory_value.append(pred_value)\n",
    "                if self.policy_network is not None:\n",
    "                    self.memory_policy.append(pred_policy)\n",
    "                self.memory_pv.append(self.agent.portfolio_value)\n",
    "                self.memory_num_stocks.append(self.agent.num_stocks)\n",
    "                if exploration:\n",
    "                    self.memory_exp_idx.append(self.training_data_idx)\n",
    "                    \n",
    "                # update iteration info\n",
    "                self.batch_size += 1\n",
    "                self.itr_cnt += 1\n",
    "                self.exploration_cnt +=1 if exploration else 0\n",
    "                \n",
    "            # training network after completing an epoch\n",
    "            if learning:\n",
    "                self.fit()\n",
    "            \n",
    "            # log about an epoch info\n",
    "            # check the length of epoch number string\n",
    "            num_epochs_digit = len(str(self.num_epochs))\n",
    "            # fill '0' as same size as the length of number of epochs\n",
    "            epoch_str = str(epoch + 1).rjust(num_epochs_digit, '0')\n",
    "            time_end_epoch = time.time()\n",
    "            # save time of an epoch\n",
    "            elapsed_time_epoch = time_end_epoch - time_start_epoch\n",
    "            logger.debug(f'[{self.stock_code}][Epoch {epoch_str}]'\n",
    "                         f'Epsilon:{epsilon:.4f} #Expl.:{self.exploration_cnt}/{self.itr_cnt} '\n",
    "                         f'#Buy:{self.agent.num_buy} #Sell:{self.agent.num_sell} #Hold:{self.agent.num_hold} '\n",
    "                         f'#Stocks:{self.agent.num_stocks} PV:{self.agent.portfolio_value:,.0f} '\n",
    "                         f'Loss:{self.loss:.6f} ET:{elapsed_time_epoch:.4f}')\n",
    "            \n",
    "            # visualize epoch information\n",
    "            if self.gen_output:\n",
    "                if self.num_epochs == 1 or (epoch + 1) % max(int(self.num_epochs / 100), 1) == 0:\n",
    "                    self.visualize(epoch_str, self.num_epochs, epsilon)\n",
    "            \n",
    "            # update training info\n",
    "            max_portfolio_value = max(\n",
    "                max_portfolio_value, self.agent.portfolio_value\n",
    "            )\n",
    "            if self.agent.portfolio_value > self.agent.initial_balance:\n",
    "                epoch_win_cnt += 1\n",
    "                \n",
    "        # end time\n",
    "        time_end = time.time()\n",
    "        elapsed_time = time_end - time_start\n",
    "        \n",
    "        # log about training\n",
    "        with self.lock:\n",
    "            logger.debug(f'[{self.stock_code} Elapsed Time:{elapsed_time:.4f}]'\n",
    "                         f'Max PV:{max_portfolio_value:,.0f} #Win:{epoch_win_cnt}')\n",
    "        \n",
    "    def save_models(self):\n",
    "        if self.value_network is not None and self.value_network_path is not None:\n",
    "            self.value_network.save_model(self.value_network_path)\n",
    "        if self.policy_network is not None and self.policy_network_path is not None:\n",
    "            self.policy_network.save_model(self.policy_network_path)\n",
    "            \n",
    "    # wihtou training, just predict actions based on samples\n",
    "    def predict(self):\n",
    "        # initiate an agent\n",
    "        self.agent.reset()\n",
    "        \n",
    "        # queue for step samples\n",
    "        q_sample = collections.deque(maxlen=self.num_steps)\n",
    "        \n",
    "        result = []\n",
    "        while True:\n",
    "            # create samples\n",
    "            next_sample = self.build_sample()\n",
    "            if next_sample is None:\n",
    "                break\n",
    "            \n",
    "            # save samples as many as num_steps\n",
    "            q_sample.append(next_sample)\n",
    "            if len(q_sample) < self.num_steps:\n",
    "                continue\n",
    "            \n",
    "            # prediction based on value and policy network\n",
    "            pred_value = None\n",
    "            pred_policy = None\n",
    "            if self.value_network is not None:\n",
    "                pred_value = self.value_network.predict(list(q_sample)).tolist()\n",
    "            if self.policy_network is not None:\n",
    "                pred_policy = self.policy_network.predict(list(q_sample)).tolist()\n",
    "                \n",
    "            # decide action based on the network\n",
    "            result.append((self.environment.step[0]. pred_value, pred_policy))\n",
    "            \n",
    "        if self.gen_output:\n",
    "            with open(os.path.join(self.output_path, f'pred_{self.stock_code}.json'), 'w') as f:\n",
    "                print(json.dumps(result), file=f)\n",
    "                \n",
    "        return result\n",
    "             \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNLearner(ReinforcementLearner):\n",
    "    def __init__(self, *args, value_network_path=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.value_network_path = value_network_path\n",
    "        # create value network\n",
    "        self.init_value_network()\n",
    "    \n",
    "    # abstract method\n",
    "    def get_batch(self):\n",
    "        # reverse memory array\n",
    "        memory = zip(\n",
    "            reversed(self.memory_sample),\n",
    "            reversed(self.memory_action),\n",
    "            reversed(self.memory_value),\n",
    "            reversed(self.memory_reward),\n",
    "        )\n",
    "        \n",
    "        # prepare sample array 'x' and label array 'y_value' with 0 value\n",
    "        x = np.zeros((len(self.memory_sample), self.num_steps, self.num_features))\n",
    "        y_value = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        value_max_next = 0\n",
    "        \n",
    "        # we can handle from the last data becase of reversed memory\n",
    "        for i, (sample, action, value, reward) in enumerate(memory):\n",
    "            # sample\n",
    "            x[i] = sample\n",
    "            # # reward for training\n",
    "            ## memory_reward[-1] : last profit/loss in the batch data\n",
    "            ## reward : profit/loss at the time of action\n",
    "            r = self.memory_reward[-1] - reward\n",
    "            # value network output\n",
    "            y_value[i] = value\n",
    "            # state-action value\n",
    "            y_value[i, action] = r + self.discount_factor * value_max_next\n",
    "            # save the maximum next state value\n",
    "            value_max_next = value.max()\n",
    "            \n",
    "        # return sample array, value network label, policy network label\n",
    "        # DQN has no policy network, return None\n",
    "        return x, y_value, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientLearner(ReinforcementLearner):\n",
    "    def __init__(self, *args, policy_network_path=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.policy_network_path = policy_network_path\n",
    "        self.init_policy_network()\n",
    "        \n",
    "    def get_batch(self):\n",
    "        memory = zip(\n",
    "            reversed(self.memory_sample),\n",
    "            reversed(self.memory_action),\n",
    "            reversed(self.memory_policy),\n",
    "            reversed(self.memory_reward),\n",
    "        )\n",
    "        # sample array composed of training data and agent states\n",
    "        x = np.zeros((len(self.memory_sample), self.num_steps, self.num_features))\n",
    "        # label array for training policy network\n",
    "        y_policy = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        for i, (sample, action, policy, reward) in enumerate(memory):\n",
    "            # feature vector\n",
    "            x[i] = sample\n",
    "            r = self.memory_reward[-1] - reward\n",
    "            # policy network output\n",
    "            y_policy[i, :] = policy\n",
    "            # make it label with sigmoid to the reward\n",
    "            y_policy[i, action] = sigmoid(r)\n",
    "        \n",
    "        # there is no value network in PG\n",
    "        return x, None, y_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ActorCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticLearner(ReinforcementLearner):\n",
    "    def __init__(self, *args, shared_network=None,\n",
    "                 value_network_path=None, policy_network_path=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # shared layer of policy and value network\n",
    "        if shared_network is None:\n",
    "            self.shared_network = Network.get_shared_network(\n",
    "                net=self.net, num_steps=self.num_steps,\n",
    "                input_dim=self.num_features,\n",
    "                output_dim=self.agent.NUM_ACTIONS\n",
    "            )\n",
    "        else:\n",
    "            self.shared_network = shared_network\n",
    "        self.value_network_path = value_network_path\n",
    "        self.policy_network_path = policy_network_path\n",
    "        if self.value_network is None:\n",
    "            self.init_value_network(shared_network=self.shared_network)\n",
    "        if self.policy_network is None:\n",
    "            self.init_policy_network(shared_network=self.shared_network)\n",
    "    \n",
    "    def get_batch(self):\n",
    "        memory = zip(\n",
    "            reversed(self.memory_sample),\n",
    "            reversed(self.memory_action),\n",
    "            reversed(self.memory_value),\n",
    "            reversed(self.memory_policy),\n",
    "            reversed(self.memory_reward),\n",
    "        )\n",
    "        x = np.zeros((len(self.memory_sample), self.num_steps, self.num_features))\n",
    "        y_value = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        y_policy = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        value_max_next = 0\n",
    "        for i, (sample, action, value, policy, reward) in enumerate(memory):\n",
    "            x[i] = sample\n",
    "            r = self.memory_reward[-1] - reward\n",
    "            # value network label\n",
    "            y_value[i, :] = value\n",
    "            y_value[i, action] = r + self.discount_factor * value_max_next\n",
    "            y_policy[i, :] = policy\n",
    "            # policy network label\n",
    "            y_policy[i, action] = sigmoid(r)\n",
    "            value_max_next = value.max()\n",
    "        return x, y_value, y_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2CLearner(ActorCriticLearner):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def get_batch(self):\n",
    "        memory = zip(\n",
    "            reversed(self.memory_sample),\n",
    "            reversed(self.memory_action),\n",
    "            reversed(self.memory_value),\n",
    "            reversed(self.memory_policy),\n",
    "            reversed(self.memory_reward)\n",
    "        )\n",
    "        x = np.zeros((len(self.memory_sample), self.num_steps, self.num_features))\n",
    "        y_value = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        y_policy = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        value_max_next = 0\n",
    "        reward_next = self.memory_reward[-1]\n",
    "        \n",
    "        for i, (sample, action, value, policy, reward) in enumerate(memory):\n",
    "            x[i] = sample\n",
    "            r = reward_next + self.memory_reward[-1] - reward * 2\n",
    "            y_value[i, :] = value\n",
    "            y_value[i, action] = np.tanh(r + self.discount_factor * value_max_next)\n",
    "            advantage = y_value[i, action] - y_value[i].mean()\n",
    "            y_policy[i, :] = policy\n",
    "            y_policy[i, action] = sigmoid(advantage)\n",
    "            value_max_next = value.max()\n",
    "        return x, y_value, y_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A3CLearner(ReinforcementLearner):\n",
    "    def __init__(self, *args, list_stock_code=None,\n",
    "                 list_stock_data=None, list_training_data=None,\n",
    "                 list_min_trading_price=None, list_max_trading_price=None,\n",
    "                 value_network_path=None, policy_network_path=None,\n",
    "                 **kwargs):\n",
    "        assert len(list_training_data) > 0\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_features += list_training_data[0].shape[1]\n",
    "        \n",
    "        ''' \n",
    "        create A2C learner instances as many as list size\n",
    "        each A2C learner shares value and policy network\n",
    "        '''\n",
    "        \n",
    "        # create shared network\n",
    "        self.shared_network = Network.get_shared_network(\n",
    "            net=self.net, num_steps=self.num_steps,\n",
    "            input_dim=self.num_features,\n",
    "            output_dim=self.agent.NUM_ACTIONS\n",
    "        )\n",
    "        self.value_network_path = value_network_path\n",
    "        self.policy_network_path = policy_network_path\n",
    "        if self.value_network is None:\n",
    "            self.init_value_network(shared_network=self.shared_network)\n",
    "        if self.policy_network is None:\n",
    "            self.init_policy_network(shared_network=self.shared_network)\n",
    "            \n",
    "        # create A2C instances\n",
    "        self.learners = []\n",
    "        for (stock_code, stock_data, training_data,\n",
    "             min_trading_price, max_trading_price) in zip(\n",
    "                 list_stock_code, list_stock_data, list_training_data,\n",
    "                 list_min_trading_price, list_max_trading_price\n",
    "             ):\n",
    "                 learner = A2CLearner(*args, stock_code=stock_code,\n",
    "                                      stock_data=stock_data,\n",
    "                                      training_data=training_data,\n",
    "                                      min_trading_price=min_trading_price,\n",
    "                                      max_trading_price=max_trading_price,\n",
    "                                      shared_network=self.shared_network,\n",
    "                                      value_network=self.value_network,\n",
    "                                      policy_network=self.policy_network, **kwargs)\n",
    "                 self.learners.append(learner)\n",
    "    \n",
    "    def run(self, learning=True):\n",
    "        threads = []\n",
    "        # execute run() method of each A2CLearne instances simultaneiously\n",
    "        for learner in self.learners:\n",
    "            threads.append(threading.Thread(\n",
    "                target=learner.run, daemon=True, kwargs={'learning': learning}\n",
    "            ))\n",
    "        \n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "            \n",
    "    def predict(self):\n",
    "        threads = []\n",
    "        for learner in self.learners:\n",
    "            threads.append(threading.Thread(\n",
    "                target=learner.predict, daemon=True\n",
    "            ))\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOLearner(A2CLearner):\n",
    "    def __init__(self, *args, lmb=0.95, eps=0.1, K=3, **kwargs):\n",
    "        # kwargs['value_network_activation'] = 'tanh'\n",
    "        # kwargs['policy_network_activation'] = 'tanh'\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lmb = lmb\n",
    "        self.eps = eps\n",
    "        self.K = K\n",
    "        \n",
    "    def get_batch(self):\n",
    "        memory = zip(\n",
    "            reversed(self.memory_sample),\n",
    "            reversed(self.memory_action),\n",
    "            reversed(self.memory_value),\n",
    "            reversed(self.memory_policy),\n",
    "            reversed(self.memory_reward),\n",
    "        )\n",
    "        x = np.zeros((len(self.memory_sample), self.num_steps, self.num_features))\n",
    "        y_value = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        y_policy = np.zeros((len(self.memory_sample), self.agent.NUM_ACTIONS))\n",
    "        value_max_next = 0\n",
    "        reward_next = self.memory_reward[-1]\n",
    "        for i, (sample, action, value, policy, reward) in enumerate(memory):\n",
    "            x[i] = sample\n",
    "            y_value[i, :] = value\n",
    "            y_value[i, action] = np.tanh(reward + self.discount_factor * value_max_next)\n",
    "            advantage = y_value[i, action] - y_value[i].mean()\n",
    "            y_policy[i, :] = policy\n",
    "            y_policy[i, action] = advantage\n",
    "            value_max_next = value.max()\n",
    "        return x, y_value, y_policy\n",
    "    \n",
    "    def fit(self):\n",
    "        x, y_value, y_policy = self.get_batch()\n",
    "        # initialize loss\n",
    "        self.loss = None\n",
    "        if len(x) > 0:\n",
    "            loss = 0\n",
    "            if y_value is not None:\n",
    "                # update value network\n",
    "                loss += self.value_network.train_on_batch(x, y_value)\n",
    "            if y_policy is not None:\n",
    "                # update policy network\n",
    "                loss += self.policy_network.train_on_batch_for_ppo(x, y_policy, list(reversed(self.memory_action)), self.eps, self.K)\n",
    "            self.loss = loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import logging\n",
    "# import argparse\n",
    "# import json\n",
    "\n",
    "# os.environ['RLTRADER_BASE'] = 'C:\\project\\github\\projects\\trader'\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     mode = 'train'      # 'train', 'test', 'update', 'predict'\n",
    "#     name = 'Apple'\n",
    "#     rl_method = 'dqn'\n",
    "#     net = 'cnn'\n",
    "#     start_date = '2018-01-01'\n",
    "#     end_date = '2022-12-31'\n",
    "#     lr = 0.01\n",
    "#     discount_factor = 0.7\n",
    "#     initial_balance = 1000000\n",
    "#     stock_codes = ['AAPL']\n",
    "    \n",
    "#     # learner's parameter\n",
    "#     output_name = f'{mode}_{name}_{rl_method}_{net}'\n",
    "#     # reinforcement learning True or False\n",
    "#     learning = mode in ['train', 'update']\n",
    "#     # use model flag\n",
    "#     reuse_models = mode in ['test', 'update', 'predict']\n",
    "#     value_network_name = f'{name}_{rl_method}_{net}_value.mdl'\n",
    "#     policy_network_name = f'{name}_{rl_method}_{net}_policy.mdl'\n",
    "#     start_epsilon = 1 if mode in ['train', 'update'] else 0\n",
    "#     num_epochs = 1000 if mode in ['train', 'update'] else 0\n",
    "#     num_steps = 5 if net in ['lstm', 'cnn'] else 1\n",
    "    \n",
    "#     # output path\n",
    "#     output_path = os.path.join(BASE_DIR, 'output', output_name)\n",
    "#     if not os.path.isdir(output_path):\n",
    "#         os.makedirs(output_path)\n",
    "    \n",
    "#     # model path\n",
    "#     value_network_path = os.path.join(BASE_DIR, 'models', value_network_name)\n",
    "#     policy_network_path = os.path.join(BASE_DIR, 'models', policy_network_name)\n",
    "    \n",
    "#     # setting for logging\n",
    "#     # log level DEBUG < INFO < WARNING < CRITICAL. more than DEBUG\n",
    "#     log_path = os.path.join(output_path, f'{output_name}.log')\n",
    "#     if os.path.exists(log_path):\n",
    "#         os.remove(log_path)\n",
    "#     logging.basicConfig(format='%(message)s')\n",
    "#     logger = logging.getLogger(LOGGER_NAME)\n",
    "#     logger.setLevel(logging.DEBUG)\n",
    "#     logger.propagate = False\n",
    "#     stream_handler = logging.StreamHandler(sys.stdout)\n",
    "#     stream_handler.setLevel(logging.INFO)\n",
    "#     file_handler = logging.FileHandler(filename=log_path, encoding='utf-8')\n",
    "#     file_handler.setLevel(logging.DEBUG)\n",
    "#     logger.addHandler(stream_handler)\n",
    "#     logger.addHandler(file_handler)\n",
    "    \n",
    "#     common_params = {}\n",
    "#     list_stock_code = []\n",
    "#     list_training_data = []\n",
    "#     list_min_trading_price = []\n",
    "#     list_max_trading_price = []\n",
    "    \n",
    "#     for stock_code in stock_codes:\n",
    "#         _, stock_data, training_data = load_data(\n",
    "#             stock_code, start_date, end_date\n",
    "#         )\n",
    "        \n",
    "#         assert len(stock_data) >= num_steps\n",
    "        \n",
    "#         # minimum and maximum trading price policy\n",
    "#         min_trading_price = 1\n",
    "#         max_trading_price = 10000\n",
    "        \n",
    "#         # common parameters\n",
    "#         common_params = {\n",
    "#             'rl_method': rl_method,\n",
    "#             'net': net, 'num_steps': num_steps,  'lr': lr,\n",
    "#             'balance': initial_balance, 'num_epochs': num_epochs,\n",
    "#             'discount_factor': discount_factor, 'start_epsilon': start_epsilon,\n",
    "#             'output_path': output_path, 'reuse_models': reuse_models\n",
    "#         }\n",
    "        \n",
    "#         # start reinforcement learning\n",
    "#         learner = None\n",
    "#         common_params.update({\n",
    "#             'stock_code': stock_code,\n",
    "#             'stock_data': stock_data,\n",
    "#             'training_data': training_data,\n",
    "#             'min_trading_price': min_trading_price,\n",
    "#             'max_trading_price': max_trading_price\n",
    "#         })\n",
    "        \n",
    "#         learner = DQNLearner(**{**common_params, 'value_network_path': value_network_path})\n",
    "        \n",
    "#         # check learner is not None\n",
    "#         assert learner is not None\n",
    "        \n",
    "#         if mode in ['train', 'test', 'update']:\n",
    "#             learner.run(learning=learning)\n",
    "            \n",
    "#             if mode in ['train', 'update']:\n",
    "#                 learner.save_models()\n",
    "        \n",
    "#         elif mode == 'predict':\n",
    "#             learner.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import logging\n",
    "# import argparse\n",
    "# import json\n",
    "\n",
    "# def run_trader(mode='train', stock_name='Apple', rl_method='dqn', net='cnn',\n",
    "#                start_date='2020-01-01', end_date='2023-12-31',\n",
    "#                lr=0.01, discount_factor=0.9,\n",
    "#                initial_balance=1000000, stock_code='AAPL',\n",
    "#                min_trading_price=1, max_trading_price=10000, num_epochs=1000):\n",
    "    \n",
    "#     os.environ['RLTRADER_BASE'] = 'C:\\project\\github\\projects\\trader'\n",
    "#     ''' \n",
    "#     Arguments\n",
    "#     --------\n",
    "#     mode : 'train', 'test', 'update', 'predict'\n",
    "#     rl_method : 'dqn', 'a2c', 'a3c', 'pg', 'ppo'\n",
    "#     '''\n",
    "\n",
    "#     # learner's parameter\n",
    "#     output_name = f'{mode}_{stock_name}_{rl_method}_{net}'\n",
    "#     # reinforcement learning True or False\n",
    "#     learning = mode in ['train', 'update']\n",
    "#     # use model flag\n",
    "#     reuse_models = mode in ['test', 'update', 'predict']\n",
    "#     value_network_name = f'{stock_name}_{rl_method}_{net}_value.mdl'\n",
    "#     policy_network_name = f'{stock_name}_{rl_method}_{net}_policy.mdl'\n",
    "#     start_epsilon = 1 if mode in ['train', 'update'] else 0\n",
    "#     num_epochs = num_epochs if mode in ['train', 'update'] else 0\n",
    "#     num_steps = 5 if net in ['lstm', 'cnn'] else 1\n",
    "    \n",
    "#     # output path\n",
    "#     output_path = os.path.join(BASE_DIR, 'output', output_name)\n",
    "#     if not os.path.isdir(output_path):\n",
    "#         os.makedirs(output_path)\n",
    "        \n",
    "#     # log parameters\n",
    "#     params = {\n",
    "#         'mode': mode,\n",
    "#         'stock_name': stock_name,\n",
    "#         'rl_method': rl_method,\n",
    "#         'net': net,\n",
    "#         'start_date': start_date,\n",
    "#         'end_date': end_date,\n",
    "#         'lr': lr,\n",
    "#         'discount_factor': discount_factor,\n",
    "#         'initial_balance': initial_balance,\n",
    "#         'stock_code': stock_code,\n",
    "#     }\n",
    "#     # params = json.dumps(vars(args))\n",
    "#     with open(os.path.join(output_path, 'params.json'), 'w') as f:\n",
    "#         f.write(str(params))\n",
    "    \n",
    "#     # model path\n",
    "#     value_network_path = os.path.join(BASE_DIR, 'models', value_network_name)\n",
    "#     policy_network_path = os.path.join(BASE_DIR, 'models', policy_network_name)\n",
    "    \n",
    "#     # setting for logging\n",
    "#     # log level DEBUG < INFO < WARNING < CRITICAL. more than DEBUG\n",
    "#     log_path = os.path.join(output_path, f'{output_name}.log')\n",
    "#     if os.path.exists(log_path):\n",
    "#         os.remove(log_path)\n",
    "#     logging.basicConfig(format='%(message)s')\n",
    "#     logger = logging.getLogger(LOGGER_NAME)\n",
    "#     logger.setLevel(logging.DEBUG)\n",
    "#     logger.propagate = False\n",
    "#     stream_handler = logging.StreamHandler(sys.stdout)\n",
    "#     stream_handler.setLevel(logging.INFO)\n",
    "#     file_handler = logging.FileHandler(filename=log_path, encoding='utf-8')\n",
    "#     file_handler.setLevel(logging.DEBUG)\n",
    "#     logger.addHandler(stream_handler)\n",
    "#     logger.addHandler(file_handler)\n",
    "    \n",
    "#     common_params = {}\n",
    "#     # list_stock_code = []\n",
    "#     # list_training_data = []\n",
    "#     # list_min_trading_price = []\n",
    "#     # list_max_trading_price = []\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#     _, stock_data, training_data = load_data(\n",
    "#         stock_code, start_date, end_date\n",
    "#     )\n",
    "        \n",
    "#     assert len(stock_data) >= num_steps\n",
    "        \n",
    "#     # minimum and maximum trading price policy\n",
    "#     min_trading_price = min_trading_price\n",
    "#     max_trading_price = max_trading_price\n",
    "        \n",
    "#     # common parameters\n",
    "#     common_params = {\n",
    "#         'rl_method': rl_method,\n",
    "#         'net': net, 'num_steps': num_steps,  'lr': lr,\n",
    "#         'balance': initial_balance, 'num_epochs': num_epochs,\n",
    "#         'discount_factor': discount_factor, 'start_epsilon': start_epsilon,\n",
    "#         'output_path': output_path, 'reuse_models': reuse_models\n",
    "#     }\n",
    "        \n",
    "#     # start reinforcement learning\n",
    "#     learner = None\n",
    "#     common_params.update({\n",
    "#         'stock_code': stock_code,\n",
    "#         'stock_data': stock_data,\n",
    "#         'training_data': training_data,\n",
    "#         'min_trading_price': min_trading_price,\n",
    "#         'max_trading_price': max_trading_price\n",
    "#     })\n",
    "    \n",
    "#     if rl_method == 'dqn':    \n",
    "#         learner = DQNLearner(**{**common_params, 'value_network_path': value_network_path})\n",
    "    \n",
    "#     elif rl_method == 'pg':\n",
    "#         learner = PolicyGradientLearner(**{**common_params, 'policy_network_path': policy_network_path})\n",
    "    \n",
    "#     elif rl_method == 'ac':\n",
    "#         learner = ActorCriticLearner(**{**common_params, 'value_network_path': value_network_path, 'policy_network_path': policy_network_path})\n",
    "    \n",
    "#     elif rl_method == 'a2c':\n",
    "#         learner = A2CLearner(**{**common_params,\n",
    "#                                 'value_network_path': value_network_path,\n",
    "#                                 'policy_network_path': policy_network_path})\n",
    "#     elif rl_method == 'ppo':\n",
    "#         learner = PPOLearner(**{**common_params,\n",
    "#                                 'value_network_path': value_network_path,\n",
    "#                                 'policy_network_path': policy_network_path})\n",
    "        \n",
    "#     # check learner is not None\n",
    "#     assert learner is not None\n",
    "        \n",
    "#     if mode in ['train', 'test', 'update']:\n",
    "#         learner.run(learning=learning)\n",
    "            \n",
    "#         if mode in ['train', 'update']:\n",
    "#             learner.save_models()\n",
    "        \n",
    "#     elif mode == 'predict':\n",
    "#         learner.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_trader(stock_name='TESLA', stock_code='TSLA', net='cnn', rl_method='ppo', num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import logging\n",
    "# import argparse\n",
    "# import json\n",
    "\n",
    "# def run_trader_a3c(mode='train', stock_names=['Apple', 'Tesla', 'Microsoft'], rl_method='dqn', net='cnn',\n",
    "#                start_date='2020-01-01', end_date='2023-12-31',\n",
    "#                lr=0.01, discount_factor=0.9,\n",
    "#                initial_balance=1000000, stock_codes=['AAPL', 'TSLA', 'MSFT'],\n",
    "#                min_trading_price=1, max_trading_price=10000, num_epochs=1000):\n",
    "    \n",
    "#     os.environ['RLTRADER_BASE'] = 'C:\\project\\github\\projects\\trader'\n",
    "#     ''' \n",
    "#     Arguments\n",
    "#     --------\n",
    "#     mode : 'train', 'test', 'update', 'predict'\n",
    "#     rl_method : 'dqn', 'a2c', 'a3c', 'pg', 'ppo'\n",
    "#     '''\n",
    "\n",
    "#     # learner's parameter\n",
    "#     output_name = f'{mode}_{stock_names}_{rl_method}_{net}'\n",
    "#     # reinforcement learning True or False\n",
    "#     learning = mode in ['train', 'update']\n",
    "#     # use model flag\n",
    "#     reuse_models = mode in ['test', 'update', 'predict']\n",
    "#     value_network_name = f'{stock_names}_{rl_method}_{net}_value.mdl'\n",
    "#     policy_network_name = f'{stock_names}_{rl_method}_{net}_policy.mdl'\n",
    "#     start_epsilon = 1 if mode in ['train', 'update'] else 0\n",
    "#     num_epochs = num_epochs if mode in ['train', 'update'] else 0\n",
    "#     num_steps = 5 if net in ['lstm', 'cnn', 'alex'] else 1\n",
    "    \n",
    "#     # output path\n",
    "#     output_path = os.path.join(BASE_DIR, 'output', output_name)\n",
    "#     if not os.path.isdir(output_path):\n",
    "#         os.makedirs(output_path)\n",
    "        \n",
    "#     # log parameters\n",
    "#     params = {\n",
    "#         'mode': mode,\n",
    "#         'stock_names': stock_names,\n",
    "#         'rl_method': rl_method,\n",
    "#         'net': net,\n",
    "#         'start_date': start_date,\n",
    "#         'end_date': end_date,\n",
    "#         'lr': lr,\n",
    "#         'discount_factor': discount_factor,\n",
    "#         'initial_balance': initial_balance,\n",
    "#         'stock_codes': stock_codes,\n",
    "#     }\n",
    "#     # params = json.dumps(vars(args))\n",
    "#     with open(os.path.join(output_path, 'params.json'), 'w') as f:\n",
    "#         f.write(str(params))\n",
    "    \n",
    "#     # model path\n",
    "#     value_network_path = os.path.join(BASE_DIR, 'models', value_network_name)\n",
    "#     policy_network_path = os.path.join(BASE_DIR, 'models', policy_network_name)\n",
    "    \n",
    "#     # setting for logging\n",
    "#     # log level DEBUG < INFO < WARNING < CRITICAL. more than DEBUG\n",
    "#     log_path = os.path.join(output_path, f'{output_name}.log')\n",
    "#     if os.path.exists(log_path):\n",
    "#         os.remove(log_path)\n",
    "#     logging.basicConfig(format='%(message)s')\n",
    "#     logger = logging.getLogger(LOGGER_NAME)\n",
    "#     logger.setLevel(logging.DEBUG)\n",
    "#     logger.propagate = False\n",
    "#     stream_handler = logging.StreamHandler(sys.stdout)\n",
    "#     stream_handler.setLevel(logging.INFO)\n",
    "#     file_handler = logging.FileHandler(filename=log_path, encoding='utf-8')\n",
    "#     file_handler.setLevel(logging.DEBUG)\n",
    "#     logger.addHandler(stream_handler)\n",
    "#     logger.addHandler(file_handler)\n",
    "    \n",
    "#     common_params = {}\n",
    "#     list_stock_code = []\n",
    "#     list_stock_data = []\n",
    "#     list_training_data = []\n",
    "#     list_min_trading_price = []\n",
    "#     list_max_trading_price = []\n",
    "    \n",
    "#     for stock_code in stock_codes:\n",
    "#         _, stock_data, training_data = load_data(\n",
    "#             stock_code, start_date, end_date\n",
    "#         )\n",
    "        \n",
    "#         assert len(stock_data) >= num_steps\n",
    "        \n",
    "#         # minimum and maximum trading price policy\n",
    "#         min_trading_price = min_trading_price\n",
    "#         max_trading_price = max_trading_price\n",
    "        \n",
    "#         # common parameters\n",
    "#         common_params = {\n",
    "#             'rl_method': rl_method,\n",
    "#             'net': net, 'num_steps': num_steps,  'lr': lr,\n",
    "#             'balance': initial_balance, 'num_epochs': num_epochs,\n",
    "#             'discount_factor': discount_factor, 'start_epsilon': start_epsilon,\n",
    "#             'output_path': output_path, 'reuse_models': reuse_models\n",
    "#         }\n",
    "                \n",
    "#         # start reinforcement learning\n",
    "#         learner = None\n",
    "#         if rl_method != 'a3c':\n",
    "#             common_params.update({\n",
    "#                 'stock_code': stock_code,\n",
    "#                 'stock_data': stock_data,\n",
    "#                 'training_data': training_data,\n",
    "#                 'min_trading_price': min_trading_price,\n",
    "#                 'max_trading_price': max_trading_price\n",
    "#             })\n",
    "            \n",
    "#             if rl_method == 'dqn':    \n",
    "#                 learner = DQNLearner(**{**common_params, 'value_network_path': value_network_path})\n",
    "            \n",
    "#             elif rl_method == 'pg':\n",
    "#                 learner = PolicyGradientLearner(**{**common_params, 'policy_network_path': policy_network_path})\n",
    "            \n",
    "#             elif rl_method == 'ac':\n",
    "#                 learner = ActorCriticLearner(**{**common_params, 'value_network_path': value_network_path, 'policy_network_path': policy_network_path})\n",
    "            \n",
    "#             elif rl_method == 'a2c':\n",
    "#                 learner = A2CLearner(**{**common_params,\n",
    "#                                         'value_network_path': value_network_path,\n",
    "#                                         'policy_network_path': policy_network_path})\n",
    "#             elif rl_method == 'ppo':\n",
    "#                 learner = PPOLearner(**{**common_params,\n",
    "#                                         'value_network_path': value_network_path,\n",
    "#                                         'policy_network_path': policy_network_path})\n",
    "#         else:\n",
    "#             list_stock_code.append(stock_code)\n",
    "#             list_stock_data.append(stock_data)\n",
    "#             list_training_data.append(training_data)\n",
    "#             list_min_trading_price.append(min_trading_price)\n",
    "#             list_max_trading_price.append(max_trading_price)\n",
    "    \n",
    "#     # in case of A3CLearner, create A2C instances as many as list size\n",
    "#     if rl_method == 'a3c':\n",
    "#         learner = A3CLearner(**{\n",
    "#             **common_params,\n",
    "#             'list_stock_code': list_stock_code,\n",
    "#             'list_stock_data': list_stock_data,\n",
    "#             'list_training_data': list_training_data,\n",
    "#             'list_min_trading_price': list_min_trading_price,\n",
    "#             'list_max_trading_price': list_max_trading_price,\n",
    "#             'value_network_path': value_network_path,\n",
    "#             'policy_network_path': value_network_path\n",
    "#         })\n",
    "        \n",
    "#     # check learner is not None\n",
    "#     assert learner is not None\n",
    "        \n",
    "#     if mode in ['train', 'test', 'update']:\n",
    "#         learner.run(learning=learning)\n",
    "            \n",
    "#         if mode in ['train', 'update']:\n",
    "#             learner.save_models()\n",
    "        \n",
    "#     elif mode == 'predict':  \n",
    "#         learner.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "def run_trader(mode='train', stock_names=['Apple', 'Tesla', 'Microsoft'], rl_method='dqn', net='cnn',\n",
    "               start_date='2020-01-01', end_date='2023-12-31',\n",
    "               lr=0.01, discount_factor=0.9,\n",
    "               initial_balance=1000000, stock_codes=['AAPL', 'TSLA', 'MSFT'],\n",
    "               min_trading_price=1, max_trading_price=10000, num_epochs=1000):\n",
    "    \n",
    "    os.environ['RLTRADER_BASE'] = 'C:\\project\\github\\projects\\trader'\n",
    "    ''' \n",
    "    Arguments\n",
    "    --------\n",
    "    mode : 'train', 'test', 'update', 'predict'\n",
    "    rl_method : 'dqn', 'a2c', 'a3c', 'pg', 'ppo'\n",
    "    '''\n",
    "\n",
    "    # learner's parameter\n",
    "    output_name = f'{mode}_{stock_names}_{rl_method}_{net}'\n",
    "    # reinforcement learning True or False\n",
    "    learning = mode in ['train', 'update']\n",
    "    # use model flag\n",
    "    reuse_models = mode in ['test', 'update', 'predict']\n",
    "    value_network_name = f'{stock_names}_{rl_method}_{net}_value.mdl'\n",
    "    policy_network_name = f'{stock_names}_{rl_method}_{net}_policy.mdl'\n",
    "    start_epsilon = 1 if mode in ['train', 'update'] else 0\n",
    "    num_epochs = num_epochs if mode in ['train', 'update'] else 0\n",
    "    num_steps = 5 if net in ['lstm', 'cnn', 'alex'] else 1\n",
    "    \n",
    "    # output path\n",
    "    output_path = os.path.join(BASE_DIR, 'output', output_name)\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    # log parameters\n",
    "    params = {\n",
    "        'mode': mode,\n",
    "        'stock_names': stock_names,\n",
    "        'rl_method': rl_method,\n",
    "        'net': net,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'lr': lr,\n",
    "        'discount_factor': discount_factor,\n",
    "        'initial_balance': initial_balance,\n",
    "        'stock_codes': stock_codes,\n",
    "    }\n",
    "    # params = json.dumps(vars(args))\n",
    "    with open(os.path.join(output_path, 'params.json'), 'w') as f:\n",
    "        f.write(str(params))\n",
    "    \n",
    "    # model path\n",
    "    value_network_path = os.path.join(BASE_DIR, 'models', value_network_name)\n",
    "    policy_network_path = os.path.join(BASE_DIR, 'models', policy_network_name)\n",
    "    \n",
    "    # setting for logging\n",
    "    # log level DEBUG < INFO < WARNING < CRITICAL. more than DEBUG\n",
    "    log_path = os.path.join(output_path, f'{output_name}.log')\n",
    "    if os.path.exists(log_path):\n",
    "        os.remove(log_path)\n",
    "    logging.basicConfig(format='%(message)s')\n",
    "    logger = logging.getLogger(LOGGER_NAME)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.propagate = False\n",
    "    stream_handler = logging.StreamHandler(sys.stdout)\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    file_handler = logging.FileHandler(filename=log_path, encoding='utf-8')\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    common_params = {}\n",
    "    list_stock_code = []\n",
    "    list_stock_data = []\n",
    "    list_training_data = []\n",
    "    list_min_trading_price = []\n",
    "    list_max_trading_price = []\n",
    "    \n",
    "    for stock_code in stock_codes:\n",
    "        _, stock_data, training_data = load_data(\n",
    "            stock_code, start_date, end_date\n",
    "        )\n",
    "        \n",
    "        assert len(stock_data) >= num_steps\n",
    "        \n",
    "        # minimum and maximum trading price policy\n",
    "        min_trading_price = min_trading_price\n",
    "        max_trading_price = max_trading_price\n",
    "        \n",
    "        # common parameters\n",
    "        common_params = {\n",
    "            'rl_method': rl_method,\n",
    "            'net': net, 'num_steps': num_steps,  'lr': lr,\n",
    "            'balance': initial_balance, 'num_epochs': num_epochs,\n",
    "            'discount_factor': discount_factor, 'start_epsilon': start_epsilon,\n",
    "            'output_path': output_path, 'reuse_models': reuse_models\n",
    "        }\n",
    "                \n",
    "        # start reinforcement learning\n",
    "        learner = None\n",
    "        if rl_method != 'a3c':\n",
    "            common_params.update({\n",
    "                'stock_code': stock_code,\n",
    "                'stock_data': stock_data,\n",
    "                'training_data': training_data,\n",
    "                'min_trading_price': min_trading_price,\n",
    "                'max_trading_price': max_trading_price\n",
    "            })\n",
    "            \n",
    "            if rl_method == 'dqn':    \n",
    "                learner = DQNLearner(**{**common_params, 'value_network_path': value_network_path})\n",
    "            \n",
    "            elif rl_method == 'pg':\n",
    "                learner = PolicyGradientLearner(**{**common_params, 'policy_network_path': policy_network_path})\n",
    "            \n",
    "            elif rl_method == 'ac':\n",
    "                learner = ActorCriticLearner(**{**common_params, 'value_network_path': value_network_path, 'policy_network_path': policy_network_path})\n",
    "            \n",
    "            elif rl_method == 'a2c':\n",
    "                learner = A2CLearner(**{**common_params,\n",
    "                                        'value_network_path': value_network_path,\n",
    "                                        'policy_network_path': policy_network_path})\n",
    "            elif rl_method == 'ppo':\n",
    "                learner = PPOLearner(**{**common_params,\n",
    "                                        'value_network_path': value_network_path,\n",
    "                                        'policy_network_path': policy_network_path})\n",
    "        else:\n",
    "            list_stock_code.append(stock_code)\n",
    "            list_stock_data.append(stock_data)\n",
    "            list_training_data.append(training_data)\n",
    "            list_min_trading_price.append(min_trading_price)\n",
    "            list_max_trading_price.append(max_trading_price)\n",
    "    \n",
    "    # in case of A3CLearner, create A2C instances as many as list size\n",
    "    if rl_method == 'a3c':\n",
    "        learner = A3CLearner(**{\n",
    "            **common_params,\n",
    "            'list_stock_code': list_stock_code,\n",
    "            'list_stock_data': list_stock_data,\n",
    "            'list_training_data': list_training_data,\n",
    "            'list_min_trading_price': list_min_trading_price,\n",
    "            'list_max_trading_price': list_max_trading_price,\n",
    "            'value_network_path': value_network_path,\n",
    "            'policy_network_path': value_network_path\n",
    "        })\n",
    "        \n",
    "    # check learner is not None\n",
    "    assert learner is not None\n",
    "        \n",
    "    if mode in ['train', 'test', 'update']:\n",
    "        learner.run(learning=learning)\n",
    "            \n",
    "        if mode in ['train', 'update']:\n",
    "            learner.save_models()\n",
    "        \n",
    "    elif mode == 'predict':  \n",
    "        learner.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_trader_a3c(stock_names=['Tesla', 'Apple', 'Miscrosoft'], stock_codes=['TSLA', 'AAPL', 'MSFT'], net='dnn', rl_method='a3c', num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'TSLA'\n",
      "                    AND date BETWEEN '2020-01-01' AND '2023-12-31' \n",
      "                    \n",
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'AAPL'\n",
      "                    AND date BETWEEN '2020-01-01' AND '2023-12-31' \n",
      "                    \n",
      " \n",
      "                    SELECT * FROM price_global\n",
      "                    WHERE ticker = 'MSFT'\n",
      "                    AND date BETWEEN '2020-01-01' AND '2023-12-31' \n",
      "                    \n",
      "alex\n",
      "AlexNet is called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/1000 [00:01<?, ?it/s]\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\woojin\\anaconda3\\envs\\finance\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\woojin\\anaconda3\\envs\\finance\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_8056\\490651352.py\", line 388, in run\n",
      "  File \"C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_8056\\490651352.py\", line 254, in fit\n",
      "AttributeError: 'NoneType' object has no attribute 'train_on_batch'\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\woojin\\anaconda3\\envs\\finance\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\woojin\\anaconda3\\envs\\finance\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_8056\\490651352.py\", line 388, in run\n",
      "  File \"C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_8056\\490651352.py\", line 254, in fit\n",
      "AttributeError: 'NoneType' object has no attribute 'train_on_batch'\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\woojin\\anaconda3\\envs\\finance\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\woojin\\anaconda3\\envs\\finance\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_8056\\490651352.py\", line 388, in run\n",
      "  File \"C:\\Users\\woojin\\AppData\\Local\\Temp\\ipykernel_8056\\490651352.py\", line 254, in fit\n",
      "AttributeError: 'NoneType' object has no attribute 'train_on_batch'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_trader(stock_names=['Tesla', 'Apple', 'Miscrosoft'], stock_codes=['TSLA', 'AAPL', 'MSFT'], net='alex', rl_method='a3c', num_epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
