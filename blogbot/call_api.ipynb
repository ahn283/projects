{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'messages': HumanMessage(content=\"# Title\\nDeepSeek-R1: A Groundbreaking Reinforcement Learning-Based AI Model\\n\\n# Objectives\\n- Provide a comprehensive overview of the DeepSeek-R1 AI model\\n- Explain its unique approach to reasoning using Reinforcement Learning (RL)\\n- Highlight the model's technical capabilities, open-source nature, and potential impact on AI research\\n\\n# Outlines\\n\\n## 1. Introduction to DeepSeek-R1\\n- Release date: January 20, 2025\\n- Developed by DeepSeek, a startup in Hangzhou, China\\n- Key distinguishing feature: First SOTA reasoning model trained purely through Reinforcement Learning\\n\\n## 2. Technical Architecture\\n- Reinforcement Learning Approach\\n  - Direct large-scale RL training\\n  - Base model: DeepSeek-V3\\n- Model Variants\\n  - DeepSeek-R1-Zero\\n  - Six dense models (1.5B, 7B, 8B, 14B, 32B, 70B)\\n- Licensing: MIT open-source license\\n\\n## 3. Performance and Capabilities\\n- Reasoning Task Performance\\n  - Comparable to OpenAI's o1 model\\n  - Strong performance in:\\n    - Chemistry\\n    - Mathematics\\n    - Coding tasks\\n- Innovative Features\\n  - Open-weight model\\n  - Affordable AI deployment\\n  - Distilled versions for researchers with limited computing power\\n\\n## 4. Pricing and Accessibility\\n- API Pricing\\n  - Input tokens (cache hit): $0.14 per million\\n  - Input tokens (cache miss): $0.55 per million\\n  - Output tokens: $2.19 per million\\n- Accessibility\\n  - Available through DeepSeek API\\n  - Open-source model weights\\n  - Community-friendly approach\\n\\n## 5. Potential Implications and Risks\\n- Global AI Landscape Impact\\n- Security Considerations\\n- Ethical AI Development\\n- Potential for Research and Innovation\\n\\n## 6. Conclusion\\n- Summary of DeepSeek-R1's unique contributions\\n- Future outlook for Reinforcement Learning in AI\\n\\n# Research and Writing Tasks\\n1. Research Team\\n- Gather detailed technical specifications of DeepSeek-R1\\n- Collect performance benchmarks\\n- Analyze comparative studies with other AI models\\n\\n2. Technical Writing Team\\n- Explain Reinforcement Learning in accessible language\\n- Highlight the model's innovative approach\\n- Discuss potential real-world applications\\n\\n3. Code Example Team\\n- Provide sample code demonstrating DeepSeek-R1 usage\\n- Show integration with DeepSeek API\\n- Create simple reasoning task demonstrations\\n\\n# Additional Notes\\n- Verify all technical details with the latest DeepSeek documentation\\n- Maintain a balanced, objective tone\\n- Emphasize the model's open-source and research-friendly nature\\n\\nWould you like me to elaborate on any specific section of the blog post plan?\", additional_kwargs={}, response_metadata={}, name='planner', id='5009ec9f-29d8-4525-b591-2ab299a56a96'), 'outline': \"# Title\\nDeepSeek-R1: A Groundbreaking Reinforcement Learning-Based AI Model\\n\\n# Objectives\\n- Provide a comprehensive overview of the DeepSeek-R1 AI model\\n- Explain its unique approach to reasoning using Reinforcement Learning (RL)\\n- Highlight the model's technical capabilities, open-source nature, and potential impact on AI research\\n\\n# Outlines\\n\\n## 1. Introduction to DeepSeek-R1\\n- Release date: January 20, 2025\\n- Developed by DeepSeek, a startup in Hangzhou, China\\n- Key distinguishing feature: First SOTA reasoning model trained purely through Reinforcement Learning\\n\\n## 2. Technical Architecture\\n- Reinforcement Learning Approach\\n  - Direct large-scale RL training\\n  - Base model: DeepSeek-V3\\n- Model Variants\\n  - DeepSeek-R1-Zero\\n  - Six dense models (1.5B, 7B, 8B, 14B, 32B, 70B)\\n- Licensing: MIT open-source license\\n\\n## 3. Performance and Capabilities\\n- Reasoning Task Performance\\n  - Comparable to OpenAI's o1 model\\n  - Strong performance in:\\n    - Chemistry\\n    - Mathematics\\n    - Coding tasks\\n- Innovative Features\\n  - Open-weight model\\n  - Affordable AI deployment\\n  - Distilled versions for researchers with limited computing power\\n\\n## 4. Pricing and Accessibility\\n- API Pricing\\n  - Input tokens (cache hit): $0.14 per million\\n  - Input tokens (cache miss): $0.55 per million\\n  - Output tokens: $2.19 per million\\n- Accessibility\\n  - Available through DeepSeek API\\n  - Open-source model weights\\n  - Community-friendly approach\\n\\n## 5. Potential Implications and Risks\\n- Global AI Landscape Impact\\n- Security Considerations\\n- Ethical AI Development\\n- Potential for Research and Innovation\\n\\n## 6. Conclusion\\n- Summary of DeepSeek-R1's unique contributions\\n- Future outlook for Reinforcement Learning in AI\\n\\n# Research and Writing Tasks\\n1. Research Team\\n- Gather detailed technical specifications of DeepSeek-R1\\n- Collect performance benchmarks\\n- Analyze comparative studies with other AI models\\n\\n2. Technical Writing Team\\n- Explain Reinforcement Learning in accessible language\\n- Highlight the model's innovative approach\\n- Discuss potential real-world applications\\n\\n3. Code Example Team\\n- Provide sample code demonstrating DeepSeek-R1 usage\\n- Show integration with DeepSeek API\\n- Create simple reasoning task demonstrations\\n\\n# Additional Notes\\n- Verify all technical details with the latest DeepSeek documentation\\n- Maintain a balanced, objective tone\\n- Emphasize the model's open-source and research-friendly nature\\n\\nWould you like me to elaborate on any specific section of the blog post plan?\"}}\n",
      "{'researcher': {'messages': HumanMessage(content=\"Here’s a comprehensive overview of the **DeepSeek-R1 AI model**, based on the latest information available:\\n\\n### 1. Introduction to DeepSeek-R1\\n- **Release Date**: January 20, 2025.\\n- **Developer**: DeepSeek, a startup located in Hangzhou, China.\\n- **Key Feature**: It is the first state-of-the-art (SOTA) reasoning model trained purely through Reinforcement Learning (RL), distinguishing it from other AI models that often incorporate supervised learning techniques.\\n\\n### 2. Technical Architecture\\n- **Reinforcement Learning Approach**: DeepSeek-R1 utilizes direct large-scale RL training, building on the base model DeepSeek-V3.\\n- **Model Variants**: The model has several variants, including:\\n  - **DeepSeek-R1-Zero**: A model trained solely using direct RL.\\n  - **Dense Models**: Six different dense models with parameters ranging from 1.5B to 70B.\\n- **Licensing**: Released under the MIT open-source license, allowing broad access for developers and researchers.\\n\\n### 3. Performance and Capabilities\\n- **Reasoning Task Performance**: Initial benchmarks indicate that DeepSeek-R1 performs comparably to OpenAI's o1 model, particularly excelling in tasks related to:\\n  - Chemistry\\n  - Mathematics\\n  - Coding\\n- **Innovative Features**:\\n  - Open-weight model, enabling researchers to study and build upon its architecture.\\n  - Affordable deployment options, including distilled versions for users with limited computational resources.\\n\\n### 4. Pricing and Accessibility\\n- **API Pricing**:\\n  - Input tokens (cache hit): $0.14 per million.\\n  - Input tokens (cache miss): $0.55 per million.\\n  - Output tokens: $2.19 per million.\\n- **Accessibility**: Available through the DeepSeek API, with open-source model weights provided to encourage community engagement.\\n\\n### 5. Potential Implications and Risks\\n- **Impact on Global AI Landscape**: DeepSeek-R1's release has sparked discussions about its implications for AI research and development, particularly in light of U.S. export controls on AI technology.\\n- **Security and Ethical Considerations**: The model raises questions regarding security, ethical AI development, and its potential to drive innovation in various fields.\\n\\n### 6. Conclusion\\nDeepSeek-R1 represents a significant advancement in the application of Reinforcement Learning for reasoning tasks in AI, promising to influence future research and development in the field.\\n\\n### Sources\\n1. [Aiera - DeepSeek's R1 Release](https://www.aiera.com/resources/deepseeks-r1-release-separating-signal-from-noise)\\n2. [Medium - Summary of DeepSeek-R1](https://medium.com/@mayadakhatib/deepseek-r1-a-short-summary-73b6b8ced9cf)\\n3. [DeepSeek API Docs](https://api-docs.deepseek.com/news/news250120)\\n4. [Nature - DeepSeek-R1 Performance](https://www.nature.com/articles/d41586-025-00229-6)\\n5. [Lawfare - What DeepSeek-R1 Means](https://www.lawfaremedia.org/article/what-deepseek-r1-means-and-what-it-doesn-t)\\n\\nThis information should provide a solid foundation for your blog post on the DeepSeek-R1 AI model. If you need further elaboration on any specific section, feel free to ask!\", additional_kwargs={}, response_metadata={}, name='researcher', id='dec0af33-1ab7-4b97-b3a7-48c66678d166'), 'docs': \"Here’s a comprehensive overview of the **DeepSeek-R1 AI model**, based on the latest information available:\\n\\n### 1. Introduction to DeepSeek-R1\\n- **Release Date**: January 20, 2025.\\n- **Developer**: DeepSeek, a startup located in Hangzhou, China.\\n- **Key Feature**: It is the first state-of-the-art (SOTA) reasoning model trained purely through Reinforcement Learning (RL), distinguishing it from other AI models that often incorporate supervised learning techniques.\\n\\n### 2. Technical Architecture\\n- **Reinforcement Learning Approach**: DeepSeek-R1 utilizes direct large-scale RL training, building on the base model DeepSeek-V3.\\n- **Model Variants**: The model has several variants, including:\\n  - **DeepSeek-R1-Zero**: A model trained solely using direct RL.\\n  - **Dense Models**: Six different dense models with parameters ranging from 1.5B to 70B.\\n- **Licensing**: Released under the MIT open-source license, allowing broad access for developers and researchers.\\n\\n### 3. Performance and Capabilities\\n- **Reasoning Task Performance**: Initial benchmarks indicate that DeepSeek-R1 performs comparably to OpenAI's o1 model, particularly excelling in tasks related to:\\n  - Chemistry\\n  - Mathematics\\n  - Coding\\n- **Innovative Features**:\\n  - Open-weight model, enabling researchers to study and build upon its architecture.\\n  - Affordable deployment options, including distilled versions for users with limited computational resources.\\n\\n### 4. Pricing and Accessibility\\n- **API Pricing**:\\n  - Input tokens (cache hit): $0.14 per million.\\n  - Input tokens (cache miss): $0.55 per million.\\n  - Output tokens: $2.19 per million.\\n- **Accessibility**: Available through the DeepSeek API, with open-source model weights provided to encourage community engagement.\\n\\n### 5. Potential Implications and Risks\\n- **Impact on Global AI Landscape**: DeepSeek-R1's release has sparked discussions about its implications for AI research and development, particularly in light of U.S. export controls on AI technology.\\n- **Security and Ethical Considerations**: The model raises questions regarding security, ethical AI development, and its potential to drive innovation in various fields.\\n\\n### 6. Conclusion\\nDeepSeek-R1 represents a significant advancement in the application of Reinforcement Learning for reasoning tasks in AI, promising to influence future research and development in the field.\\n\\n### Sources\\n1. [Aiera - DeepSeek's R1 Release](https://www.aiera.com/resources/deepseeks-r1-release-separating-signal-from-noise)\\n2. [Medium - Summary of DeepSeek-R1](https://medium.com/@mayadakhatib/deepseek-r1-a-short-summary-73b6b8ced9cf)\\n3. [DeepSeek API Docs](https://api-docs.deepseek.com/news/news250120)\\n4. [Nature - DeepSeek-R1 Performance](https://www.nature.com/articles/d41586-025-00229-6)\\n5. [Lawfare - What DeepSeek-R1 Means](https://www.lawfaremedia.org/article/what-deepseek-r1-means-and-what-it-doesn-t)\\n\\nThis information should provide a solid foundation for your blog post on the DeepSeek-R1 AI model. If you need further elaboration on any specific section, feel free to ask!\"}}\n",
      "{'coder': {'messages': HumanMessage(content='# Topic\\nDeepSeek-R1 AI Model Overview\\n\\n# Code Snippet\\n```python\\n# Example of making an API call to the DeepSeek-R1 model\\nimport requests\\n\\n# Define the API endpoint and your API key\\nAPI_ENDPOINT = \"https://api.deepseek.com/v1/generate\"\\nAPI_KEY = \"your_api_key_here\"\\n\\n# Function to generate text using DeepSeek-R1\\ndef generate_text(prompt):\\n    # Prepare the request payload\\n    payload = {\\n        \"prompt\": prompt,\\n        \"max_tokens\": 150  # Limit the number of tokens in the response\\n    }\\n    \\n    # Set headers including the authorization\\n    headers = {\\n        \"Authorization\": f\"Bearer {API_KEY}\",\\n        \"Content-Type\": \"application/json\"\\n    }\\n    \\n    # Make the POST request to the API\\n    response = requests.post(API_ENDPOINT, json=payload, headers=headers)\\n    \\n    # Check for errors in the response\\n    if response.status_code == 200:\\n        return response.json()[\\'text\\']  # Extract the generated text\\n    else:\\n        raise Exception(f\"Error: {response.status_code} - {response.text}\")\\n\\n# Example usage\\nif __name__ == \"__main__\":\\n    prompt = \"Explain the significance of DeepSeek-R1 in AI development.\"\\n    try:\\n        generated_text = generate_text(prompt)\\n        print(\"Generated Text:\", generated_text)\\n    except Exception as e:\\n        print(e)\\n```\\n\\n# Explanation\\nThis Python code snippet demonstrates how to interact with the DeepSeek-R1 API to generate text based on a given prompt. Here\\'s a breakdown of the key components:\\n\\n1. **API Configuration**: The `API_ENDPOINT` variable holds the URL for the DeepSeek API, and `API_KEY` should be replaced with a valid key that you receive upon registration.\\n\\n2. **Function Definition**: The `generate_text` function takes a `prompt` as an argument:\\n   - It prepares the payload with the prompt and a limit on the number of tokens for the response.\\n   - Sets the headers, including the authorization token for API access.\\n\\n3. **Making the Request**: The function uses the `requests` library to perform a POST request to the API endpoint with the payload and headers.\\n\\n4. **Error Handling**: After making the request, it checks the response status. If successful, it extracts and returns the generated text; otherwise, it raises an exception with the error details.\\n\\n5. **Example Usage**: The script includes a main block that demonstrates how to use the `generate_text` function with a sample prompt.\\n\\nThis code is a practical example of how to leverage the DeepSeek-R1 model for generating text, showcasing its potential for various applications in AI development.', additional_kwargs={}, response_metadata={}, name='coder', id='c78547db-1fec-4aae-85e9-1cfb3f4fcbd4'), 'codes': '# Topic\\nDeepSeek-R1 AI Model Overview\\n\\n# Code Snippet\\n```python\\n# Example of making an API call to the DeepSeek-R1 model\\nimport requests\\n\\n# Define the API endpoint and your API key\\nAPI_ENDPOINT = \"https://api.deepseek.com/v1/generate\"\\nAPI_KEY = \"your_api_key_here\"\\n\\n# Function to generate text using DeepSeek-R1\\ndef generate_text(prompt):\\n    # Prepare the request payload\\n    payload = {\\n        \"prompt\": prompt,\\n        \"max_tokens\": 150  # Limit the number of tokens in the response\\n    }\\n    \\n    # Set headers including the authorization\\n    headers = {\\n        \"Authorization\": f\"Bearer {API_KEY}\",\\n        \"Content-Type\": \"application/json\"\\n    }\\n    \\n    # Make the POST request to the API\\n    response = requests.post(API_ENDPOINT, json=payload, headers=headers)\\n    \\n    # Check for errors in the response\\n    if response.status_code == 200:\\n        return response.json()[\\'text\\']  # Extract the generated text\\n    else:\\n        raise Exception(f\"Error: {response.status_code} - {response.text}\")\\n\\n# Example usage\\nif __name__ == \"__main__\":\\n    prompt = \"Explain the significance of DeepSeek-R1 in AI development.\"\\n    try:\\n        generated_text = generate_text(prompt)\\n        print(\"Generated Text:\", generated_text)\\n    except Exception as e:\\n        print(e)\\n```\\n\\n# Explanation\\nThis Python code snippet demonstrates how to interact with the DeepSeek-R1 API to generate text based on a given prompt. Here\\'s a breakdown of the key components:\\n\\n1. **API Configuration**: The `API_ENDPOINT` variable holds the URL for the DeepSeek API, and `API_KEY` should be replaced with a valid key that you receive upon registration.\\n\\n2. **Function Definition**: The `generate_text` function takes a `prompt` as an argument:\\n   - It prepares the payload with the prompt and a limit on the number of tokens for the response.\\n   - Sets the headers, including the authorization token for API access.\\n\\n3. **Making the Request**: The function uses the `requests` library to perform a POST request to the API endpoint with the payload and headers.\\n\\n4. **Error Handling**: After making the request, it checks the response status. If successful, it extracts and returns the generated text; otherwise, it raises an exception with the error details.\\n\\n5. **Example Usage**: The script includes a main block that demonstrates how to use the `generate_text` function with a sample prompt.\\n\\nThis code is a practical example of how to leverage the DeepSeek-R1 model for generating text, showcasing its potential for various applications in AI development.'}}\n",
      "{'writer': {'messages': HumanMessage(content='Based on the search results and our previous research, I\\'ll draft the blog post in Markdown format:\\n\\n# DeepSeek-R1: A Groundbreaking Reinforcement Learning-Based AI Model\\n\\n## Introduction\\n\\nOn January 20, 2025, DeepSeek, a pioneering AI startup based in Hangzhou, China, unveiled the **DeepSeek-R1** — a revolutionary AI model that is set to redefine the landscape of artificial intelligence and reasoning capabilities. What makes DeepSeek-R1 truly remarkable is its unique approach: it\\'s the first state-of-the-art (SOTA) reasoning model trained purely through Reinforcement Learning (RL).\\n\\n## Technical Architecture: A Deep Dive into Reinforcement Learning\\n\\n### Innovative Training Approach\\nUnlike traditional AI models that rely heavily on supervised learning, DeepSeek-R1 takes a bold step by utilizing direct large-scale Reinforcement Learning. Built on the foundation of the DeepSeek-V3 base model, R1 represents a significant leap in AI model development.\\n\\n### Model Variants\\nDeepSeek has released a comprehensive suite of models to cater to diverse research and application needs:\\n\\n- **DeepSeek-R1-Zero**: The flagship model trained solely through direct RL\\n- **Dense Models**: Six variants with parameter sizes ranging from 1.5B to 70B\\n- **Licensing**: Released under the MIT open-source license, promoting transparency and community collaboration\\n\\n## Performance and Capabilities\\n\\n### Reasoning Task Excellence\\nInitial benchmarks reveal that DeepSeek-R1 performs comparably to OpenAI\\'s o1 model, particularly excelling in:\\n- Chemistry\\n- Mathematics\\n- Coding tasks\\n\\n### Innovative Features\\n- **Open-weight model** allowing researchers to study and build upon its architecture\\n- **Affordable deployment options**\\n- **Distilled versions** for researchers with limited computational resources\\n\\n## Pricing and Accessibility\\n\\n### API Pricing Structure\\n- Input tokens (cache hit): $0.14 per million\\n- Input tokens (cache miss): $0.55 per million\\n- Output tokens: $2.19 per million\\n\\n### Accessibility Highlights\\n- Available through DeepSeek API\\n- Open-source model weights\\n- Community-friendly approach\\n\\n## Code Example: Interacting with DeepSeek-R1\\n\\nHere\\'s a Python snippet demonstrating how to interact with the DeepSeek-R1 API:\\n\\n```python\\nimport requests\\n\\nAPI_ENDPOINT = \"https://api.deepseek.com/v1/generate\"\\nAPI_KEY = \"your_api_key_here\"\\n\\ndef generate_text(prompt):\\n    payload = {\\n        \"prompt\": prompt,\\n        \"max_tokens\": 150\\n    }\\n    \\n    headers = {\\n        \"Authorization\": f\"Bearer {API_KEY}\",\\n        \"Content-Type\": \"application/json\"\\n    }\\n    \\n    response = requests.post(API_ENDPOINT, json=payload, headers=headers)\\n    \\n    if response.status_code == 200:\\n        return response.json()[\\'text\\']\\n    else:\\n        raise Exception(f\"Error: {response.status_code} - {response.text}\")\\n\\n# Example usage\\nprompt = \"Explain the significance of DeepSeek-R1 in AI development.\"\\ngenerated_text = generate_text(prompt)\\nprint(\"Generated Text:\", generated_text)\\n```\\n\\n## Global Impact and Implications\\n\\n### Research and Innovation\\nDeepSeek-R1 is not just another AI model; it\\'s a testament to the potential of Reinforcement Learning in creating more adaptive and intelligent systems. By open-sourcing the model, DeepSeek has invited global researchers to collaborate and push the boundaries of AI.\\n\\n### Economic Perspective\\nInterestingly, analysts at Jeffries estimate that DeepSeek spent approximately $5.6 million to train R1 — a fraction of the cost compared to models developed by U.S. tech giants.\\n\\n## Conclusion\\n\\nDeepSeek-R1 represents a significant milestone in AI development, showcasing the power of Reinforcement Learning and the importance of open-source collaboration. As the AI landscape continues to evolve, models like R1 demonstrate that innovation can come from unexpected places, challenging existing paradigms and opening new frontiers of technological exploration.\\n\\n## References\\n1. DeepSeek API Documentation\\n2. Nature Research Article\\n3. Builtin.com AI Coverage\\n4. Lawfare Media Analysis\\n\\n*Disclaimer: API', additional_kwargs={}, response_metadata={}, name='writer', id='e4228825-4b89-4750-a314-a043d52547ad'), 'post': 'Based on the search results and our previous research, I\\'ll draft the blog post in Markdown format:\\n\\n# DeepSeek-R1: A Groundbreaking Reinforcement Learning-Based AI Model\\n\\n## Introduction\\n\\nOn January 20, 2025, DeepSeek, a pioneering AI startup based in Hangzhou, China, unveiled the **DeepSeek-R1** — a revolutionary AI model that is set to redefine the landscape of artificial intelligence and reasoning capabilities. What makes DeepSeek-R1 truly remarkable is its unique approach: it\\'s the first state-of-the-art (SOTA) reasoning model trained purely through Reinforcement Learning (RL).\\n\\n## Technical Architecture: A Deep Dive into Reinforcement Learning\\n\\n### Innovative Training Approach\\nUnlike traditional AI models that rely heavily on supervised learning, DeepSeek-R1 takes a bold step by utilizing direct large-scale Reinforcement Learning. Built on the foundation of the DeepSeek-V3 base model, R1 represents a significant leap in AI model development.\\n\\n### Model Variants\\nDeepSeek has released a comprehensive suite of models to cater to diverse research and application needs:\\n\\n- **DeepSeek-R1-Zero**: The flagship model trained solely through direct RL\\n- **Dense Models**: Six variants with parameter sizes ranging from 1.5B to 70B\\n- **Licensing**: Released under the MIT open-source license, promoting transparency and community collaboration\\n\\n## Performance and Capabilities\\n\\n### Reasoning Task Excellence\\nInitial benchmarks reveal that DeepSeek-R1 performs comparably to OpenAI\\'s o1 model, particularly excelling in:\\n- Chemistry\\n- Mathematics\\n- Coding tasks\\n\\n### Innovative Features\\n- **Open-weight model** allowing researchers to study and build upon its architecture\\n- **Affordable deployment options**\\n- **Distilled versions** for researchers with limited computational resources\\n\\n## Pricing and Accessibility\\n\\n### API Pricing Structure\\n- Input tokens (cache hit): $0.14 per million\\n- Input tokens (cache miss): $0.55 per million\\n- Output tokens: $2.19 per million\\n\\n### Accessibility Highlights\\n- Available through DeepSeek API\\n- Open-source model weights\\n- Community-friendly approach\\n\\n## Code Example: Interacting with DeepSeek-R1\\n\\nHere\\'s a Python snippet demonstrating how to interact with the DeepSeek-R1 API:\\n\\n```python\\nimport requests\\n\\nAPI_ENDPOINT = \"https://api.deepseek.com/v1/generate\"\\nAPI_KEY = \"your_api_key_here\"\\n\\ndef generate_text(prompt):\\n    payload = {\\n        \"prompt\": prompt,\\n        \"max_tokens\": 150\\n    }\\n    \\n    headers = {\\n        \"Authorization\": f\"Bearer {API_KEY}\",\\n        \"Content-Type\": \"application/json\"\\n    }\\n    \\n    response = requests.post(API_ENDPOINT, json=payload, headers=headers)\\n    \\n    if response.status_code == 200:\\n        return response.json()[\\'text\\']\\n    else:\\n        raise Exception(f\"Error: {response.status_code} - {response.text}\")\\n\\n# Example usage\\nprompt = \"Explain the significance of DeepSeek-R1 in AI development.\"\\ngenerated_text = generate_text(prompt)\\nprint(\"Generated Text:\", generated_text)\\n```\\n\\n## Global Impact and Implications\\n\\n### Research and Innovation\\nDeepSeek-R1 is not just another AI model; it\\'s a testament to the potential of Reinforcement Learning in creating more adaptive and intelligent systems. By open-sourcing the model, DeepSeek has invited global researchers to collaborate and push the boundaries of AI.\\n\\n### Economic Perspective\\nInterestingly, analysts at Jeffries estimate that DeepSeek spent approximately $5.6 million to train R1 — a fraction of the cost compared to models developed by U.S. tech giants.\\n\\n## Conclusion\\n\\nDeepSeek-R1 represents a significant milestone in AI development, showcasing the power of Reinforcement Learning and the importance of open-source collaboration. As the AI landscape continues to evolve, models like R1 demonstrate that innovation can come from unexpected places, challenging existing paradigms and opening new frontiers of technological exploration.\\n\\n## References\\n1. DeepSeek API Documentation\\n2. Nature Research Article\\n3. Builtin.com AI Coverage\\n4. Lawfare Media Analysis\\n\\n*Disclaimer: API'}}\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "url = \"http://127.0.0.1:8000/write/\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\"subject\": \"DeepSeek-R1\"}\n",
    "\n",
    "with httpx.stream(\"POST\", url, headers=headers, json=data, timeout=300.0) as response:\n",
    "    for chunk in response.iter_text():\n",
    "        print(chunk, end=\"\")  # Print streamed content live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Assistant\":\"Hello! How can I assist you today?\"}"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "url = \"http://127.0.0.1:8000/chat/\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\"messages\": \"hello\"}\n",
    "with httpx.stream(\"POST\", url, headers=headers, json=data, timeout=300.0) as response:\n",
    "    for chunk in response.iter_lines():\n",
    "        print(chunk, end=\"\")  # Print streamed content live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Assistant\": \"---START---\"}\n",
      "{\"Assistant\": \"1\"}\n",
      "{\"Assistant\": \"2\"}\n",
      "{\"Assistant\": \"3\"}\n",
      "{\"Assistant\": \"---END---\"}"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "url = \"http://127.0.0.1:8000/stream/\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\"messages\": \"hello\"}\n",
    "with httpx.stream(\"POST\", url, headers=headers, json=data, timeout=300.0) as response:\n",
    "    for chunk in response.iter_text():\n",
    "        print(chunk, end=\"\")  # Print streamed content live"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blogbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
